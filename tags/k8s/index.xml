<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>K8S on 万东的云计算运维博客</title>
    <link>https://wandong1.github.io/tags/k8s/</link>
    <description>Recent content in K8S on 万东的云计算运维博客</description>
    <image>
      <url>https://wandong1.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E</url>
      <link>https://wandong1.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E</link>
    </image>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-cn</language>
    <lastBuildDate>Thu, 15 Sep 2022 08:15:16 +0000</lastBuildDate><atom:link href="https://wandong1.github.io/tags/k8s/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>K8S根据现有证书生成管理员kubeconfig文件</title>
      <link>https://wandong1.github.io/post/k8s%E6%A0%B9%E6%8D%AE%E7%8E%B0%E6%9C%89%E8%AF%81%E4%B9%A6%E7%94%9F%E6%88%90%E7%AE%A1%E7%90%86%E5%91%98kubeconfig%E6%96%87%E4%BB%B6/</link>
      <pubDate>Thu, 15 Sep 2022 08:15:16 +0000</pubDate>
      
      <guid>https://wandong1.github.io/post/k8s%E6%A0%B9%E6%8D%AE%E7%8E%B0%E6%9C%89%E8%AF%81%E4%B9%A6%E7%94%9F%E6%88%90%E7%AE%A1%E7%90%86%E5%91%98kubeconfig%E6%96%87%E4%BB%B6/</guid>
      <description>生成管理员证书 cat &amp;gt; admin-csr.json &amp;lt;&amp;lt;EOF { &amp;#34;CN&amp;#34;: &amp;#34;admin&amp;#34;, &amp;#34;hosts&amp;#34;: [], &amp;#34;key&amp;#34;: { &amp;#34;algo&amp;#34;: &amp;#34;rsa&amp;#34;, &amp;#34;size&amp;#34;: 2048 }, &amp;#34;names&amp;#34;: [ { &amp;#34;C&amp;#34;: &amp;#34;CN&amp;#34;, &amp;#34;L&amp;#34;: &amp;#34;BeiJing&amp;#34;, &amp;#34;ST&amp;#34;: &amp;#34;BeiJing&amp;#34;, &amp;#34;O&amp;#34;: &amp;#34;system:masters&amp;#34;, &amp;#34;OU&amp;#34;: &amp;#34;System&amp;#34; } ] } EOF 执行生成命令 cfssl gencert -ca=ca.pem -ca-key=ca-key.pem -config=ca-config.json -profile=kubernetes admin-csr.json | cfssljson -bare admin 创建kubeconfig文件 # 设置集群参数 kubectl config set-cluster kubernetes \ --server=https://192.168.0.149:6443 \ --certificate-authority=ca.pem \ --embed-certs=true \ --kubeconfig=config # 设置上下文参数 kubectl config set-context default \ --cluster=kubernetes \ --user=cluster-admin \ --kubeconfig=config # 设置客户端认证参数 kubectl config set-credentials cluster-admin \ --certificate-authority=ca.</description>
    </item>
    
    <item>
      <title>rainbond对接nfs或者nas存储</title>
      <link>https://wandong1.github.io/post/rainbond%E5%AF%B9%E6%8E%A5nfs%E6%88%96%E8%80%85nas%E5%AD%98%E5%82%A8/</link>
      <pubDate>Thu, 15 Sep 2022 08:15:16 +0000</pubDate>
      
      <guid>https://wandong1.github.io/post/rainbond%E5%AF%B9%E6%8E%A5nfs%E6%88%96%E8%80%85nas%E5%AD%98%E5%82%A8/</guid>
      <description>https://www.rainbond.com/docs/ops-guide/storage/deploy-nfsclient
添加helm仓库 helm repo add rainbond https://openchart.goodrain.com/goodrain/rainbond helm repo update nfs或者nas配置文件 nfs-client.yaml
nfs: server: 1afc54bbca-jna4.cn-chongqing-cqzwy-d01.nas.alinetops.cqzwy.com #nfs server地址 path: / #nfs server 的路径 mountOptions: #添加参数 - hard - vers=4 - nolock - proto=tcp - rsize=1048576 - wsize=1048576 - timeo=600 - retrans=2 - noresvport 部署 helm install nfs-client-provisioner rainbond/nfs-client-provisioner \ -f nfs-client.yaml \ --version 1.2.8 创建有状态应用进行绑定 </description>
    </item>
    
    <item>
      <title>rainbond平台部署ES-filebeat</title>
      <link>https://wandong1.github.io/post/rainbond%E5%B9%B3%E5%8F%B0%E9%83%A8%E7%BD%B2es-filebeat/</link>
      <pubDate>Thu, 15 Sep 2022 08:15:16 +0000</pubDate>
      
      <guid>https://wandong1.github.io/post/rainbond%E5%B9%B3%E5%8F%B0%E9%83%A8%E7%BD%B2es-filebeat/</guid>
      <description>https://lequ7.com/guan-yu-paas-ping-tai-rainbond-tong-guo-cha-jian-zheng-he-elkefk-shi-xian-ri-zhi-shou-ji.html
通过helm部署filebeat采集容器日志 helm repo add elastic https://helm.elastic.co helm pull elastic/filebeat tar -xvzf filebeat-7.17.3.tgz &amp;amp;&amp;amp; cd filebeat hosts: [&amp;#39;cqzwy-mgmt-log-platform-grc055ce-0.cqzwy-mgmt-log-platform-grc055ce.013497775a1b4580924a00009a20c887.svc.cluster.local:9200&amp;#39;] username: &amp;#34;elastic&amp;#34; password: &amp;#34;kuGmFNENeZyYuGkYZ4BU&amp;#34; 进入容器内ping es的svc即可获得svc全称
helm install filebeat -n 013497775a1b4580924a00009a20c887 ./filebeat helm list -A 或者使用yaml直接不部署
--- apiVersion: v1 kind: ConfigMap metadata: name: filebeat-config namespace: 013497775a1b4580924a00009a20c887 labels: k8s-app: filebeat data: filebeat.yml: |- filebeat.config: inputs: # Mounted `filebeat-inputs` configmap: path: ${path.config}/inputs.d/*.yml # Reload inputs configs as they change: reload.enabled: false modules: path: ${path.config}/modules.d/*.yml # Reload module configs as they change: reload.</description>
    </item>
    
    <item>
      <title>rancher的安装和使用</title>
      <link>https://wandong1.github.io/post/rancher/</link>
      <pubDate>Thu, 15 Sep 2022 08:15:16 +0000</pubDate>
      
      <guid>https://wandong1.github.io/post/rancher/</guid>
      <description>Rancher Rancher 是一套容器管理平台，它可以帮助组织在生产环境中轻松快捷的部署和管理容器。 Rancher 可以轻松地管理各种环境的 Kubernetes，满足 IT 需求并为 DevOps 团队提供支持。
Rancher 四个组成部分 Rancher 由以下四个部分组成：
1、基础设施编排
Rancher 可以使用任何公有云或者私有云的 Linux 主机资源。Linux 主机可以是虚拟机，也可以是 物理机。
2、容器编排与调度
很多用户都会选择使用容器编排调度框架来运行容器化应用。Rancher 包含了当前全部主流的编排 调度引擎，例如 Docker Swarm， Kubernetes， 和 Mesos。同一个用户可以创建 Swarm 或者 Kubernetes 集群。并且可以使用原生的 Swarm 或者 Kubernetes 工具管理应用。 除了 Swarm，Kubernetes 和 Mesos 之外，Rancher 还支持自己的 Cattle 容器编排调度引擎。 Cattle 被广泛用于编排 Rancher 自己的基础设施服务以及用于 Swarm 集群，Kubernetes 集群和 Mesos 集群的配置，管理与升级。
3、应用商店
Rancher 的用户可以在应用商店里一键部署由多个容器组成的应用。用户可以管理这个部署的应 用，并且可以在这个应用有新的可用版本时进行自动化的升级。Rancher 提供了一个由 Rancher 社区维 护的应用商店，其中包括了一系列的流行应用。Rancher 的用户也可以创建自己的私有应用商店。
4、企业级权限管理
Rancher 支持灵活的插件式的用户认证。支持 Active Directory，LDAP， Github 等 认证方 式。</description>
    </item>
    
    <item>
      <title>helm的使用方法介绍</title>
      <link>https://wandong1.github.io/post/helm%E7%9A%84%E4%BD%BF%E7%94%A8%E6%96%B9%E6%B3%95/</link>
      <pubDate>Wed, 14 Sep 2022 16:14:24 +0000</pubDate>
      
      <guid>https://wandong1.github.io/post/helm%E7%9A%84%E4%BD%BF%E7%94%A8%E6%96%B9%E6%B3%95/</guid>
      <description>Helm Helm是一个Kubernetes的包管理工具，就像Linux下的包管理器，如yum/apt等，可以很方便的将之前
打包好的yaml文件部署到kubernetes上。
Helm有3个重要概念：
• **helm：**一个命令行客户端工具，主要用于Kubernetes应用chart的创建、打包、发布和管理。
• **Chart：**应用描述，一系列用于描述 k8s 资源相关文件的集合。
• **Release：**基于Chart的部署实体，一个 chart 被 Helm 运行后将会生成对应的一个 release；将在
k8s中创建出真实运行的资源对象。
Helm客户端 使用helm很简单，你只需要下载一个二进制客户端包即可，会通过kubeconfig配置（通常$HOME/.kube/config）来连接Kubernetes。
项目地址：https://github.com/helm/helm
下载Helm客户端：
wget https://get.helm.sh/helm-v3.4.2-linux-amd64.tar.gz tar zxvf helm-v3.4.2-linux-amd64.tar.gz mv linux-amd64/helm /usr/bin/ Helm常用命令 Helm管理应用生命周期： • helm create 创建Chart示例
• helm install 部署
• helm upgrade 更新
• helm rollback 回滚
• helm uninstall 卸载
Helm基本使用：创建Chart示例 创建chart：
# 默认示例中部署的是一个nginx服务 helm create mychart 打包chart：
helm package mychart • charts：目录里存放这个chart依赖的所有子chart。
• Chart.yaml：用于描述这个 Chart的基本信息，包括名字、描述信息以及版本等。
• values.yaml ：用于存储 templates 目录中模板文件中用到变量的值。</description>
    </item>
    
    <item>
      <title>为K8S集群添加nfs类型的sotrageClass</title>
      <link>https://wandong1.github.io/post/%E4%B8%BAk8s%E9%9B%86%E7%BE%A4%E6%B7%BB%E5%8A%A0nfs%E7%B1%BB%E5%9E%8B%E7%9A%84sotrageclass/</link>
      <pubDate>Sun, 15 Aug 2021 08:25:16 +0000</pubDate>
      
      <guid>https://wandong1.github.io/post/%E4%B8%BAk8s%E9%9B%86%E7%BE%A4%E6%B7%BB%E5%8A%A0nfs%E7%B1%BB%E5%9E%8B%E7%9A%84sotrageclass/</guid>
      <description>项目源码介绍 使用nfs-subdir-external-provisioner github地址：https://github.com/kubernetes-sigs/nfs-subdir-external-provisioner 详细介绍：https://artifacthub.io/packages/helm/nfs-subdir-external-provisioner/nfs-subdir-external-provisioner 镜像地址：https://hub.docker.com/r/eipwork/nfs-subdir-external-provisioner/tags
NFS服务端安装 # 安装nfs服务端 yum install nfs-utils -y vim /etc/exports /opt/nfsdata 192.168.0.0/24(rw,no_root_squash,no_all_squash,sync) # 刷新并验证 exportfs -rv # 启动nfs服务，共两个服务 systemctl enable rpcbind --now systemctl enable nfs --now 所有客户端也需要安装nfs-utils，安装完成即可，无需启动服务
yum install nfs-utils -y storageClass插件安装 # 添加helm仓库地址 helm repo add nfs-subdir-external-provisioner https://kubernetes-sigs.github.io/nfs-subdir-external-provisioner/ # 安装第一个 helm install nfs-subdir-external-provisioner nfs-subdir-external-provisioner/nfs-subdir-external-provisioner \ --set nfs.server=192.168.0.13 \ --set nfs.path=/opt/nfsdata \ --set image.repository=eipwork/nfs-subdir-external-provisioner # 安装第二个(可选) helm install second-nfs-subdir-external-provisioner nfs-subdir-external-provisioner/nfs-subdir-external-provisioner \ --set nfs.server=192.168.0.13 \ --set nfs.path=/opt/nfsdata2 \ --set image.</description>
    </item>
    
    <item>
      <title>k8s集群负载均衡keepalived&#43;nginx实现</title>
      <link>https://wandong1.github.io/post/k8s%E9%9B%86%E7%BE%A4%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1keepalived&#43;nginx%E5%AE%9E%E7%8E%B0/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://wandong1.github.io/post/k8s%E9%9B%86%E7%BE%A4%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1keepalived&#43;nginx%E5%AE%9E%E7%8E%B0/</guid>
      <description>使用keepalived实现vip的动态飘逸 keepalived.conf 主
! Configuration File for keepalived global_defs { notification_email { acassen@firewall.loc failover@firewall.loc sysadmin@firewall.loc } notification_email_from Alexandre.Cassen@firewall.loc smtp_server 192.168.200.1 smtp_connect_timeout 30 router_id LVS_DEVEL vrrp_skip_check_adv_addr vrrp_garp_interval 0 vrrp_gna_interval 0 } vrrp_script check_nginx { script &amp;#34;/etc/keepalived/check_nginx.sh&amp;#34; } vrrp_instance VI_1{ state MASTER interface ens34 virtual_router_id 51 priority 100 advert_int 1 authentication { auth_tpye PASS auth_pass 1111 } virtual_ipaddress { 192.168.200.59/24 } track_script { check_nginx } } keepalived.conf 备
! Configuration File for keepalived global_defs { notification_email { acassen@firewall.</description>
    </item>
    
    <item>
      <title>kubeadm安装K8S集群</title>
      <link>https://wandong1.github.io/post/kubeadm%E5%AE%89%E8%A3%85k8s%E9%9B%86%E7%BE%A4/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://wandong1.github.io/post/kubeadm%E5%AE%89%E8%A3%85k8s%E9%9B%86%E7%BE%A4/</guid>
      <description>kubeadm是官方社区推出的一个用于快速部署kubernetes集群的工具。
这个工具能通过两条指令完成一个kubernetes集群的部署：
# 创建一个 Master 节点$ kubeadm init# 将一个 Node 节点加入到当前集群中$ kubeadm join &amp;lt;Master节点的IP和端口 &amp;gt; 1. 安装要求 在开始之前，部署Kubernetes集群机器需要满足以下几个条件：
一台或多台机器，操作系统 CentOS7.x-86_x64 硬件配置：2GB或更多RAM，2个CPU或更多CPU，硬盘30GB或更多 集群中所有机器之间网络互通 可以访问外网，需要拉取镜像 禁止swap分区 2. 准备环境 角色 IP k8s-master 192.168.31.61 k8s-node1 192.168.31.62 k8s-node2 192.168.31.63 关闭防火墙：$ systemctl stop firewalld$ systemctl disable firewalld关闭selinux：$ sed -i &amp;#39;s/enforcing/disabled/&amp;#39; /etc/selinux/config # 永久$ setenforce 0 # 临时关闭swap：$ swapoff -a # 临时$ vim /etc/fstab # 永久设置主机名：$ hostnamectl set-hostname &amp;lt;hostname&amp;gt;在master添加hosts：$ cat &amp;gt;&amp;gt; /etc/hosts &amp;lt;&amp;lt; EOF192.</description>
    </item>
    
    <item>
      <title>kubectl命令补全</title>
      <link>https://wandong1.github.io/post/kubectl%E5%91%BD%E4%BB%A4%E8%A1%A5%E5%85%A8/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://wandong1.github.io/post/kubectl%E5%91%BD%E4%BB%A4%E8%A1%A5%E5%85%A8/</guid>
      <description>一、kubectl命令补全 yum install -y bash-completion #临时生效
source /usr/share/bash-completion/bash_completion #永久生效
source &amp;lt;(kubectl completion bash) echo &amp;#34;source &amp;lt;(kubectl completion bash)&amp;#34; &amp;gt;&amp;gt; ~/.bashrc </description>
    </item>
    
    <item>
      <title>kubectl管理命令概要</title>
      <link>https://wandong1.github.io/post/kubectl%E7%AE%A1%E7%90%86%E5%91%BD%E4%BB%A4%E6%A6%82%E8%A6%81/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://wandong1.github.io/post/kubectl%E7%AE%A1%E7%90%86%E5%91%BD%E4%BB%A4%E6%A6%82%E8%A6%81/</guid>
      <description>kubectl管理命令概要 配置命令补全： http://123.207.224.155:8080/post/60
体验 使用Deployment控制器部署镜像：
kubectl create deployment web --image=lizhenliang/java-demo kubectl get deploy,pods 使用Service将Pod暴露出去：
kubectl expose deployment web --port=80 --target-port=8080 --type=NodePort kubectl get service 访问应用： http://NodeIP:Port # 端口随机生成，通过get svc获取
查看资源并显示标签
kubectl get pods --show-labels 根据查看带有指定标签名字的资源
kubectl get pod -l app=web https://kubernetes.io/docs 官方资料查询
YAML字段记忆技巧 用create命令生成 kubectl create deployment nginx --image=nginx:1.16 -o yaml --dry-run=client &amp;gt; my-deploy.yaml 用get命令导出 kubectl get deploymentnginx-o yaml &amp;gt; my-deploy.yaml Pod容器的字段拼写忘记了 kubectl explain pods.spec.containers kubectl explain deployment </description>
    </item>
    
  </channel>
</rss>
