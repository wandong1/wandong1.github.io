<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>离线安装docker | 万东的云计算运维博客</title><meta name=keywords content="ES"><meta name=description content="离线安装docker"><meta name=author content="Me"><link rel=canonical href=https://www.sulvblog.cn/post/elasticsearch%E5%85%A5%E9%97%A8/><link crossorigin=anonymous href=/assets/css/stylesheet.min.77d563e104d7b39d673d4f21adf63da1ad0244dbcd78291ac2b44dc25b0066e1.css integrity="sha256-d9Vj4QTXs51nPU8hrfY9oa0CRNvNeCkawrRNwlsAZuE=" rel="preload stylesheet" as=style><script defer crossorigin=anonymous src=/assets/js/highlight.min.b95bacdc39e37a332a9f883b1e78be4abc1fdca2bc1f2641f55e3cd3dabd4d61.js integrity="sha256-uVus3DnjejMqn4g7Hni+Srwf3KK8HyZB9V4809q9TWE=" onload=hljs.initHighlightingOnLoad()></script>
<link rel=icon href=https://www.sulvblog.cn/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=16x16 href=https://www.sulvblog.cn/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=32x32 href=https://www.sulvblog.cn/%3Clink%20/%20abs%20url%3E><link rel=apple-touch-icon href=https://www.sulvblog.cn/%3Clink%20/%20abs%20url%3E><link rel=mask-icon href=https://www.sulvblog.cn/%3Clink%20/%20abs%20url%3E><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><noscript><style>#theme-toggle,.top-link{display:none}</style></noscript><script type=application/javascript>var doNotTrack=!1;doNotTrack||(function(e,t,n,s,o,i,a){e.GoogleAnalyticsObject=o,e[o]=e[o]||function(){(e[o].q=e[o].q||[]).push(arguments)},e[o].l=1*new Date,i=t.createElement(n),a=t.getElementsByTagName(n)[0],i.async=1,i.src=s,a.parentNode.insertBefore(i,a)}(window,document,"script","https://www.google-analytics.com/analytics.js","ga"),ga("create","UA-123-45","auto"),ga("send","pageview"))</script><meta property="og:title" content="离线安装docker"><meta property="og:description" content="离线安装docker"><meta property="og:type" content="article"><meta property="og:url" content="https://www.sulvblog.cn/post/elasticsearch%E5%85%A5%E9%97%A8/"><meta property="og:image" content="https://www.sulvblog.cn/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta property="article:section" content="post"><meta property="article:published_time" content="2021-08-15T08:15:16+00:00"><meta property="article:modified_time" content="2021-08-15T08:15:16+00:00"><meta property="og:site_name" content="ExampleSite"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://www.sulvblog.cn/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta name=twitter:title content="离线安装docker"><meta name=twitter:description content="离线安装docker"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":2,"name":"Posts","item":"https://www.sulvblog.cn/post/"},{"@type":"ListItem","position":3,"name":"离线安装docker","item":"https://www.sulvblog.cn/post/elasticsearch%E5%85%A5%E9%97%A8/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"离线安装docker","name":"离线安装docker","description":"离线安装docker","keywords":["ES"],"articleBody":"ES版本： v7.17.3\nES环境搭建视频：https://pan.baidu.com/s/1PsTNbpDy–M-pvFWb3aehQ?pwd=nwxl\nElasticSearch快速入门实战 note 链接：http://note.youdao.com/noteshare?id=d5d5718ae542f274ba0fda4284a53231\u0026sub=68E590656C7A48858C7F6997D4A1511A\n全文检索 数据分类：\n结构化数据： 固定格式，有限长度 比如mysql存的数据 非结构化数据：不定长，无固定格式 比如邮件，word文档，日志 半结构化数据： 前两者结合 比如xml，html 搜索分类：\n结构化数据搜索： 使用关系型数据库\n非结构化数据搜索\n顺序扫描 全文检索 设想一个关于搜索的场景，假设我们要搜索一首诗句内容中带“前”字的古诗\nname content author 静夜思 床前明月光,疑是地上霜。举头望明月，低头思故乡。 李白 望庐山瀑布 日照香炉生紫烟，遥看瀑布挂前川。飞流直下三千尺,疑是银河落九天。 李白 … … … 思考：用传统关系型数据库和ES 实现会有什么差别？\n如果用像 MySQL 这样的 RDBMS 来存储古诗的话，我们应该会去使用这样的 SQL 去查询\n​ select name from poems where content like “%前%”\n这种我们称为顺序扫描法，需要遍历所有的记录进行匹配。不但效率低，而且不符合我们搜索时的期望，比如我们在搜索“ABCD\"这样的关键词时，通常还希望看到\"A\",“AB”,“CD”,“ABC”的搜索结果。\n什么是全文检索 全文检索是指：\n通过一个程序扫描文本中的每一个单词，针对单词建立索引，并保存该单词在文本中的位置、以及出现的次数 用户查询时，通过之前建立好的索引来查询，将索引中单词对应的文本位置、出现的次数返回给用户，因为有了具体文本的位置，所以就可以将具体内容读取出来了 ​ 搜索原理简单概括的话可以分为这么几步：\n内容爬取，停顿词过滤比如一些无用的像\"的\"，“了”之类的语气词/连接词 内容分词，提取关键词 根据关键词建立倒排索引 用户输入关键词进行搜索 倒排索引 索引就类似于目录，平时我们使用的都是索引，都是通过主键定位到某条数据，那么倒排索引呢，刚好相反，数据对应到主键。\n​ 这里以一个博客文章的内容为例:\n正排索引（正向索引）\n文章ID 文章标题 文章内容 1 浅析JAVA设计模式 JAVA设计模式是每一个JAVA程序员都应该掌握的进阶知识 2 JAVA多线程设计模式 JAVA多线程与设计模式结合 倒排索引（反向索引）\n假如，我们有一个站内搜索的功能，通过某个关键词来搜索相关的文章，那么这个关键词可能出现在标题中，也可能出现在文章内容中，那我们将会在创建或修改文章的时候，建立一个关键词与文章的对应关系表，这种，我们可以称之为倒排索引。\nlike %java设计模式% java 设计模式\n关键词 文章ID JAVA 1,2 设计模式 1,2 多线程 2 简单理解，正向索引是通过key找value，反向索引则是通过value找key。ES底层在检索时底层使用的就是倒排索引。\nElasticSearch简介 ElasticSearch是什么 ElasticSearch（简称ES）是一个分布式、RESTful 风格的搜索和数据分析引擎，是用Java开发并且是当前最流行的开源的企业级搜索引擎，能够达到近实时搜索，稳定，可靠，快速，安装使用方便。\n客户端支持Java、.NET（C#）、PHP、Python、Ruby等多种语言。\n官方网站: https://www.elastic.co/\n**下载地址：**https://www.elastic.co/cn/downloads/past-releases#elasticsearch\n搜索引擎排名：\n​ 参考网站：https://db-engines.com/en/ranking/search+engine\n起源——Lucene 基于Java语言开发的搜索引擎库类\n创建于1999年，2005年成为Apache 顶级开源项目\nLucene具有高性能、易扩展的优点\nLucene的局限性︰\n只能基于Java语言开发 类库的接口学习曲线陡峭 原生并不支持水平扩展 Elasticsearch的诞生 Elasticsearch是构建在Apache Lucene之上的开源分布式搜索引擎。\n2004年 Shay Banon 基于Lucene开发了Compass\n2010年 Shay Banon重写了Compass，取名Elasticsearch\n支持分布式，可水平扩展 降低全文检索的学习曲线，可以被任何编程语言调用 ​ Elasticsearch 与 Lucene 核心库竞争的优势在于：\n完美封装了 Lucene 核心库，设计了友好的 Restful-API，开发者无需过多关注底层机制，直接开箱即用。 分片与副本机制，直接解决了集群下性能与高可用问题。 ES Server进程 3节点 raft (奇数节点)\n数据分片 -》lucene实例 分片和副本数 1个ES节点可以有多个lucene实例。也可以指定一个索引的多个分片\n​ ElasticSearch版本特性 5.x新特性\nLucene 6.x， 性能提升，默认打分机制从TF-IDF改为BM 25\n支持Ingest节点/ Painless Scripting / Completion suggested支持/原生的Java REST客户端\nType标记成deprecated， 支持了Keyword的类型\n性能优化\n内部引擎移除了避免同一文档并发更新的竞争锁，带来15% - 20%的性能提升 Instant aggregation,支持分片，上聚合的缓存 新增了Profile API 6.x新特性\nLucene 7.x\n新功能\n跨集群复制(CCR) 索引生命周期管理 SQL的支持 更友好的的升级及数据迁移\n在主要版本之间的迁移更为简化，体验升级 全新的基于操作的数据复制框架，可加快恢复数据 性能优化\n有效存储稀疏字段的新方法，降低了存储成本 在索引时进行排序，可加快排序的查询性能 7.x新特性\nLucene 8.0\n重大改进-正式废除单个索引下多Type的支持\n7.1开始，Security 功能免费使用\nECK - Elasticseach Operator on Kubernetes\n新功能\nNew Cluster coordination Feature——Complete High Level REST Client Script Score Query 性能优化\n默认的Primary Shard数从5改为1,避免Over Sharding 性能优化， 更快的Top K 8.x新特性\nRest API相比较7.x而言做了比较大的改动（比如彻底删除_type） 默认开启安全配置 存储空间优化：对倒排文件使用新的编码集，对于keyword、match_only_text、text类型字段有效，有3.5%的空间优化提升，对于新建索引和segment自动生效。 优化geo_point，geo_shape类型的索引（写入）效率：15%的提升。 技术预览版KNN API发布，（K邻近算法），跟推荐系统、自然语言排名相关。 https://www.elastic.co/guide/en/elastic-stack/current/elasticsearch-breaking-changes.html ElasticSearch vs Solr Solr 是第一个基于 Lucene 核心库功能完备的搜索引擎产品，诞生远早于 Elasticsearch。\n当单纯的对已有数据进行搜索时，Solr更快。当实时建立索引时, Solr会产生io阻塞，查询性能较差, Elasticsearch具有明显的优势。\n​ ​ 大型互联网公司，实际生产环境测试，将搜索引擎从Solr转到 Elasticsearch以后的平均查询速度有了50倍的提升。\n​ 总结：\nSolr 利用 Zookeeper 进行分布式管理，而Elasticsearch 自身带有分布式协调管理功能。 Solr 支持更多格式的数据，比如JSON、XML、CSV，而 Elasticsearch 仅支持json文件格式。 Solr 在传统的搜索应用中表现好于 Elasticsearch，但在处理实时搜索应用时效率明显低于 Elasticsearch。 Solr 是传统搜索应用的有力解决方案，但 Elasticsearch更适用于新兴的实时搜索应用。 Elastic Stack介绍 在Elastic Stack之前我们听说过ELK，ELK分别是Elasticsearch，Logstash，Kibana这三款软件在一起的简称，在发展的过程中又有新的成员Beats的加入，就形成了Elastic Stack。\n​ Elastic Stack生态圈\n在Elastic Stack生态圈中Elasticsearch作为数据存储和搜索，是生态圈的基石，Kibana在上层提供用户一个可视化及操作的界面，Logstash和Beat可以对数据进行收集。在上图的右侧X-Pack部分则是Elastic公司提供的商业项目。\n指标分析/日志分析：\n​ ElasticSearch应用场景 站内搜索 日志管理与分析 大数据分析 应用性能监控 机器学习 国内现在有大量的公司都在使用 Elasticsearch，包括携程、滴滴、今日头条、饿了么、360安全、小米、vivo等诸多知名公司。除了搜索之外，结合Kibana、Logstash、Beats，Elastic Stack还被广泛运用在大数据近实时分析领域，包括日志分析、指标监控、信息安全等多个领域。它可以帮助你探索海量结构化、非结构化数据，按需创建可视化报表，对监控数据设置报警阈值，甚至通过使用机器学习技术，自动识别异常状况。\n通用数据处理流程：\n​ ElasticSearch快速开始 安装JDK\n1、yum install -y java-1.8.0-openjdk* # 或者 mkdir /opt/jdk;tar -xvzf jdk-8u333-linux-x64.tar.gz -C /opt/jdk/; mv /opt/jdk/jdk1.8.0_333/ /opt/jdk/jdk1.8 ; cat \u003c\u003e /etc/profile JAVA_HOME=/opt/jdk/jdk1.8 CLASSPATH=$JAVA_HOME/lib/ PATH=$PATH:$JAVA_HOME/bin export PATH JAVA_HOME CLASSPATH EOF source /etc/profile ElasticSearch安装运行 环境准备 运行Elasticsearch，需安装并配置JDK\n设置$JAVA_HOME 各个版本对Java的依赖 https://www.elastic.co/support/matrix#matrix_jvm\nElasticsearch 5需要Java 8以上的版本 Elasticsearch 从6.5开始支持Java 11 7.0开始，内置了Java环境 ES比较耗内存，建议虚拟机4G或以上内存，jvm1g以上的内存分配\n可以参考es的环境文件elasticsearch-env.bat\n​ ES的jdk环境生效的优先级配置ES_JAVA_HOME\u003eJAVA_HOME\u003eES_HOME\n下载并解压ElasticSearch 下载地址： https://www.elastic.co/cn/downloads/past-releases#elasticsearch\n选择版本：7.17.3\n​ ElasticSearch文件目录结构\n目录 描述 bin 脚本文件，包括启动elasticsearch，安装插件，运行统计数据等 config 配置文件目录，如elasticsearch配置、角色配置、jvm配置等。 jdk java运行环境 data 默认的数据存放目录，包含节点、分片、索引、文档的所有数据，生产环境需要修改。 lib elasticsearch依赖的Java类库 logs 默认的日志文件存储路径，生产环境需要修改。 modules 包含所有的Elasticsearch模块，如Cluster、Discovery、Indices等。 plugins 已安装插件目录 主配置文件elasticsearch.yml\ncluster.name 当前节点所属集群名称，多个节点如果要组成同一个集群，那么集群名称一定要配置成相同。默认值elasticsearch，生产环境建议根据ES集群的使用目的修改成合适的名字。\nnode.name 当前节点名称，默认值当前节点部署所在机器的主机名，所以如果一台机器上要起多个ES节点的话，需要通过配置该属性明确指定不同的节点名称。\npath.data 配置数据存储目录，比如索引数据等，默认值 $ES_HOME/data，生产环境下强烈建议部署到另外的安全目录，防止ES升级导致数据被误删除。\npath.logs 配置日志存储目录，比如运行日志和集群健康信息等，默认值 $ES_HOME/logs，生产环境下强烈建议部署到另外的安全目录，防止ES升级导致数据被误删除。\nbootstrap.memory_lock 配置ES启动时是否进行内存锁定检查，默认值true。\nES对于内存的需求比较大，一般生产环境建议配置大内存，如果内存不足，容易导致内存交换到磁盘，严重影响ES的性能。所以默认启动时进行相应大小内存的锁定，如果无法锁定则会启动失败。\n非生产环境可能机器内存本身就很小，能够供给ES使用的就更小，如果该参数配置为true的话很可能导致无法锁定内存以致ES无法成功启动，此时可以修改为false。\nnetwork.host 配置能够访问当前节点的主机，默认值为当前节点所在机器的本机回环地址127.0.0.1 和[::1]，这就导致默认情况下只能通过当前节点所在主机访问当前节点。可以配置为 0.0.0.0 ，表示所有主机均可访问。\nhttp.port 配置当前ES节点对外提供服务的http端口，默认值 9200\ndiscovery.seed_hosts 配置参与集群节点发现过程的主机列表，说白一点就是集群中所有节点所在的主机列表，可以是具体的IP地址，也可以是可解析的域名。\ncluster.initial_master_nodes 配置ES集群初始化时参与master选举的节点名称列表，必须与node.name配置的一致。ES集群首次构建完成后，应该将集群中所有节点的配置文件中的cluster.initial_master_nodes配置项移除，重启集群或者将新节点加入某个已存在的集群时切记不要设置该配置项。\n​ #ES开启远程访问 network.host: 0.0.0.0\n修改JVM配置 修改config/jvm.options配置文件，调整jvm堆内存大小\n​ vim jvm.options -Xms4g -Xmx4g\n配置的建议\nXms和Xms设置成—样 Xmx不要超过机器内存的50% 不要超过30GB - https://www.elastic.co/cn/blog/a-heap-of-trouble 启动ElasticSearch服务 Windows\n直接运行elasticsearch.bat\nLinux（centos7）\nES不允许使用root账号启动服务，如果你当前账号是root，则需要创建一个专有账户\n​ #非root用户 bin/elasticsearch # -d 后台启动 bin/elasticsearch -d\n​ 注意：es默认不能用root用户启动，生产环境建议为elasticsearch创建用户。\n​ #为elaticsearch创建用户并赋予相应权限 adduser es passwd es chown -R es:es elasticsearch-17.3\n运行http://localhost:9200/\n​ 如果ES服务启动异常，会有提示：\n​ 启动ES服务常见错误解决方案\n[1]: max file descriptors [4096] for elasticsearch process is too low, increase to at least [65536]\nES因为需要大量的创建索引文件，需要大量的打开系统的文件，所以我们需要解除linux系统当中打开文件最大数目的限制，不然ES启动就会抛错\n#切换到root用户 vim /etc/security/limits.conf 末尾添加如下配置： *\tsoft nofile 65536 * hard nofile 65536 * soft nproc 4096 *\thard nproc 4096 ​\n[2]: max number of threads [1024] for user [es] is too low, increase to at least [4096]\n无法创建本地线程问题,用户最大可创建线程数太小\nvim /etc/security/limits.d/20-nproc.conf 改为如下配置： * soft nproc 4096 [3]: max virtual memory areas vm.max_map_count [65530] is too low, increase to at least [262144]\n最大虚拟内存太小,调大系统的虚拟内存\n​\nvim /etc/sysctl.conf 追加以下内容： vm.max_map_count=262144 保存退出之后执行如下命令： sysctl -p [4]: the default discovery settings are unsuitable for production use; at least one of [discovery.seed_hosts, discovery.seed_providers, cluster.initial_master_nodes] must be configured\n缺少默认配置，至少需要配置discovery.seed_hosts/discovery.seed_providers/cluster.initial_master_nodes中的一个参数.\ndiscovery.seed_hosts: 集群主机列表 discovery.seed_providers: 基于配置文件配置集群主机列表 cluster.initial_master_nodes: 启动时初始化的参与选主的node，生产环境必填 ​\nvim config/elasticsearch.yml #添加配置 discovery.seed_hosts: [\"127.0.0.1\"] cluster.initial_master_nodes: [\"node-1\"] #或者 单节点（集群单节点） discovery.type: single-node 客户端Kibana安装 Kibana是一个开源分析和可视化平台，旨在与Elasticsearch协同工作。\n1）下载并解压缩Kibana\n下载地址：https://www.elastic.co/cn/downloads/past-releases#kibana\n选择版本：7.17.3\n​ 2）修改Kibana.yml\nvim config/kibana.yml server.port: 5601 server.host: \"0.0.0.0\" #服务器ip elasticsearch.hosts: [\"http://localhost:9200\"] #elasticsearch的访问地址 i18n.locale: \"zh-CN\" #Kibana汉化 3）运行Kibana\n# 注意：kibana也需要非root用户启动 bin/kibana # 后台启动 nohup bin/kibana \u0026 # 或者 sudo -H -u es /bin/bash -c \"nohup bin/kibana \u0026\" ​\n访问Kibana: http://localhost:5601/\n​ cat API\n/_cat/allocation #查看单节点的shard分配整体情况 /_cat/shards #查看各shard的详细情况 /_cat/shards/{index} #查看指定分片的详细情况 /_cat/master #查看master节点信息 /_cat/nodes #查看所有节点信息 /_cat/indices #查看集群中所有index的详细信息 /_cat/indices/{index} #查看集群中指定index的详细信息 /_cat/segments #查看各index的segment详细信息,包括segment名, 所属shard, 内存(磁盘)占用大小, 是否刷盘 /_cat/segments/{index}#查看指定index的segment详细信息 /_cat/count #查看当前集群的doc数量 /_cat/count/{index} #查看指定索引的doc数量 /_cat/recovery #查看集群内每个shard的recovery过程.调整replica。 /_cat/recovery/{index}#查看指定索引shard的recovery过程 /_cat/health #查看集群当前状态：红、黄、绿 /_cat/pending_tasks #查看当前集群的pending task /_cat/aliases #查看集群中所有alias信息,路由配置等 /_cat/aliases/{alias} #查看指定索引的alias信息 /_cat/thread_pool #查看集群各节点内部不同类型的threadpool的统计信息, /_cat/plugins #查看集群各个节点上的plugin信息 /_cat/fielddata #查看当前集群各个节点的fielddata内存使用情况 /_cat/fielddata/{fields} #查看指定field的内存使用情况,里面传field属性对应的值 /_cat/nodeattrs #查看单节点的自定义属性 /_cat/repositories #输出集群中注册快照存储库 /_cat/templates #输出当前正在存在的模板信息 Elasticsearch安装分词插件 Elasticsearch提供插件机制对系统进行扩展\n以安装analysis-icu这个分词插件为例\n在线安装\n​\n#查看已安装插件 bin/elasticsearch-plugin list #安装插件 bin/elasticsearch-plugin install analysis-icu #删除插件 bin/elasticsearch-plugin remove analysis-icu 注意：安装和删除完插件后，需要重启ES服务才能生效。\n测试分词效果\n​ POST _analyze { “analyzer”:“icu_analyzer”, “text”:“中华人民共和国” }\n​ 离线安装\n本地下载相应的插件，解压，然后手动上传到elasticsearch的plugins目录，然后重启ES实例就可以了。\n比如ik中文分词插件：https://github.com/medcl/elasticsearch-analysis-ik\nelasticsearch-analysis-ik-7.15.2.zip\n必须对应es版本\n测试分词效果\n#ES的默认分词设置是standard，会单字拆分 POST _analyze { \"analyzer\":\"standard\", \"text\":\"中华人民共和国\" } #ik_smart:会做最粗粒度的拆 POST _analyze { \"analyzer\": \"ik_smart\", \"text\": \"中华人民共和国\" } #ik_max_word:会将文本做最细粒度的拆分 POST _analyze { \"analyzer\":\"ik_max_word\", \"text\":\"中华人民共和国\" } ​\n创建索引时可以指定IK分词器作为默认分词器\nPUT /es_db { \"settings\" : { \"index\" : { \"analysis.analyzer.default.type\": \"ik_max_word\" } } } ​ ElasticSearch基本概念 关系型数据库 VS ElasticSearch 在7.0之前，一个 Index可以设置多个Types\n目前Type已经被Deprecated，7.0开始，一个索引只能创建一个Type - “_doc”\n传统关系型数据库和Elasticsearch的区别:\nElasticsearch- Schemaless /相关性/高性能全文检索 RDMS —事务性/ Join ​ 索引（Index） 一个索引就是一个拥有几分相似特征的文档的集合。比如说，可以有一个客户数据的索引，另一个产品目录的索引，还有一个订单数据的索引。\n一个索引由一个名字来标识（必须全部是小写字母的），并且当我们要对对应于这个索引中的文档进行索引、搜索、更新和删除的时候，都要使用到这个名字。\n​ 文档（Document） Elasticsearch是面向文档的，文档是所有可搜索数据的最小单位。\n日志文件中的日志项 一本电影的具体信息/一张唱片的详细信息 MP3播放器里的一首歌/一篇PDF文档中的具体内容 文档会被序列化成JSON格式，保存在Elasticsearch中\nJSON对象由字段组成 每个字段都有对应的字段类型(字符串/数值/布尔/日期/二进制/范围类型) 每个文档都有一个Unique ID\n可以自己指定ID或者通过Elasticsearch自动生成 一篇文档包含了一系列字段，类似数据库表中的一条记录\nJSON文档，格式灵活，不需要预先定义格式\n字段的类型可以指定或者通过Elasticsearch自动推算 支持数组/支持嵌套 文档元数据\n​ 元数据，用于标注文档的相关信息：\n_index：文档所属的索引名 _type：文档所属的类型名 _id：文档唯—ld _source: 文档的原始Json数据 _version: 文档的版本号，修改删除操作_version都会自增1 _seq_no: 和_version一样，一旦数据发生更改，数据也一直是累计的。Shard级别严格递增，保证后写入的Doc的_seq_no大于先写入的Doc的_seq_no。 _primary_term: _primary_term主要是用来恢复数据时处理当多个文档的_seq_no一样时的冲突，避免Primary Shard上的写入被覆盖。每当Primary Shard发生重新分配时，比如重启，Primary选举等，_primary_term会递增1。 ElasticSearch索引操作 https://www.elastic.co/guide/en/elasticsearch/reference/7.17/index.html\n创建索引 索引命名必须小写，不能以下划线开头\n格式: PUT /索引名称\n​ #创建索引 PUT /es_db #创建索引时可以设置分片数和副本数 PUT /es_db { “settings” : { “number_of_shards” : 3, “number_of_replicas” : 2 } } #修改索引配置 PUT /es_db/_settings { “index” : { “number_of_replicas” : 1 } }\n​ 查询索引 格式: GET /索引名称\n​ #查询索引 GET /es_db #es_db是否存在 HEAD /es_db\n​ ​\n删除索引 格式: DELETE /索引名称\n​ DELETE /es_db\nElasticSearch文档操作 示例数据\nPUT /es_db { \"settings\" : { \"index\" : { \"analysis.analyzer.default.type\": \"ik_max_word\" } } } PUT /es_db/_doc/1 { \"name\": \"张三\", \"sex\": 1, \"age\": 25, \"address\": \"广州天河公园\", \"remark\": \"java developer\" } PUT /es_db/_doc/2 { \"name\": \"李四\", \"sex\": 1, \"age\": 28, \"address\": \"广州荔湾大厦\", \"remark\": \"java assistant\" } PUT /es_db/_doc/3 { \"name\": \"王五\", \"sex\": 0, \"age\": 26, \"address\": \"广州白云山公园\", \"remark\": \"php developer\" } PUT /es_db/_doc/4 { \"name\": \"赵六\", \"sex\": 0, \"age\": 22, \"address\": \"长沙橘子洲\", \"remark\": \"python assistant\" } PUT /es_db/_doc/5 { \"name\": \"张龙\", \"sex\": 0, \"age\": 19, \"address\": \"长沙麓谷企业广场\", \"remark\": \"java architect assistant\" }\tPUT /es_db/_doc/6 { \"name\": \"赵虎\", \"sex\": 1, \"age\": 32, \"address\": \"长沙麓谷兴工国际产业园\", \"remark\": \"java architect\" }\t​\n添加（索引）文档 格式: [PUT | POST] /索引名称/[_doc | _create ]/id ​\n# 创建文档,指定id # 如果id不存在，创建新的文档，否则先删除现有文档，再创建新的文档，版本会增加 PUT /es_db/_doc/1 { \"name\": \"张三\", \"sex\": 1, \"age\": 25, \"address\": \"广州天河公园\", \"remark\": \"java developer\" }\t#创建文档，ES生成id POST /es_db/_doc { \"name\": \"张三\", \"sex\": 1, \"age\": 25, \"address\": \"广州天河公园\", \"remark\": \"java developer\" } ​\n​ 注意:POST和PUT都能起到创建/更新的作用，PUT需要对一个具体的资源进行操作也就是要确定id才能进行更新/创建，而POST是可以针对整个资源集合进行操作的，如果不写id就由ES生成一个唯一id进行创建新文档，如果填了id那就针对这个id的文档进行创建/更新\n​ Create -如果ID已经存在，会失败\n​ 修改文档 全量更新，整个json都会替换，格式: [PUT | POST] /索引名称/_doc/id 如果文档存在，现有文档会被删除，新的文档会被索引\n​\n# 全量更新，替换整个json PUT /es_db/_doc/1/ { \"name\": \"张三\", \"sex\": 1, \"age\": 25 } #查询文档 GET /es_db/_doc/1 ​\n​ 使用_update部分更新，格式: POST /索引名称/_update/id update不会删除原来的文档，而是实现真正的数据更新\n​\n# 部分更新：在原有文档上更新 # Update -文档必须已经存在，更新只会对相应字段做增量修改 POST /es_db/_update/1 { \"doc\": { \"age\": 28 } } #查询文档 GET /es_db/_doc/1 ​\n​ 使用 _update_by_query 更新文档 ​\nPOST /es_db/_update_by_query { \"query\": { \"match\": { \"_id\": 1 } }, \"script\": { \"source\": \"ctx._source.age = 30\" } } ​\n​ 并发场景下修改文档 _seq_no和_primary_term是对_version的优化，7.X版本的ES默认使用这种方式控制版本，所以当在高并发环境下使用乐观锁机制修改文档时，要带上当前文档的_seq_no和_primary_term进行更新：\n​\nPOST /es_db/_doc/2?if_seq_no=21\u0026if_primary_term=6 { \"name\": \"李四xxx\" } 如果版本号不对，会抛出版本冲突异常，如下图：\n​ 查询文档 根据id查询文档，格式: GET /索引名称/_doc/id GET /es_db/_doc/1 条件查询 _search，格式： /索引名称/_doc/_search # 查询前10条文档 GET /es_db/_doc/_search ​\nES Search API提供了两种条件查询搜索方式：\nREST风格的请求URI，直接将参数带过去 封装到request body中，这种方式可以定义更加易读的JSON格式 ​\n#通过URI搜索，使用“q”指定查询字符串，“query string syntax” KV键值对 #条件查询, 如要查询age等于28岁的 _search?q=*:*** GET /es_db/_doc/_search?q=age:28 #范围查询, 如要查询age在25至26岁之间的 _search?q=***[** TO **] 注意: TO 必须为大写 GET /es_db/_doc/_search?q=age[25 TO 26] #查询年龄小于等于28岁的 :\u003c= GET /es_db/_doc/_search?q=age:\u003c=28 #查询年龄大于28前的 :\u003e GET /es_db/_doc/_search?q=age:\u003e28 #分页查询 from=*\u0026size=* GET /es_db/_doc/_search?q=age[25 TO 26]\u0026from=0\u0026size=1 #对查询结果只输出某些字段 _source=字段,字段 GET /es_db/_doc/_search?_source=name,age #对查询结果排序 sort=字段:desc/asc GET /es_db/_doc/_search?sort=age:desc 通过请求体的搜索方式会在后面课程详细讲解（DSL）\n​\nGET /es_db/_search { \"query\": { \"match\": { \"address\": \"广州白云\" } } } 删除文档 格式: DELETE /索引名称/_doc/id\nDELETE /es_db/_doc/1 ElasticSearch文档批量操作 批量操作可以减少网络连接所产生的开销，提升性能\n支持在一次API调用中，对不同的索引进行操作 可以在URI中指定Index，也可以在请求的Payload中进行 操作中单条操作失败，并不会影响其他操作 返回结果包括了每一条操作执行的结果 批量写入 批量对文档进行写操作是通过_bulk的API来实现的\n请求方式：POST\n请求地址：_bulk\n请求参数：通过_bulk操作文档，一般至少有两行参数(或偶数行参数)\n第一行参数为指定操作的类型及操作的对象(index,type和id) 第二行参数才是操作的数据 参数类似于：\n{\"actionName\":{\"_index\":\"indexName\", \"_type\":\"typeName\",\"_id\":\"id\"}} {\"field1\":\"value1\", \"field2\":\"value2\"} actionName：表示操作类型，主要有create,index,delete和update 批量创建文档create\nPOST _bulk {\"create\":{\"_index\":\"article\", \"_type\":\"_doc\", \"_id\":3}} {\"id\":3,\"title\":\"fox老师\",\"content\":\"fox老师666\",\"tags\":[\"java\", \"面向对象\"],\"create_time\":1554015482530} {\"create\":{\"_index\":\"article\", \"_type\":\"_doc\", \"_id\":4}} {\"id\":4,\"title\":\"mark老师\",\"content\":\"mark老师NB\",\"tags\":[\"java\", \"面向对象\"],\"create_time\":1554015482530} 普通创建或全量替换index\nPOST _bulk {\"index\":{\"_index\":\"article\", \"_type\":\"_doc\", \"_id\":3}} {\"id\":3,\"title\":\"图灵徐庶老师\",\"content\":\"图灵学院徐庶老师666\",\"tags\":[\"java\", \"面向对象\"],\"create_time\":1554015482530} {\"index\":{\"_index\":\"article\", \"_type\":\"_doc\", \"_id\":4}} {\"id\":4,\"title\":\"图灵诸葛老师\",\"content\":\"图灵学院诸葛老师NB\",\"tags\":[\"java\", \"面向对象\"],\"create_time\":1554015482530} 如果原文档不存在，则是创建 如果原文档存在，则是替换(全量修改原文档) 批量删除delete\n​\nPOST _bulk {\"delete\":{\"_index\":\"article\", \"_type\":\"_doc\", \"_id\":3}} {\"delete\":{\"_index\":\"article\", \"_type\":\"_doc\", \"_id\":4}} 批量修改update\n​\nPOST _bulk {\"update\":{\"_index\":\"article\", \"_type\":\"_doc\", \"_id\":3}} {\"doc\":{\"title\":\"ES大法必修内功\"}} {\"update\":{\"_index\":\"article\", \"_type\":\"_doc\", \"_id\":4}} {\"doc\":{\"create_time\":1554018421008}} 组合应用\n​\nPOST _bulk {\"create\":{\"_index\":\"article\", \"_type\":\"_doc\", \"_id\":3}} {\"id\":3,\"title\":\"fox老师\",\"content\":\"fox老师666\",\"tags\":[\"java\", \"面向对象\"],\"create_time\":1554015482530} {\"delete\":{\"_index\":\"article\", \"_type\":\"_doc\", \"_id\":3}} {\"update\":{\"_index\":\"article\", \"_type\":\"_doc\", \"_id\":4}} {\"doc\":{\"create_time\":1554018421008}} 批量读取 es的批量查询可以使用mget和msearch两种。其中mget是需要我们知道它的id，可以指定不同的index，也可以指定返回值source。msearch可以通过字段查询来进行一个批量的查找。\n_mget\n​\n#可以通过ID批量获取不同index和type的数据 GET _mget { \"docs\": [ { \"_index\": \"es_db\", \"_id\": 1 }, { \"_index\": \"article\", \"_id\": 4 } ] } #可以通过ID批量获取es_db的数据 GET /es_db/_mget { \"docs\": [ { \"_id\": 1 }, { \"_id\": 4 } ] } #简化后 GET /es_db/_mget { \"ids\":[\"1\",\"2\"] } ​\n​ _msearch\n在_msearch中，请求格式和bulk类似。查询一条数据需要两个对象，第一个设置index和type，第二个设置查询语句。查询语句和search相同。如果只是查询一个index，我们可以在url中带上index，这样，如果查该index可以直接用空对象表示。\n​\nGET /es_db/_msearch {} {\"query\" : {\"match_all\" : {}}, \"from\" : 0, \"size\" : 2} {\"index\" : \"article\"} {\"query\" : {\"match_all\" : {}}} ​ Logstash与FileBeat详解以及ELK整合 链接：http://note.youdao.com/noteshare?id=cd88d72a1c76d18efcf7fe767e8c2d20\u0026sub=D7819084A43243FFA52E8A8741795414\n背景 日志管理的挑战：\n关注点很多，任何一个点都有可能引起问题 日志分散在很多机器，出了问题时，才发现日志被删了 很多运维人员是消防员，哪里有问题去哪里 ​ 集中化日志管理思路：\n日志收集 ——》格式化分析 ——》检索和可视化 ——》 风险告警\nELK架构 ELK架构分为两种，一种是经典的ELK，另外一种是加上消息队列（Redis或Kafka或RabbitMQ）和Nginx结构。\n经典的ELK 经典的ELK主要是由Filebeat + Logstash + Elasticsearch + Kibana组成，如下图：（早期的ELK只有Logstash + Elasticsearch + Kibana）\n​ 此架构主要适用于数据量小的开发环境，存在数据丢失的危险。\n整合消息队列+Nginx架构 这种架构，主要加上了Redis或Kafka或RabbitMQ做消息队列，保证了消息的不丢失。\n​ 此种架构，主要用在生产环境，可以处理大数据量，并且不会丢失数据。\n什么是Logstash Logstash 是免费且开放的服务器端数据处理管道，能够从多个来源采集数据，转换数据，然后将数据发送到您最喜欢的存储库中。\nhttps://www.elastic.co/cn/logstash/\n应用：ETL工具 / 数据采集处理引擎\n​ Logstash核心概念 Pipeline\n包含了input—filter-output三个阶段的处理流程 插件生命周期管理 队列管理 Logstash Event\n数据在内部流转时的具体表现形式。数据在input 阶段被转换为Event，在 output被转化成目标格式数据 Event 其实是一个Java Object，在配置文件中，对Event 的属性进行增删改查 Codec (Code / Decode)\n将原始数据decode成Event;将Event encode成目标数据\n​ Logstash数据传输原理 数据采集与输入：Logstash支持各种输入选择，能够以连续的流式传输方式，轻松地从日志、指标、Web应用以及数据存储中采集数据。 实时解析和数据转换：通过Logstash过滤器解析各个事件，识别已命名的字段来构建结构，并将它们转换成通用格式，最终将数据从源端传输到存储库中。 存储与数据导出：Logstash提供多种输出选择，可以将数据发送到指定的地方。 Logstash通过管道完成数据的采集与处理，管道配置中包含input、output和filter（可选）插件，input和output用来配置输入和输出数据源、filter用来对数据进行过滤或预处理。\n​ Logstash配置文件结构 参考：https://www.elastic.co/guide/en/logstash/7.17/configuration.html\nLogstash的管道配置文件对每种类型的插件都提供了一个单独的配置部分，用于处理管道事件。\ninput { stdin { } } filter { grok { match =\u003e { \"message\" =\u003e \"%{COMBINEDAPACHELOG}\" } } date { match =\u003e [ \"timestamp\" , \"dd/MMM/yyyy:HH:mm:ss Z\" ] } } output { elasticsearch { hosts =\u003e [\"localhost:9200\"]} stdout { codec =\u003e rubydebug } } 每个配置部分可以包含一个或多个插件。例如，指定多个filter插件，Logstash会按照它们在配置文件中出现的顺序进行处理。\n#运行 bin/logstash -f logstash-demo.conf Input Plugins\nhttps://www.elastic.co/guide/en/logstash/7.17/input-plugins.html\n一个 Pipeline可以有多个input插件\nStdin / File\nBeats / Log4J /Elasticsearch / JDBC / Kafka /Rabbitmq /Redis\nJMX/ HTTP / Websocket / UDP / TCP\nGoogle Cloud Storage / S3\nGithub / Twitter\nOutput Plugins\nhttps://www.elastic.co/guide/en/logstash/7.17/output-plugins.html\n将Event发送到特定的目的地，是 Pipeline 的最后一个阶段。\n常见 Output Plugins：\nElasticsearch Email / Pageduty Influxdb / Kafka / Mongodb / Opentsdb / Zabbix Http / TCP / Websocket Filter Plugins\nhttps://www.elastic.co/guide/en/logstash/7.17/filter-plugins.html\n处理Event\n内置的Filter Plugins:\nMutate 一操作Event的字段 Metrics — Aggregate metrics Ruby 一执行Ruby 代码 Codec Plugins\nhttps://www.elastic.co/guide/en/logstash/7.17/codec-plugins.html\n将原始数据decode成Event;将Event encode成目标数据\n内置的Codec Plugins:\nLine / Multiline JSON / Avro / Cef (ArcSight Common Event Format) Dots / Rubydebug Logstash Queue In Memory Queue 进程Crash，机器宕机，都会引起数据的丢失\nPersistent Queue 机器宕机，数据也不会丢失; 数据保证会被消费; 可以替代 Kafka等消息队列缓冲区的作用\nqueue.type: persisted (默认是memory) queue.max_bytes: 4gb ​ Logstash安装 logstash官方文档: https://www.elastic.co/guide/en/logstash/7.17/installing-logstash.html\n1）下载并解压logstash 下载地址： https://www.elastic.co/cn/downloads/past-releases#logstash\n选择版本：7.17.3\n​ 2）测试：运行最基本的logstash管道 ​\ncd logstash-7.17.3 #linux #-e选项表示，直接把配置放在命令中，这样可以有效快速进行测试 bin/logstash -e 'input { stdin { } } output { stdout {} }' #windows .\\bin\\logstash.bat -e \"input { stdin { } } output { stdout {} }\" ​\n测试结果：\n​ window版本的logstash-7.17.3的bug:\nwindows出现错误提示could not find java; set JAVA_HOME or ensure java is in PATH\n​ 修改setup.bat\n​ ​ Codec Plugin测试\n# single line bin/logstash -e \"input{stdin{codec=\u003eline}}output{stdout{codec=\u003e rubydebug}}\" bin/logstash -e \"input{stdin{codec=\u003ejson}}output{stdout{codec=\u003e rubydebug}}\" ​\nCodec Plugin —— Multiline\n设置参数:\npattern: 设置行匹配的正则表达式\nwhat : 如果匹配成功，那么匹配行属于上一个事件还是下一个事件\nprevious / next negate : 是否对pattern结果取反\ntrue / false ​\n# 多行数据，异常 Exception in thread \"main\" java.lang.NullPointerException at com.example.myproject.Book.getTitle(Book.java:16) at com.example.myproject.Author.getBookTitles(Author.java:25) at com.example.myproject.Bootstrap.main(Bootstrap.java:14) # multiline-exception.conf input { stdin { codec =\u003e multiline { pattern =\u003e \"^\\s\" what =\u003e \"previous\" } } } filter {} output { stdout { codec =\u003e rubydebug } } #执行管道 bin/logstash -f multiline-exception.conf Input Plugin —— File\n支持从文件中读取数据，如日志文件 文件读取需要解决的问题：只被读取一次。重启后需要从上次读取的位置继续(通过sincedb 实现) 读取到文件新内容，发现新文件 文件发生归档操作(文档位置发生变化，日志rotation)，不能影响当前的内容读取 Filter Plugin\nFilter Plugin可以对Logstash Event进行各种处理，例如解析，删除字段，类型转换\nDate: 日期解析 Dissect: 分割符解析 Grok: 正则匹配解析 Mutate: 处理字段。重命名，删除，替换 Ruby: 利用Ruby 代码来动态修改Event Filter Plugin - Mutate\n对字段做各种操作:\nConvert : 类型转换 Gsub : 字符串替换 Split / Join /Merge: 字符串切割，数组合并字符串，数组合并数组 Rename: 字段重命名 Update / Replace: 字段内容更新替换 Remove_field: 字段删除 Logstash导入数据到ES 1）测试数据集下载：https://grouplens.org/datasets/movielens/\n​ 2）准备logstash-movie.conf配置文件\ninput { file { path =\u003e \"/home/es/logstash-7.17.3/dataset/movies.csv\" start_position =\u003e \"beginning\" sincedb_path =\u003e \"/dev/null\" } } filter { csv { separator =\u003e \",\" columns =\u003e [\"id\",\"content\",\"genre\"] } mutate { split =\u003e { \"genre\" =\u003e \"|\" } remove_field =\u003e [\"path\", \"host\",\"@timestamp\",\"message\"] } mutate { split =\u003e [\"content\", \"(\"] add_field =\u003e { \"title\" =\u003e \"%{[content][0]}\"} add_field =\u003e { \"year\" =\u003e \"%{[content][1]}\"} } mutate { convert =\u003e { \"year\" =\u003e \"integer\" } strip =\u003e [\"title\"] remove_field =\u003e [\"path\", \"host\",\"@timestamp\",\"message\",\"content\"] } } output { elasticsearch { hosts =\u003e \"http://localhost:9200\" index =\u003e \"movies\" document_id =\u003e \"%{id}\" user =\u003e \"elastic\" password =\u003e \"123456\" } stdout {} } ​\n3）运行logstash\n​\n# linux bin/logstash -f logstash-movie.conf ​\n同步数据库数据到Elasticsearch 需求: 将数据库中的数据同步到ES，借助ES的全文搜索,提高搜索速度\n需要把新增用户信息同步到Elasticsearch中 用户信息Update 后，需要能被更新到Elasticsearch 支持增量更新 用户注销后，不能被ES所搜索到 实现思路\n基于canal同步数据（项目实战中讲解）\n借助JDBC Input Plugin将数据从数据库读到Logstash\n需要自己提供所需的 JDBC Driver； JDBC Input Plugin 支持定时任务 Scheduling，其语法来自 Rufus-scheduler，其扩展了 Cron，使用 Cron 的语法可以完成任务的触发； JDBC Input Plugin 支持通过 Tracking_column / sql_last_value 的方式记录 State，最终实现增量的更新； https://www.elastic.co/cn/blog/logstash-jdbc-input-plugin JDBC Input Plugin实现步骤\n1）拷贝jdbc依赖到logstash-7.17.3/drivers目录下\n2）准备mysql-demo.conf配置文件\ninput { jdbc { jdbc_driver_library =\u003e \"/home/es/logstash-7.17.3/drivers/mysql-connector-java-5.1.49.jar\" jdbc_driver_class =\u003e \"com.mysql.jdbc.Driver\" jdbc_connection_string =\u003e \"jdbc:mysql://localhost:3306/test?useSSL=false\" jdbc_user =\u003e \"root\" jdbc_password =\u003e \"123456\" #启用追踪，如果为true，则需要指定tracking_column use_column_value =\u003e true #指定追踪的字段， tracking_column =\u003e \"last_updated\" #追踪字段的类型，目前只有数字(numeric)和时间类型(timestamp)，默认是数字类型 tracking_column_type =\u003e \"numeric\" #记录最后一次运行的结果 record_last_run =\u003e true #上面运行结果的保存位置 last_run_metadata_path =\u003e \"jdbc-position.txt\" statement =\u003e \"SELECT * FROM user where last_updated \u003e:sql_last_value;\" schedule =\u003e \" * * * * * *\" } } output { elasticsearch { document_id =\u003e \"%{id}\" document_type =\u003e \"_doc\" index =\u003e \"users\" hosts =\u003e [\"http://localhost:9200\"] user =\u003e \"elastic\" password =\u003e \"123456\" } stdout{ codec =\u003e rubydebug } } 3）运行logstash\nbin/logstash -f mysql-demo.conf 测试\n#user表 CREATE TABLE `user` ( `id` int NOT NULL AUTO_INCREMENT, `name` varchar(50) DEFAULT NULL, `address` varchar(50) CHARACTER DEFAULT NULL, `last_updated` bigint DEFAULT NULL, `is_deleted` int DEFAULT NULL, PRIMARY KEY (`id`) ) ENGINE=InnoDB AUTO_INCREMENT=2 DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_0900_ai_ci; #插入数据 INSERT INTO user(name,address,last_updated,is_deleted) VALUES(\"张三\",\"广州天河\",unix_timestamp(NOW()),0) ​ # 更新 update user set address=\"广州白云山\",last_updated=unix_timestamp(NOW()) where name=\"张三\" ​\n​ #删除 update user set is_deleted=1,last_updated=unix_timestamp(NOW()) where name=\"张三\" ​ #ES中查询 # 创建 alias，只显示没有被标记 deleted的用户 POST /_aliases { \"actions\": [ { \"add\": { \"index\": \"users\", \"alias\": \"view_users\", \"filter\" : { \"term\" : { \"is_deleted\" : 0} } } } ] } # 通过 Alias查询，查不到被标记成 deleted的用户 POST view_users/_search POST view_users/_search { \"query\": { \"term\": { \"name.keyword\": { \"value\": \"张三\" } } } } ​\n什么是Beats 轻量型数据采集器，文档地址： https://www.elastic.co/guide/en/beats/libbeat/7.17/index.html\nBeats 是一个免费且开放的平台，集合了多种单一用途的数据采集器。它们从成百上千或成千上万台机器和系统向 Logstash 或 Elasticsearch 发送数据。\n​ FileBeat简介 FileBeat专门用于转发和收集日志数据的轻量级采集工具。它可以作为代理安装在服务器上，FileBeat监视指定路径的日志文件，收集日志数据，并将收集到的日志转发到Elasticsearch或者Logstash。\nFileBeat的工作原理 启动FileBeat时，会启动一个或者多个输入（Input），这些Input监控指定的日志数据位置。FileBeat会针对每一个文件启动一个Harvester（收割机）。Harvester读取每一个文件的日志，将新的日志发送到libbeat，libbeat将数据收集到一起，并将数据发送给输出（Output）。\n​ logstash vs FileBeat Logstash是在jvm上运行的，资源消耗比较大。而FileBeat是基于golang编写的，功能较少但资源消耗也比较小，更轻量级。 Logstash 和Filebeat都具有日志收集功能，Filebeat更轻量，占用资源更少 Logstash 具有Filter功能，能过滤分析日志 一般结构都是Filebeat采集日志，然后发送到消息队列、Redis、MQ中，然后Logstash去获取，利用Filter功能过滤分析，然后存储到Elasticsearch中 FileBeat和Logstash配合，实现背压机制。当将数据发送到Logstash或 Elasticsearch时，Filebeat使用背压敏感协议，以应对更多的数据量。如果Logstash正在忙于处理数据，则会告诉Filebeat 减慢读取速度。一旦拥堵得到解决，Filebeat就会恢复到原来的步伐并继续传输数据。 Filebeat安装 https://www.elastic.co/guide/en/beats/filebeat/7.17/filebeat-installation-configuration.html\n1）下载并解压Filebeat\n下载地址：https://www.elastic.co/cn/downloads/past-releases#filebeat\n选择版本：7.17.3\n​ 2）编辑配置\n修改 filebeat.yml 以设置连接信息：\n​\noutput.elasticsearch: hosts: [\"192.168.65.174:9200\",\"192.168.65.192:9200\",\"192.168.65.204:9200\"] username: \"elastic\" password: \"123456\" setup.kibana: host: \"192.168.65.174:5601\" ​\n3) 启用和配置数据收集模块\n从安装目录中，运行：\n# 查看可以模块列表 ./filebeat modules list #启用nginx模块 ./filebeat modules enable nginx #如果需要更改nginx日志路径,修改modules.d/nginx.yml - module: nginx access: var.paths: [\"/var/log/nginx/access.log*\"] #启用 Logstash 模块 ./filebeat modules enable logstash #在 modules.d/logstash.yml 文件中修改设置 - module: logstash log: enabled: true var.paths: [\"/home/es/logstash-7.17.3/logs/*.log\"] 4）启动 Filebeat\n# setup命令加载Kibana仪表板。 如果仪表板已经设置，则忽略此命令。 ./filebeat setup # 启动Filebeat ./filebeat -e ELK整合实战 案例：采集tomcat服务器日志 Tomcat服务器运行过程中产生很多日志信息，通过Logstash采集并存储日志信息至ElasticSearch中\n使用FileBeats将日志发送到Logstash 1）创建配置文件filebeat-logstash.yml，配置FileBeats将数据发送到Logstash\nvim filebeat-logstash.yml chmod 644 filebeat-logstash.yml #因为Tomcat的web log日志都是以IP地址开头的，所以我们需要修改下匹配字段。 # 不以ip地址开头的行追加到上一行 filebeat.inputs: - type: log enabled: true paths: - /home/es/apache-tomcat-8.5.33/logs/*access*.* multiline.pattern: '^\\\\d+\\\\.\\\\d+\\\\.\\\\d+\\\\.\\\\d+ ' multiline.negate: true multiline.match: after output.logstash: enabled: true hosts: [\"192.168.65.204:5044\"] ​\npattern：正则表达式 negate：true 或 false；默认是false，匹配pattern的行合并到上一行；true，不匹配pattern的行合并到上一行 match：after 或 before，合并到上一行的末尾或开头 2）启动FileBeat，并指定使用指定的配置文件\n./filebeat -e -c filebeat-logstash.yml 可能出现的异常：\n异常1：Exiting: error loading config file: config file (“filebeat-logstash.yml”) can only be writable by the owner but the permissions are “-rw-rw-r–” (to fix the permissions use: ‘chmod go-w /home/es/filebeat-7.17.3-linux-x86_64/filebeat-logstash.yml’)\n因为安全原因不要其他用户写的权限，去掉写的权限就可以了\n​ chmod 644 filebeat-logstash.yml\n异常2：Failed to connect to backoff(async(tcp://192.168.65.204:5044)): dial tcp 192.168.65.204:5044: connect: connection refused\nFileBeat将尝试建立与Logstash监听的IP和端口号进行连接。但此时，我们并没有开启并配置Logstash，所以FileBeat是无法连接到Logstash的。\n配置Logstash接收FileBeat收集的数据并打印 vim config/filebeat-console.conf # 配置从FileBeat接收数据 input { beats { port =\u003e 5044 } } output { stdout { codec =\u003e rubydebug } } 测试logstash配置是否正确\nbin/logstash -f config/filebeat-console.conf --config.test_and_exit 启动logstash\n# reload.automatic：修改配置文件时自动重新加载 bin/logstash -f config/filebeat-console.conf --config.reload.automatic ​\n测试访问tomcat，logstash是否接收到了Filebeat传过来的tomcat日志\nLogstash输出数据到Elasticsearch 如果我们需要将数据输出值ES而不是控制台的话，我们修改Logstash的output配置。\nvim config/filebeat-elasticSearch.conf input { beats { port =\u003e 5044 } } output { elasticsearch { hosts =\u003e [\"http://localhost:9200\"] user =\u003e \"elastic\" password =\u003e \"123456\" } stdout{ codec =\u003e rubydebug } } 启动logstash\nbin/logstash -f config/filebeat-elasticSearch.conf --config.reload.automatic ​\nES中会生成一个以logstash开头的索引，测试日志是否保存到了ES。\n思考：日志信息都保证在message字段中，是否可以把日志进行解析一个个的字段？例如：IP字段、时间、请求方式、请求URL、响应结果。\n利用Logstash过滤器解析日志 从日志文件中收集到的数据包含了很多有效信息，比如IP、时间等，在Logstash中可以配置过滤器Filter对采集到的数据进行过滤处理，Logstash中有大量的插件可以供我们使用。\n#查看Logstash已经安装的插件 bin/logstash-plugin list Grok插件\nGrok是一种将非结构化日志解析为结构化的插件。这个工具非常适合用来解析系统日志、Web服务器日志、MySQL或者是任意其他的日志格式。\nhttps://www.elastic.co/guide/en/logstash/7.17/plugins-filters-grok.html\nGrok语法\nGrok是通过模式匹配的方式来识别日志中的数据,可以把Grok插件简单理解为升级版本的正则表达式。它拥有更多的模式，默认Logstash拥有120个模式。如果这些模式不满足我们解析日志的需求，我们可以直接使用正则表达式来进行匹配。\ngrok模式的语法是：\n%{SYNTAX:SEMANTIC} SYNTAX（语法）指的是Grok模式名称，SEMANTIC（语义）是给模式匹配到的文本字段名。例如：\n%{NUMBER:duration} %{IP:client} duration表示：匹配一个数字，client表示匹配一个IP地址。 默认在Grok中，所有匹配到的的数据类型都是字符串，如果要转换成int类型（目前只支持int和float），可以这样：%{NUMBER:duration:int} %{IP:client}\n常用的Grok模式\nhttps://help.aliyun.com/document_detail/129387.html?scm=20140722.184.2.173\n用法\nfilter { grok { match =\u003e { \"message\" =\u003e \"%{IP:client} %{WORD:method} %{URIPATHPARAM:request} %{NUMBER:bytes} %{NUMBER:duration}\" } } } 比如，tomacat日志\n192.168.65.103 - - [23/Jun/2022:22:37:23 +0800] \"GET /docs/images/docs-stylesheet.css HTTP/1.1\" 200 5780 解析后的字段\n字段名 说明 client IP 浏览器端IP timestamp 请求的时间戳 method 请求方式（GET/POST） uri 请求的链接地址 status 服务器端响应状态 length 响应的数据长度 grok模式\n​\n%{IP:ip} - - \\[%{HTTPDATE:date}\\] \\\"%{WORD:method} %{PATH:uri} %{DATA:protocol}\\\" %{INT:status} %{INT:length} ​\n为了方便测试，我们可以使用Kibana来进行Grok开发：\n​ 修改Logstash配置文件\nvim config/filebeat-console.conf input { beats { port =\u003e 5044 } } filter { grok { match =\u003e { \"message\" =\u003e \"%{IP:ip} - - \\[%{HTTPDATE:date}\\] \\\"%{WORD:method} %{PATH:uri} %{DATA:protocol}\\\" %{INT:status:int} %{INT:length:int}\" } } } output { stdout { codec =\u003e rubydebug } } 启动logstash测试\nbin/logstash -f config/filebeat-console.conf --config.reload.automatic 使用mutate插件过滤掉不需要的字段\nmutate { enable_metric =\u003e \"false\" remove_field =\u003e [\"message\", \"log\", \"tags\", \"input\", \"agent\", \"host\", \"ecs\", \"@version\"] } 要将日期格式进行转换，我们可以使用Date插件来实现。该插件专门用来解析字段中的日期，官方说明文档：https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-date.html\n用法如下：\n​ 将date字段转换为「年月日 时分秒」格式。默认字段经过date插件处理后，会输出到@timestamp字段，所以，我们可以通过修改target属性来重新定义输出字段。\ndate { match =\u003e [\"date\",\"dd/MMM/yyyy:HH:mm:ss Z\",\"yyyy-MM-dd HH:mm:ss\"] target =\u003e \"date\" } ​\n输出到Elasticsearch指定索引 index来指定索引名称，默认输出的index名称为：logstash-%{+yyyy.MM.dd}。但注意，要在index中使用时间格式化，filter的输出必须包含 @timestamp字段，否则将无法解析日期。\noutput { elasticsearch { index =\u003e \"tomcat_web_log_%{+YYYY-MM}\" hosts =\u003e [\"http://localhost:9200\"] user =\u003e \"elastic\" password =\u003e \"123456\" } stdout{ codec =\u003e rubydebug } } 注意：index名称中，不能出现大写字符\n完整的Logstash配置文件\nvim config/filebeat-filter-es.conf input { beats { port =\u003e 5044 } } filter { grok { match =\u003e { \"message\" =\u003e \"%{IP:ip} - - \\[%{HTTPDATE:date}\\] \\\"%{WORD:method} %{PATH:uri} %{DATA:protocol}\\\" %{INT:status:int} %{INT:length:int}\" } } mutate { enable_metric =\u003e \"false\" remove_field =\u003e [\"message\", \"log\", \"tags\", \"input\", \"agent\", \"host\", \"ecs\", \"@version\"] } date { match =\u003e [\"date\",\"dd/MMM/yyyy:HH:mm:ss Z\",\"yyyy-MM-dd HH:mm:ss\"] target =\u003e \"date\" } } output { stdout { codec =\u003e rubydebug } elasticsearch { index =\u003e \"tomcat_web_log_%{+YYYY-MM}\" hosts =\u003e [\"http://localhost:9200\"] user =\u003e \"elastic\" password =\u003e \"123456\" } } 启动logstash\nbin/logstash -f config/filebeat-filter-es.conf --config.reload.automatic input { redis { host=\u003e \"localhost\" port =\u003e \"6379\" password =\u003e \"9ed99d6b\" key =\u003e \"filebeat\" type =\u003e \"redis-input\" data_type =\u003e \"list\" threads =\u003e4 batch_count =\u003e 10 db =\u003e 0 } } filter { } output { elasticsearch { hosts =\u003e \"http://cqzwy-mgmt-log-platform-grc055ce-0.cqzwy-mgmt-log-platform-grc055ce.013497775a1b4580924a00009a20c887.svc.cluster.local:9200\" index =\u003e \"netlog\" user =\u003e \"elastic\" password =\u003e \"kuGmFNENeZyYuGkYZ4BU\" } } logstash 问题处理\nhttps://blog.csdn.net/King_weng/article/details/106506996\nELFK整合实战2 filebeat =\u003e redis =\u003e logstash =\u003e elasticsearch =\u003e kinbana\nfilebeat的配置 filebeat.yml\nfilebeat.inputs: - type: filestream paths: - /var/log/data/10.42.76.202/*.log - /var/log/data/10.42.76.201/*.log - /var/log/data/10.42.76.204/*.log encoding: gbk # 对非utf-8的数据进行转码 ignore_older: 5m #只采集5分钟内更新的文件 - type: filestream paths: - /var/log/data/10.42.76.206/*.log - /var/log/data/10.42.76.207/*.log ignore_older: 5m output.redis: hosts: [\"10.43.152.65:6379\"] password: \"9ed99d6b\" key: \"filebeat\" db: 0 timeout: 5 filebeat 启动命令\nnohup ./filebeat -e -c filebeat.yml \u003e/dev/null \u0026 logstash的配置 logstash_run.yml\ninput { redis { host=\u003e \"localhost\" port =\u003e \"6379\" password =\u003e \"9ed99d6b\" key =\u003e \"filebeat\" # 对应redis中的key名称 type =\u003e \"redis-input\" data_type =\u003e \"list\" # key的类型 threads =\u003e4 batch_count =\u003e 10 db =\u003e 0 } } filter { } output { elasticsearch { hosts =\u003e \"http://cqzwy-mgmt-log-platform-grc055ce-0.cqzwy-mgmt-log-platform-grc055ce.013497775a1b4580924a00009a20c887.svc.cluster.local:9200\" index =\u003e \"netlog\" # 在es中的索引名称 user =\u003e \"elastic\" password =\u003e \"kuGmFNENeZyYuGkYZ4BU\" } } 通过jvm.options文件修改jvm参数\n制作logstash镜像(可选) start.sh启动脚本\n#!/bin/bash # -f 后指定的配置文件需是新的文件 bin/logstash -f config/logstash_run.yml --config.reload.automatic Dockerfile文件\nFROM centos:7 MAINTAINER wandong RUN yum install -y wget java-1.8.0-openjdk curl unzip iproute net-tools \u0026\u0026 \\ yum clean all \u0026\u0026 \\ rm -rf /var/cache/yum/* ADD logstash-7.15.2-linux-x86_64.tar.gz /opt/ WORKDIR /opt/logstash-7.15.2 COPY start.sh /opt/logstash-7.15.2 EXPOSE 5044 9600 CMD [\"sh\",\"start.sh\"] log.file.path : 10.42.76.201 and message : 39.144.219.132\n","wordCount":"2881","inLanguage":"en","datePublished":"2021-08-15T08:15:16Z","dateModified":"2021-08-15T08:15:16Z","author":{"@type":"Person","name":"Me"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://www.sulvblog.cn/post/elasticsearch%E5%85%A5%E9%97%A8/"},"publisher":{"@type":"Organization","name":"万东的云计算运维博客","logo":{"@type":"ImageObject","url":"https://www.sulvblog.cn/%3Clink%20/%20abs%20url%3E"}}}</script></head><body class=dark id=top><script>localStorage.getItem("pref-theme")==="light"&&document.body.classList.remove("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://www.sulvblog.cn accesskey=h title="万东的云计算运维博客 (Alt + H)"><img src=https://www.sulvblog.cn/img-icon.png alt=logo aria-label=logo height=35>万东的云计算运维博客</a>
<span class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></span></div><ul id=menu><li><a href=https://www.sulvblog.cn/categories/ title=分类><span>分类</span></a></li><li><a href=https://www.sulvblog.cn/tags/ title=标签><span>标签</span></a></li><li><a href=https://www.sulvblog.cn/archives/ title=归档><span>归档</span></a></li><li><a href=https://www.sulvblog.cn/search title=搜索><span>搜索</span></a></li></ul></nav></header><main class="main page"><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://www.sulvblog.cn>Home</a>&nbsp;»&nbsp;<a href=https://www.sulvblog.cn/post/>Posts</a></div><h1 class=post-title>离线安装docker</h1><div class=post-description>离线安装docker</div><div class=post-meta><span title='2021-08-15 08:15:16 +0000 UTC'>August 15, 2021</span>&nbsp;·&nbsp;14 min&nbsp;·&nbsp;2881 words&nbsp;·&nbsp;Me&nbsp;|&nbsp;<a href=https://github.com/%3cpath_to_repo%3e/content/post/Elasticsearch%e5%85%a5%e9%97%a8.md rel="noopener noreferrer" target=_blank>Suggest Changes</a></div></header><aside id=toc-container class="toc-container wide"><div class=toc><details open><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><nav id=TableOfContents><ul><li><a href=#全文检索><strong>全文检索</strong></a><ul><li><a href=#什么是全文检索><strong>什么是全文检索</strong></a></li><li><a href=#倒排索引><strong>倒排索引</strong></a></li></ul></li><li><a href=#elasticsearch简介><strong>ElasticSearch简介</strong></a><ul><li><a href=#elasticsearch是什么><strong>ElasticSearch是什么</strong></a></li><li><a href=#elastic-stack介绍><strong>Elastic Stack介绍</strong></a></li><li><a href=#elasticsearch应用场景><strong>ElasticSearch应用场景</strong></a></li></ul></li><li><a href=#elasticsearch快速开始><strong>ElasticSearch快速开始</strong></a><ul><li><a href=#elasticsearch安装运行><strong>ElasticSearch安装运行</strong></a></li><li><a href=#elasticsearch基本概念><strong>ElasticSearch基本概念</strong></a></li><li><a href=#elasticsearch索引操作><strong>ElasticSearch索引操作</strong></a></li><li><a href=#elasticsearch文档操作><strong>ElasticSearch文档操作</strong></a></li><li><a href=#elasticsearch文档批量操作><strong>ElasticSearch文档批量操作</strong></a></li></ul></li></ul><ul><li><a href=#背景><strong>背景</strong></a></li><li><a href=#elk架构><strong>ELK架构</strong></a><ul><li><a href=#经典的elk><strong>经典的ELK</strong></a></li><li><a href=#整合消息队列nginx架构><strong>整合消息队列+Nginx架构</strong></a></li></ul></li><li><a href=#什么是logstash><strong>什么是Logstash</strong></a><ul><li><a href=#logstash核心概念><strong>Logstash核心概念</strong></a></li><li><a href=#logstash数据传输原理><strong>Logstash数据传输原理</strong></a></li><li><a href=#logstash配置文件结构><strong>Logstash配置文件结构</strong></a></li><li><a href=#logstash-queue><strong>Logstash Queue</strong></a></li><li><a href=#logstash安装><strong>Logstash安装</strong></a></li><li><a href=#logstash导入数据到es><strong>Logstash导入数据到ES</strong></a></li><li><a href=#同步数据库数据到elasticsearch><strong>同步数据库数据到Elasticsearch</strong></a></li></ul></li><li><a href=#什么是beats><strong>什么是Beats</strong></a><ul><li></li></ul></li><li><a href=#elk整合实战><strong>ELK整合实战</strong></a><ul><li><a href=#案例采集tomcat服务器日志><strong>案例：采集tomcat服务器日志</strong></a></li><li><a href=#使用filebeats将日志发送到logstash><strong>使用FileBeats将日志发送到Logstash</strong></a></li><li><a href=#配置logstash接收filebeat收集的数据并打印><strong>配置Logstash接收FileBeat收集的数据并打印</strong></a></li><li><a href=#logstash输出数据到elasticsearch><strong>Logstash输出数据到Elasticsearch</strong></a></li><li><a href=#利用logstash过滤器解析日志><strong>利用Logstash过滤器解析日志</strong></a></li><li><a href=#输出到elasticsearch指定索引><strong>输出到Elasticsearch指定索引</strong></a></li></ul></li><li><a href=#elfk整合实战2>ELFK整合实战2</a><ul><li><a href=#filebeat的配置>filebeat的配置</a></li><li><a href=#logstash的配置>logstash的配置</a></li></ul></li></ul></nav></div></details></div></aside><script>let activeElement,elements;window.addEventListener("DOMContentLoaded",function(){checkTocPosition(),elements=document.querySelectorAll("h1[id],h2[id],h3[id],h4[id],h5[id],h6[id]"),activeElement=elements[0];const t=encodeURI(activeElement.getAttribute("id")).toLowerCase();document.querySelector(`.inner ul li a[href="#${t}"]`).classList.add("active")},!1),window.addEventListener("resize",function(){checkTocPosition()},!1),window.addEventListener("scroll",()=>{activeElement=Array.from(elements).find(e=>{if(getOffsetTop(e)-window.pageYOffset>0&&getOffsetTop(e)-window.pageYOffset<window.innerHeight/2)return e})||activeElement,elements.forEach(e=>{const t=encodeURI(e.getAttribute("id")).toLowerCase();e===activeElement?document.querySelector(`.inner ul li a[href="#${t}"]`).classList.add("active"):document.querySelector(`.inner ul li a[href="#${t}"]`).classList.remove("active")})},!1);const main=parseInt(getComputedStyle(document.body).getPropertyValue("--article-width"),10),toc=parseInt(getComputedStyle(document.body).getPropertyValue("--toc-width"),10),gap=parseInt(getComputedStyle(document.body).getPropertyValue("--gap"),10);function checkTocPosition(){const e=document.body.scrollWidth;e-main-toc*2-gap*4>0?document.getElementById("toc-container").classList.add("wide"):document.getElementById("toc-container").classList.remove("wide")}function getOffsetTop(e){if(!e.getClientRects().length)return 0;let t=e.getBoundingClientRect(),n=e.ownerDocument.defaultView;return t.top+n.pageYOffset}</script><div class=post-content><p>ES版本： v7.17.3</p><p>ES环境搭建视频：https://pan.baidu.com/s/1PsTNbpDy&ndash;M-pvFWb3aehQ?pwd=nwxl</p><h1 id=elasticsearch快速入门实战>ElasticSearch快速入门实战<a hidden class=anchor aria-hidden=true href=#elasticsearch快速入门实战>#</a></h1><p>note 链接：http://note.youdao.com/noteshare?id=d5d5718ae542f274ba0fda4284a53231&sub=68E590656C7A48858C7F6997D4A1511A</p><h2 id=全文检索><strong>全文检索</strong><a hidden class=anchor aria-hidden=true href=#全文检索>#</a></h2><p><strong>数据分类：</strong></p><ul><li>结构化数据： 固定格式，有限长度 比如mysql存的数据</li><li>非结构化数据：不定长，无固定格式 比如邮件，word文档，日志</li><li>半结构化数据： 前两者结合 比如xml，html</li></ul><p><strong>搜索分类：</strong></p><ul><li><p>结构化数据搜索： 使用关系型数据库</p></li><li><p>非结构化数据搜索</p></li><li><ul><li>顺序扫描</li><li>全文检索</li></ul></li></ul><p>设想一个关于搜索的场景，假设我们要搜索一首诗句内容中带“前”字的古诗</p><table><thead><tr><th>name</th><th>content</th><th>author</th></tr></thead><tbody><tr><td>静夜思</td><td>床前明月光,疑是地上霜。举头望明月，低头思故乡。</td><td>李白</td></tr><tr><td>望庐山瀑布</td><td>日照香炉生紫烟，遥看瀑布挂前川。飞流直下三千尺,疑是银河落九天。</td><td>李白</td></tr><tr><td>&mldr;</td><td>&mldr;</td><td>&mldr;</td></tr></tbody></table><p>思考：用传统关系型数据库和ES 实现会有什么差别？</p><p>如果用像 MySQL 这样的 RDBMS 来存储古诗的话，我们应该会去使用这样的 SQL 去查询</p><p>​ select name from poems where content like &ldquo;%前%&rdquo;</p><p>这种我们称为顺序扫描法，需要遍历所有的记录进行匹配。不但效率低，而且不符合我们搜索时的期望，比如我们在搜索“ABCD"这样的关键词时，通常还希望看到"A",&ldquo;AB&rdquo;,&ldquo;CD&rdquo;,“ABC”的搜索结果。</p><h3 id=什么是全文检索><strong>什么是全文检索</strong><a hidden class=anchor aria-hidden=true href=#什么是全文检索>#</a></h3><p>全文检索是指：</p><ul><li>通过一个程序扫描文本中的每一个单词，针对单词建立索引，并保存该单词在文本中的位置、以及出现的次数</li><li>用户查询时，通过之前建立好的索引来查询，将索引中单词对应的文本位置、出现的次数返回给用户，因为有了具体文本的位置，所以就可以将具体内容读取出来了</li></ul><p>​ <img loading=lazy src=https://note.youdao.com/yws/public/resource/d5d5718ae542f274ba0fda4284a53231/xmlnote/8A90F0AB501D4D6996DF632D22E3CD04/46866 alt=0></p><p>搜索原理简单概括的话可以分为这么几步：</p><ul><li>内容爬取，停顿词过滤比如一些无用的像"的"，“了”之类的语气词/连接词</li><li>内容分词，提取关键词</li><li>根据关键词建立倒排索引</li><li>用户输入关键词进行搜索</li></ul><h3 id=倒排索引><strong>倒排索引</strong><a hidden class=anchor aria-hidden=true href=#倒排索引>#</a></h3><p>索引就类似于目录，平时我们使用的都是索引，都是通过主键定位到某条数据，那么倒排索引呢，刚好相反，数据对应到主键。</p><p>​ <img loading=lazy src=https://note.youdao.com/yws/public/resource/d5d5718ae542f274ba0fda4284a53231/xmlnote/EDCB815C4FDD41C883F4B13ECFF6E274/46781 alt=0></p><p>这里以一个博客文章的内容为例:</p><p><strong>正排索引（正向索引）</strong></p><table><thead><tr><th>文章ID</th><th>文章标题</th><th>文章内容</th></tr></thead><tbody><tr><td>1</td><td>浅析JAVA设计模式</td><td>JAVA设计模式是每一个JAVA程序员都应该掌握的进阶知识</td></tr><tr><td>2</td><td>JAVA多线程设计模式</td><td>JAVA多线程与设计模式结合</td></tr></tbody></table><p><strong>倒排索引（反向索引）</strong></p><p>假如，我们有一个站内搜索的功能，通过某个关键词来搜索相关的文章，那么这个关键词可能出现在标题中，也可能出现在文章内容中，那我们将会在创建或修改文章的时候，建立一个关键词与文章的对应关系表，这种，我们可以称之为倒排索引。</p><p>like %java设计模式% java 设计模式</p><table><thead><tr><th>关键词</th><th>文章ID</th></tr></thead><tbody><tr><td>JAVA</td><td>1,2</td></tr><tr><td>设计模式</td><td>1,2</td></tr><tr><td>多线程</td><td>2</td></tr></tbody></table><p>简单理解，正向索引是通过key找value，反向索引则是通过value找key。ES底层在检索时底层使用的就是倒排索引。</p><h2 id=elasticsearch简介><strong>ElasticSearch简介</strong><a hidden class=anchor aria-hidden=true href=#elasticsearch简介>#</a></h2><h3 id=elasticsearch是什么><strong>ElasticSearch是什么</strong><a hidden class=anchor aria-hidden=true href=#elasticsearch是什么>#</a></h3><p>ElasticSearch（简称ES）是一个分布式、RESTful 风格的搜索和数据分析引擎，是用Java开发并且是当前最流行的开源的企业级搜索引擎，能够达到近实时搜索，稳定，可靠，快速，安装使用方便。</p><p>客户端支持Java、.NET（C#）、PHP、Python、Ruby等多种语言。</p><p><strong>官方网站:</strong> <a href=https://www.elastic.co/>https://www.elastic.co/</a></p><p>**下载地址：**<a href=https://www.elastic.co/cn/downloads/past-releases#elasticsearch>https://www.elastic.co/cn/downloads/past-releases#elasticsearch</a></p><p>搜索引擎排名：</p><p>​ <img loading=lazy src=https://note.youdao.com/yws/public/resource/d5d5718ae542f274ba0fda4284a53231/xmlnote/C14A899210B444CDAF00DB58A30E4D38/46333 alt=0></p><p>参考网站：https://db-engines.com/en/ranking/search+engine</p><h4 id=起源lucene><strong>起源——Lucene</strong><a hidden class=anchor aria-hidden=true href=#起源lucene>#</a></h4><ul><li><p>基于Java语言开发的搜索引擎库类</p></li><li><p>创建于1999年，2005年成为Apache 顶级开源项目</p></li><li><p>Lucene具有高性能、易扩展的优点</p></li><li><p>Lucene的局限性︰</p></li><li><ul><li>只能基于Java语言开发</li><li>类库的接口学习曲线陡峭</li><li>原生并不支持水平扩展</li></ul></li></ul><h4 id=elasticsearch的诞生><strong>Elasticsearch的诞生</strong><a hidden class=anchor aria-hidden=true href=#elasticsearch的诞生>#</a></h4><p>Elasticsearch是构建在Apache Lucene之上的开源分布式搜索引擎。</p><ul><li><p>2004年 Shay Banon 基于Lucene开发了Compass</p></li><li><p>2010年 Shay Banon重写了Compass，取名Elasticsearch</p></li><li><ul><li>支持分布式，可水平扩展</li><li>降低全文检索的学习曲线，可以被任何编程语言调用</li></ul></li></ul><p>​ <img loading=lazy src=https://note.youdao.com/yws/public/resource/d5d5718ae542f274ba0fda4284a53231/xmlnote/A8F24FAED7834EFAAFFD94EFCF5A07A8/46329 alt=0></p><p>Elasticsearch 与 Lucene 核心库竞争的优势在于：</p><ul><li>完美封装了 Lucene 核心库，设计了友好的 Restful-API，开发者无需过多关注底层机制，直接开箱即用。</li><li>分片与副本机制，直接解决了集群下性能与高可用问题。</li></ul><p>ES Server进程 3节点 raft (奇数节点)</p><p>数据分片 -》lucene实例 分片和副本数 1个ES节点可以有多个lucene实例。也可以指定一个索引的多个分片</p><p>​ <img loading=lazy src=https://note.youdao.com/yws/public/resource/d5d5718ae542f274ba0fda4284a53231/xmlnote/77E4EF0FBAF8465EA2DA3841014A8B6B/50604 alt=0></p><h4 id=elasticsearch版本特性><strong>ElasticSearch版本特性</strong><a hidden class=anchor aria-hidden=true href=#elasticsearch版本特性>#</a></h4><p>5.x新特性</p><ul><li><p>Lucene 6.x， 性能提升，默认打分机制从TF-IDF改为BM 25</p></li><li><p>支持Ingest节点/ Painless Scripting / Completion suggested支持/原生的Java REST客户端</p></li><li><p>Type标记成deprecated， 支持了Keyword的类型</p></li><li><p>性能优化</p></li><li><ul><li>内部引擎移除了避免同一文档并发更新的竞争锁，带来15% - 20%的性能提升</li><li>Instant aggregation,支持分片，上聚合的缓存</li><li>新增了Profile API</li></ul></li></ul><p>6.x新特性</p><ul><li><p>Lucene 7.x</p></li><li><p>新功能</p></li><li><ul><li>跨集群复制(CCR)</li><li>索引生命周期管理</li><li>SQL的支持</li></ul></li><li><p>更友好的的升级及数据迁移</p></li><li><ul><li>在主要版本之间的迁移更为简化，体验升级</li><li>全新的基于操作的数据复制框架，可加快恢复数据</li></ul></li><li><p>性能优化</p></li><li><ul><li>有效存储稀疏字段的新方法，降低了存储成本</li><li>在索引时进行排序，可加快排序的查询性能</li></ul></li></ul><p>7.x新特性</p><ul><li><p>Lucene 8.0</p></li><li><p>重大改进-正式废除单个索引下多Type的支持</p></li><li><p>7.1开始，Security 功能免费使用</p></li><li><p>ECK - Elasticseach Operator on Kubernetes</p></li><li><p>新功能</p></li><li><ul><li>New Cluster coordination</li><li>Feature——Complete High Level REST Client</li><li>Script Score Query</li></ul></li><li><p>性能优化</p></li><li><ul><li>默认的Primary Shard数从5改为1,避免Over Sharding</li><li>性能优化， 更快的Top K</li></ul></li></ul><p>8.x新特性</p><ul><li>Rest API相比较7.x而言做了比较大的改动（比如彻底删除_type）</li><li>默认开启安全配置</li><li>存储空间优化：对倒排文件使用新的编码集，对于keyword、match_only_text、text类型字段有效，有3.5%的空间优化提升，对于新建索引和segment自动生效。</li><li>优化geo_point，geo_shape类型的索引（写入）效率：15%的提升。</li><li>技术预览版KNN API发布，（K邻近算法），跟推荐系统、自然语言排名相关。</li><li><a href=https://www.elastic.co/guide/en/elastic-stack/current/elasticsearch-breaking-changes.html>https://www.elastic.co/guide/en/elastic-stack/current/elasticsearch-breaking-changes.html</a></li></ul><h4 id=elasticsearch-vs-solr><strong>ElasticSearch vs Solr</strong><a hidden class=anchor aria-hidden=true href=#elasticsearch-vs-solr>#</a></h4><p>Solr 是第一个基于 Lucene 核心库功能完备的搜索引擎产品，诞生远早于 Elasticsearch。</p><p>当单纯的对已有数据进行搜索时，Solr更快。当实时建立索引时, Solr会产生io阻塞，查询性能较差, Elasticsearch具有明显的优势。</p><p>​ <img loading=lazy src=https://note.youdao.com/yws/public/resource/d5d5718ae542f274ba0fda4284a53231/xmlnote/E98844053B7A48D59BE2B285506B4DD8/50800 alt=0></p><p>​ <img loading=lazy src=https://note.youdao.com/yws/public/resource/d5d5718ae542f274ba0fda4284a53231/xmlnote/A1C3A7F3FBA943E89AADB69DA767EE4D/46439 alt=0></p><p>大型互联网公司，实际生产环境测试，将搜索引擎从Solr转到 Elasticsearch以后的平均查询速度有了50倍的提升。</p><p>​ <img loading=lazy src=https://note.youdao.com/yws/public/resource/d5d5718ae542f274ba0fda4284a53231/xmlnote/ED8202C58E1C4FF9B7FD435A498B36F5/46437 alt=0></p><p><strong>总结：</strong></p><ul><li>Solr 利用 Zookeeper 进行分布式管理，而Elasticsearch 自身带有分布式协调管理功能。</li><li>Solr 支持更多格式的数据，比如JSON、XML、CSV，而 Elasticsearch 仅支持json文件格式。</li><li>Solr 在传统的搜索应用中表现好于 Elasticsearch，但在处理实时搜索应用时效率明显低于 Elasticsearch。</li><li>Solr 是传统搜索应用的有力解决方案，但 Elasticsearch更适用于新兴的实时搜索应用。</li></ul><h3 id=elastic-stack介绍><strong>Elastic Stack介绍</strong><a hidden class=anchor aria-hidden=true href=#elastic-stack介绍>#</a></h3><p>在Elastic Stack之前我们听说过ELK，ELK分别是Elasticsearch，Logstash，Kibana这三款软件在一起的简称，在发展的过程中又有新的成员Beats的加入，就形成了Elastic Stack。</p><p>​ <img loading=lazy src=https://note.youdao.com/yws/public/resource/d5d5718ae542f274ba0fda4284a53231/xmlnote/FB9BA708EAA1492EB2B2919B4DF10704/46325 alt=0></p><p>　　　　　　　 Elastic Stack生态圈</p><p>在Elastic Stack生态圈中Elasticsearch作为数据存储和搜索，是生态圈的基石，Kibana在上层提供用户一个可视化及操作的界面，Logstash和Beat可以对数据进行收集。在上图的右侧X-Pack部分则是Elastic公司提供的商业项目。</p><p>指标分析/日志分析：</p><p>​ <img loading=lazy src=https://note.youdao.com/yws/public/resource/d5d5718ae542f274ba0fda4284a53231/xmlnote/7B1A36FA8A004C298683FCC5F318EE6B/46442 alt=0></p><h3 id=elasticsearch应用场景><strong>ElasticSearch应用场景</strong><a hidden class=anchor aria-hidden=true href=#elasticsearch应用场景>#</a></h3><ul><li>站内搜索</li><li>日志管理与分析</li><li>大数据分析</li><li>应用性能监控</li><li>机器学习</li></ul><p>国内现在有大量的公司都在使用 Elasticsearch，包括携程、滴滴、今日头条、饿了么、360安全、小米、vivo等诸多知名公司。除了搜索之外，结合Kibana、Logstash、Beats，Elastic Stack还被广泛运用在大数据近实时分析领域，包括日志分析、指标监控、信息安全等多个领域。它可以帮助你探索海量结构化、非结构化数据，按需创建可视化报表，对监控数据设置报警阈值，甚至通过使用机器学习技术，自动识别异常状况。</p><p><strong>通用数据处理流程：</strong></p><p>​ <img loading=lazy src=https://note.youdao.com/yws/public/resource/d5d5718ae542f274ba0fda4284a53231/xmlnote/F6E2A13CBA5D4F3096A1984C6266F1C5/46527 alt=0></p><h2 id=elasticsearch快速开始><strong>ElasticSearch快速开始</strong><a hidden class=anchor aria-hidden=true href=#elasticsearch快速开始>#</a></h2><p><strong>安装JDK</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-shell data-lang=shell><span class=line><span class=cl>1、yum install -y java-1.8.0-openjdk*
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 或者</span>
</span></span><span class=line><span class=cl>mkdir /opt/jdk<span class=p>;</span>tar -xvzf jdk-8u333-linux-x64.tar.gz -C /opt/jdk/<span class=p>;</span>  mv /opt/jdk/jdk1.8.0_333/ /opt/jdk/jdk1.8 <span class=p>;</span>
</span></span><span class=line><span class=cl>cat <span class=s>&lt;&lt;EOF &gt;&gt; /etc/profile
</span></span></span><span class=line><span class=cl><span class=s>JAVA_HOME=/opt/jdk/jdk1.8
</span></span></span><span class=line><span class=cl><span class=s>CLASSPATH=$JAVA_HOME/lib/
</span></span></span><span class=line><span class=cl><span class=s>PATH=$PATH:$JAVA_HOME/bin
</span></span></span><span class=line><span class=cl><span class=s>export PATH JAVA_HOME CLASSPATH
</span></span></span><span class=line><span class=cl><span class=s>EOF</span>
</span></span><span class=line><span class=cl><span class=nb>source</span> /etc/profile
</span></span></code></pre></div><h3 id=elasticsearch安装运行><strong>ElasticSearch安装运行</strong><a hidden class=anchor aria-hidden=true href=#elasticsearch安装运行>#</a></h3><h4 id=环境准备><strong>环境准备</strong><a hidden class=anchor aria-hidden=true href=#环境准备>#</a></h4><ul><li><p>运行Elasticsearch，需安装并配置JDK</p></li><li><ul><li>设置$JAVA_HOME</li></ul></li><li><p>各个版本对Java的依赖 <a href=https://www.elastic.co/support/matrix#matrix_jvm>https://www.elastic.co/support/matrix#matrix_jvm</a></p></li><li><ul><li>Elasticsearch 5需要Java 8以上的版本</li><li>Elasticsearch 从6.5开始支持Java 11</li><li>7.0开始，内置了Java环境</li></ul></li><li><p>ES比较耗内存，建议虚拟机4G或以上内存，jvm1g以上的内存分配</p></li></ul><p>可以参考es的环境文件elasticsearch-env.bat</p><p>​ <img loading=lazy src=https://note.youdao.com/yws/public/resource/d5d5718ae542f274ba0fda4284a53231/xmlnote/09A302EBF53F4B2DB4B956F8CC2DFBF3/46255 alt=0></p><p>ES的jdk环境生效的优先级配置ES_JAVA_HOME>JAVA_HOME>ES_HOME</p><h4 id=下载并解压elasticsearch><strong>下载并解压ElasticSearch</strong><a hidden class=anchor aria-hidden=true href=#下载并解压elasticsearch>#</a></h4><p>下载地址： <a href=https://www.elastic.co/cn/downloads/past-releases#elasticsearch>https://www.elastic.co/cn/downloads/past-releases#elasticsearch</a></p><p>选择版本：7.17.3</p><p>​ <img loading=lazy src=https://note.youdao.com/yws/public/resource/d5d5718ae542f274ba0fda4284a53231/xmlnote/EFB0C67135D14C71A090FD5D65B08B08/46614 alt=0></p><p><strong>ElasticSearch文件目录结构</strong></p><table><thead><tr><th>目录</th><th>描述</th></tr></thead><tbody><tr><td>bin</td><td>脚本文件，包括启动elasticsearch，安装插件，运行统计数据等</td></tr><tr><td>config</td><td>配置文件目录，如elasticsearch配置、角色配置、jvm配置等。</td></tr><tr><td>jdk</td><td>java运行环境</td></tr><tr><td>data</td><td>默认的数据存放目录，包含节点、分片、索引、文档的所有数据，生产环境需要修改。</td></tr><tr><td>lib</td><td>elasticsearch依赖的Java类库</td></tr><tr><td>logs</td><td>默认的日志文件存储路径，生产环境需要修改。</td></tr><tr><td>modules</td><td>包含所有的Elasticsearch模块，如Cluster、Discovery、Indices等。</td></tr><tr><td>plugins</td><td>已安装插件目录</td></tr></tbody></table><p><strong>主配置文件elasticsearch.yml</strong></p><ul><li>cluster.name</li></ul><p>当前节点所属集群名称，多个节点如果要组成同一个集群，那么集群名称一定要配置成相同。默认值elasticsearch，生产环境建议根据ES集群的使用目的修改成合适的名字。</p><ul><li>node.name</li></ul><p>当前节点名称，默认值当前节点部署所在机器的主机名，所以如果一台机器上要起多个ES节点的话，需要通过配置该属性明确指定不同的节点名称。</p><ul><li>path.data</li></ul><p>配置数据存储目录，比如索引数据等，默认值 $ES_HOME/data，生产环境下强烈建议部署到另外的安全目录，防止ES升级导致数据被误删除。</p><ul><li>path.logs</li></ul><p>配置日志存储目录，比如运行日志和集群健康信息等，默认值 $ES_HOME/logs，生产环境下强烈建议部署到另外的安全目录，防止ES升级导致数据被误删除。</p><ul><li>bootstrap.memory_lock</li></ul><p>配置ES启动时是否进行内存锁定检查，默认值true。</p><p>ES对于内存的需求比较大，一般生产环境建议配置大内存，如果内存不足，容易导致内存交换到磁盘，严重影响ES的性能。所以默认启动时进行相应大小内存的锁定，如果无法锁定则会启动失败。</p><p>非生产环境可能机器内存本身就很小，能够供给ES使用的就更小，如果该参数配置为true的话很可能导致无法锁定内存以致ES无法成功启动，此时可以修改为false。</p><ul><li>network.host</li></ul><p>配置能够访问当前节点的主机，默认值为当前节点所在机器的本机回环地址127.0.0.1 和[::1]，这就导致默认情况下只能通过当前节点所在主机访问当前节点。可以配置为 0.0.0.0 ，表示所有主机均可访问。</p><ul><li>http.port</li></ul><p>配置当前ES节点对外提供服务的http端口，默认值 9200</p><ul><li>discovery.seed_hosts</li></ul><p>配置参与集群节点发现过程的主机列表，说白一点就是集群中所有节点所在的主机列表，可以是具体的IP地址，也可以是可解析的域名。</p><ul><li>cluster.initial_master_nodes</li></ul><p>配置ES集群初始化时参与master选举的节点名称列表，必须与node.name配置的一致。ES集群首次构建完成后，应该将集群中所有节点的配置文件中的cluster.initial_master_nodes配置项移除，重启集群或者将新节点加入某个已存在的集群时切记不要设置该配置项。</p><p>​ #ES开启远程访问 network.host: 0.0.0.0</p><h4 id=修改jvm配置><strong>修改JVM配置</strong><a hidden class=anchor aria-hidden=true href=#修改jvm配置>#</a></h4><p>修改config/jvm.options配置文件，调整jvm堆内存大小</p><p>​ vim jvm.options -Xms4g -Xmx4g</p><p>配置的建议</p><ul><li>Xms和Xms设置成—样</li><li>Xmx不要超过机器内存的50%</li><li>不要超过30GB - <a href=https://www.elastic.co/cn/blog/a-heap-of-trouble>https://www.elastic.co/cn/blog/a-heap-of-trouble</a></li></ul><h4 id=启动elasticsearch服务><strong>启动ElasticSearch服务</strong><a hidden class=anchor aria-hidden=true href=#启动elasticsearch服务>#</a></h4><p><strong>Windows</strong></p><p><strong>直接运行elasticsearch.bat</strong></p><p><strong>Linux（centos7）</strong></p><p>ES不允许使用root账号启动服务，如果你当前账号是root，则需要创建一个专有账户</p><p>​ #非root用户 bin/elasticsearch # -d 后台启动 bin/elasticsearch -d</p><p>​ <img loading=lazy src=https://note.youdao.com/yws/public/resource/d5d5718ae542f274ba0fda4284a53231/xmlnote/26BE4E106C434191825F00C705954421/49275 alt=0></p><p>注意：es默认不能用root用户启动，生产环境建议为elasticsearch创建用户。</p><p>​ #为elaticsearch创建用户并赋予相应权限 adduser es passwd es chown -R es:es elasticsearch-17.3</p><p>运行http://localhost:9200/</p><p>​ <img loading=lazy src=https://note.youdao.com/yws/public/resource/d5d5718ae542f274ba0fda4284a53231/xmlnote/E6A5B87B529E41B2A9C90F4E0E8CA4B2/46552 alt=0></p><p>如果ES服务启动异常，会有提示：</p><p>​ <img loading=lazy src=https://note.youdao.com/yws/public/resource/d5d5718ae542f274ba0fda4284a53231/xmlnote/87C4B293151E422ABE8E60C982EF5314/48965 alt=0></p><p><strong>启动ES服务常见错误解决方案</strong></p><p>[1]: max file descriptors [4096] for elasticsearch process is too low, increase to at least [65536]</p><p>ES因为需要大量的创建索引文件，需要大量的打开系统的文件，所以我们需要解除linux系统当中打开文件最大数目的限制，不然ES启动就会抛错</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-shell data-lang=shell><span class=line><span class=cl> <span class=c1>#切换到root用户 vim /etc/security/limits.conf 末尾添加如下配置： </span>
</span></span><span class=line><span class=cl> *	    soft 	nofile 	<span class=m>65536</span>  
</span></span><span class=line><span class=cl> *     hard 	nofile 	<span class=m>65536</span>  
</span></span><span class=line><span class=cl> *     soft 	nproc 	<span class=m>4096</span>  
</span></span><span class=line><span class=cl> *	    hard 	nproc 	<span class=m>4096</span>          
</span></span></code></pre></div><p>​</p><p>[2]: max number of threads [1024] for user [es] is too low, increase to at least [4096]</p><p>无法创建本地线程问题,用户最大可创建线程数太小</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-shell data-lang=shell><span class=line><span class=cl>vim /etc/security/limits.d/20-nproc.conf
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>改为如下配置：
</span></span><span class=line><span class=cl>* soft nproc <span class=m>4096</span>
</span></span></code></pre></div><p>[3]: max virtual memory areas vm.max_map_count [65530] is too low, increase to at least [262144]</p><p>最大虚拟内存太小,调大系统的虚拟内存</p><p>​</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-shell data-lang=shell><span class=line><span class=cl>vim /etc/sysctl.conf
</span></span><span class=line><span class=cl>追加以下内容：
</span></span><span class=line><span class=cl>vm.max_map_count<span class=o>=</span><span class=m>262144</span>
</span></span><span class=line><span class=cl>保存退出之后执行如下命令：
</span></span><span class=line><span class=cl>sysctl -p
</span></span></code></pre></div><p>[4]: the default discovery settings are unsuitable for production use; at least one of [discovery.seed_hosts, discovery.seed_providers, cluster.initial_master_nodes] must be configured</p><p>缺少默认配置，至少需要配置discovery.seed_hosts/discovery.seed_providers/cluster.initial_master_nodes中的一个参数.</p><ul><li>discovery.seed_hosts: 集群主机列表</li><li>discovery.seed_providers: 基于配置文件配置集群主机列表</li><li>cluster.initial_master_nodes: 启动时初始化的参与选主的node，生产环境必填</li></ul><p>​</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-shell data-lang=shell><span class=line><span class=cl>vim config/elasticsearch.yml
</span></span><span class=line><span class=cl><span class=c1>#添加配置</span>
</span></span><span class=line><span class=cl>discovery.seed_hosts: <span class=o>[</span><span class=s2>&#34;127.0.0.1&#34;</span><span class=o>]</span>
</span></span><span class=line><span class=cl>cluster.initial_master_nodes: <span class=o>[</span><span class=s2>&#34;node-1&#34;</span><span class=o>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1>#或者  单节点（集群单节点）</span>
</span></span><span class=line><span class=cl>discovery.type: single-node
</span></span></code></pre></div><h4 id=客户端kibana安装><strong>客户端Kibana安装</strong><a hidden class=anchor aria-hidden=true href=#客户端kibana安装>#</a></h4><p>Kibana是一个开源分析和可视化平台，旨在与Elasticsearch协同工作。</p><p><strong>1）下载并解压缩Kibana</strong></p><p>下载地址：https://www.elastic.co/cn/downloads/past-releases#kibana</p><p>选择版本：7.17.3</p><p>​ <img loading=lazy src=https://note.youdao.com/yws/public/resource/d5d5718ae542f274ba0fda4284a53231/xmlnote/D8EA84AABCCB4189B6BB4147AC87B045/46611 alt=0></p><p><strong>2）修改Kibana.yml</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-shell data-lang=shell><span class=line><span class=cl>vim config/kibana.yml 
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>server.port: <span class=m>5601</span> 
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>server.host: <span class=s2>&#34;0.0.0.0&#34;</span>  <span class=c1>#服务器ip </span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>elasticsearch.hosts: <span class=o>[</span><span class=s2>&#34;http://localhost:9200&#34;</span><span class=o>]</span>  <span class=c1>#elasticsearch的访问地址 </span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>i18n.locale: <span class=s2>&#34;zh-CN&#34;</span>   <span class=c1>#Kibana汉化              </span>
</span></span></code></pre></div><p><strong>3）运行Kibana</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-shell data-lang=shell><span class=line><span class=cl><span class=c1># 注意：kibana也需要非root用户启动</span>
</span></span><span class=line><span class=cl>bin/kibana 
</span></span><span class=line><span class=cl><span class=c1># 后台启动 </span>
</span></span><span class=line><span class=cl>nohup  bin/kibana <span class=p>&amp;</span>   
</span></span><span class=line><span class=cl><span class=c1># 或者</span>
</span></span><span class=line><span class=cl>sudo -H -u es /bin/bash -c  <span class=s2>&#34;nohup bin/kibana &amp;&#34;</span>
</span></span></code></pre></div><p>​</p><p><strong>访问Kibana:</strong> <a href=http://localhost:5601/><strong>http://localhost:5601/</strong></a></p><p>​ <img loading=lazy src=https://note.youdao.com/yws/public/resource/d5d5718ae542f274ba0fda4284a53231/xmlnote/D2612BA72B6F43F58AED880D9EDB25CE/46817 alt=0></p><p><strong>cat API</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-shell data-lang=shell><span class=line><span class=cl>/_cat/allocation         <span class=c1>#查看单节点的shard分配整体情况</span>
</span></span><span class=line><span class=cl>/_cat/shards          <span class=c1>#查看各shard的详细情况</span>
</span></span><span class=line><span class=cl>/_cat/shards/<span class=o>{</span>index<span class=o>}</span>     <span class=c1>#查看指定分片的详细情况</span>
</span></span><span class=line><span class=cl>/_cat/master          <span class=c1>#查看master节点信息</span>
</span></span><span class=line><span class=cl>/_cat/nodes           <span class=c1>#查看所有节点信息</span>
</span></span><span class=line><span class=cl>/_cat/indices         <span class=c1>#查看集群中所有index的详细信息</span>
</span></span><span class=line><span class=cl>/_cat/indices/<span class=o>{</span>index<span class=o>}</span>      <span class=c1>#查看集群中指定index的详细信息</span>
</span></span><span class=line><span class=cl>/_cat/segments        <span class=c1>#查看各index的segment详细信息,包括segment名, 所属shard, 内存(磁盘)占用大小, 是否刷盘</span>
</span></span><span class=line><span class=cl>/_cat/segments/<span class=o>{</span>index<span class=o>}</span><span class=c1>#查看指定index的segment详细信息</span>
</span></span><span class=line><span class=cl>/_cat/count           <span class=c1>#查看当前集群的doc数量</span>
</span></span><span class=line><span class=cl>/_cat/count/<span class=o>{</span>index<span class=o>}</span>   <span class=c1>#查看指定索引的doc数量</span>
</span></span><span class=line><span class=cl>/_cat/recovery        <span class=c1>#查看集群内每个shard的recovery过程.调整replica。</span>
</span></span><span class=line><span class=cl>/_cat/recovery/<span class=o>{</span>index<span class=o>}</span><span class=c1>#查看指定索引shard的recovery过程</span>
</span></span><span class=line><span class=cl>/_cat/health          <span class=c1>#查看集群当前状态：红、黄、绿</span>
</span></span><span class=line><span class=cl>/_cat/pending_tasks   <span class=c1>#查看当前集群的pending task</span>
</span></span><span class=line><span class=cl>/_cat/aliases         <span class=c1>#查看集群中所有alias信息,路由配置等</span>
</span></span><span class=line><span class=cl>/_cat/aliases/<span class=o>{</span>alias<span class=o>}</span> <span class=c1>#查看指定索引的alias信息</span>
</span></span><span class=line><span class=cl>/_cat/thread_pool     <span class=c1>#查看集群各节点内部不同类型的threadpool的统计信息,</span>
</span></span><span class=line><span class=cl>/_cat/plugins         <span class=c1>#查看集群各个节点上的plugin信息</span>
</span></span><span class=line><span class=cl>/_cat/fielddata       <span class=c1>#查看当前集群各个节点的fielddata内存使用情况</span>
</span></span><span class=line><span class=cl>/_cat/fielddata/<span class=o>{</span>fields<span class=o>}</span>     <span class=c1>#查看指定field的内存使用情况,里面传field属性对应的值</span>
</span></span><span class=line><span class=cl>/_cat/nodeattrs              <span class=c1>#查看单节点的自定义属性</span>
</span></span><span class=line><span class=cl>/_cat/repositories           <span class=c1>#输出集群中注册快照存储库</span>
</span></span><span class=line><span class=cl>/_cat/templates              <span class=c1>#输出当前正在存在的模板信息</span>
</span></span></code></pre></div><h4 id=elasticsearch安装分词插件><strong>Elasticsearch安装分词插件</strong><a hidden class=anchor aria-hidden=true href=#elasticsearch安装分词插件>#</a></h4><p>Elasticsearch提供插件机制对系统进行扩展</p><p>以安装analysis-icu这个分词插件为例</p><p><strong>在线安装</strong></p><p>​</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-shell data-lang=shell><span class=line><span class=cl><span class=c1>#查看已安装插件</span>
</span></span><span class=line><span class=cl>bin/elasticsearch-plugin list
</span></span><span class=line><span class=cl><span class=c1>#安装插件</span>
</span></span><span class=line><span class=cl>bin/elasticsearch-plugin install analysis-icu
</span></span><span class=line><span class=cl><span class=c1>#删除插件</span>
</span></span><span class=line><span class=cl>bin/elasticsearch-plugin remove analysis-icu
</span></span></code></pre></div><p>注意：安装和删除完插件后，需要重启ES服务才能生效。</p><p>测试分词效果</p><p>​ POST _analyze { &ldquo;analyzer&rdquo;:&ldquo;icu_analyzer&rdquo;, &ldquo;text&rdquo;:&ldquo;中华人民共和国&rdquo; }</p><p>​ <img loading=lazy src=https://note.youdao.com/yws/public/resource/d5d5718ae542f274ba0fda4284a53231/xmlnote/4E2EA6F5FECA45D288AE41FBB8A69F22/46920 alt=0></p><p><strong>离线安装</strong></p><p>本地下载相应的插件，解压，然后手动上传到elasticsearch的plugins目录，然后重启ES实例就可以了。</p><p>比如ik中文分词插件：https://github.com/medcl/elasticsearch-analysis-ik</p><p><a href=https://github.com/medcl/elasticsearch-analysis-ik/releases/download/v7.15.2/elasticsearch-analysis-ik-7.15.2.zip>elasticsearch-analysis-ik-7.15.2.zip</a></p><p>必须对应es版本</p><p>测试分词效果</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-shell data-lang=shell><span class=line><span class=cl><span class=c1>#ES的默认分词设置是standard，会单字拆分</span>
</span></span><span class=line><span class=cl>POST _analyze
</span></span><span class=line><span class=cl><span class=o>{</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;analyzer&#34;</span>:<span class=s2>&#34;standard&#34;</span>,
</span></span><span class=line><span class=cl>    <span class=s2>&#34;text&#34;</span>:<span class=s2>&#34;中华人民共和国&#34;</span>
</span></span><span class=line><span class=cl><span class=o>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1>#ik_smart:会做最粗粒度的拆</span>
</span></span><span class=line><span class=cl>POST _analyze
</span></span><span class=line><span class=cl><span class=o>{</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;analyzer&#34;</span>: <span class=s2>&#34;ik_smart&#34;</span>,
</span></span><span class=line><span class=cl>    <span class=s2>&#34;text&#34;</span>: <span class=s2>&#34;中华人民共和国&#34;</span>
</span></span><span class=line><span class=cl> <span class=o>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1>#ik_max_word:会将文本做最细粒度的拆分</span>
</span></span><span class=line><span class=cl>POST _analyze
</span></span><span class=line><span class=cl><span class=o>{</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;analyzer&#34;</span>:<span class=s2>&#34;ik_max_word&#34;</span>,
</span></span><span class=line><span class=cl>    <span class=s2>&#34;text&#34;</span>:<span class=s2>&#34;中华人民共和国&#34;</span>
</span></span><span class=line><span class=cl><span class=o>}</span>
</span></span></code></pre></div><p>​</p><p>创建索引时可以指定IK分词器作为默认分词器</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-shell data-lang=shell><span class=line><span class=cl>PUT /es_db
</span></span><span class=line><span class=cl><span class=o>{</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;settings&#34;</span> : <span class=o>{</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;index&#34;</span> : <span class=o>{</span>
</span></span><span class=line><span class=cl>            <span class=s2>&#34;analysis.analyzer.default.type&#34;</span>: <span class=s2>&#34;ik_max_word&#34;</span>
</span></span><span class=line><span class=cl>        <span class=o>}</span>
</span></span><span class=line><span class=cl>    <span class=o>}</span>
</span></span><span class=line><span class=cl><span class=o>}</span>
</span></span></code></pre></div><p>​ <img loading=lazy src=https://note.youdao.com/yws/public/resource/d5d5718ae542f274ba0fda4284a53231/xmlnote/C4D26DC85B57401CBC9DBB14297DB2FD/49281 alt=0></p><h3 id=elasticsearch基本概念><strong>ElasticSearch基本概念</strong><a hidden class=anchor aria-hidden=true href=#elasticsearch基本概念>#</a></h3><h4 id=关系型数据库-vs-elasticsearch><strong>关系型数据库 VS ElasticSearch</strong><a hidden class=anchor aria-hidden=true href=#关系型数据库-vs-elasticsearch>#</a></h4><ul><li><p>在7.0之前，一个 Index可以设置多个Types</p></li><li><p>目前Type已经被Deprecated，7.0开始，一个索引只能创建一个Type - “_doc”</p></li><li><p>传统关系型数据库和Elasticsearch的区别:</p></li><li><ul><li>Elasticsearch- Schemaless /相关性/高性能全文检索</li><li>RDMS —事务性/ Join</li></ul></li></ul><p>​ <img loading=lazy src=https://note.youdao.com/yws/public/resource/d5d5718ae542f274ba0fda4284a53231/xmlnote/DA77ACFAFC764F5CB2E54E79CACE89C1/46708 alt=0></p><h4 id=索引index><strong>索引（Index）</strong><a hidden class=anchor aria-hidden=true href=#索引index>#</a></h4><p>一个索引就是一个拥有几分相似特征的文档的集合。比如说，可以有一个客户数据的索引，另一个产品目录的索引，还有一个订单数据的索引。</p><p>一个索引由一个名字来标识（必须全部是小写字母的），并且当我们要对对应于这个索引中的文档进行索引、搜索、更新和删除的时候，都要使用到这个名字。</p><p>​ <img loading=lazy src=https://note.youdao.com/yws/public/resource/d5d5718ae542f274ba0fda4284a53231/xmlnote/580D9CFF2A374482B1FC99C1C37A0954/46764 alt=0></p><h4 id=文档document><strong>文档（Document）</strong><a hidden class=anchor aria-hidden=true href=#文档document>#</a></h4><ul><li><p>Elasticsearch是面向文档的，文档是所有可搜索数据的最小单位。</p></li><li><ul><li>日志文件中的日志项</li><li>一本电影的具体信息/一张唱片的详细信息</li><li>MP3播放器里的一首歌/一篇PDF文档中的具体内容</li></ul></li><li><p>文档会被序列化成JSON格式，保存在Elasticsearch中</p></li><li><ul><li>JSON对象由字段组成</li><li>每个字段都有对应的字段类型(字符串/数值/布尔/日期/二进制/范围类型)</li></ul></li><li><p>每个文档都有一个Unique ID</p></li><li><ul><li>可以自己指定ID或者通过Elasticsearch自动生成</li></ul></li><li><p>一篇文档包含了一系列字段，类似数据库表中的一条记录</p></li><li><p>JSON文档，格式灵活，不需要预先定义格式</p></li><li><ul><li>字段的类型可以指定或者通过Elasticsearch自动推算</li><li>支持数组/支持嵌套</li></ul></li></ul><p><strong>文档元数据</strong></p><p>​ <img loading=lazy src=https://note.youdao.com/yws/public/resource/d5d5718ae542f274ba0fda4284a53231/xmlnote/E2374FCD99AF4E339344A48B40B202D3/46726 alt=0></p><p>元数据，用于标注文档的相关信息：</p><ul><li>_index：文档所属的索引名</li><li>_type：文档所属的类型名</li><li>_id：文档唯—ld</li><li>_source: 文档的原始Json数据</li><li>_version: 文档的版本号，修改删除操作_version都会自增1</li><li>_seq_no: 和_version一样，一旦数据发生更改，数据也一直是累计的。Shard级别严格递增，保证后写入的Doc的_seq_no大于先写入的Doc的_seq_no。</li><li>_primary_term: _primary_term主要是用来恢复数据时处理当多个文档的_seq_no一样时的冲突，避免Primary Shard上的写入被覆盖。每当Primary Shard发生重新分配时，比如重启，Primary选举等，_primary_term会递增1。</li></ul><h3 id=elasticsearch索引操作><strong>ElasticSearch索引操作</strong><a hidden class=anchor aria-hidden=true href=#elasticsearch索引操作>#</a></h3><p><a href=https://www.elastic.co/guide/en/elasticsearch/reference/7.17/index.html>https://www.elastic.co/guide/en/elasticsearch/reference/7.17/index.html</a></p><h4 id=创建索引><strong>创建索引</strong><a hidden class=anchor aria-hidden=true href=#创建索引>#</a></h4><p>索引命名必须小写，不能以下划线开头</p><p>格式: PUT /索引名称</p><p>​ #创建索引 PUT /es_db #创建索引时可以设置分片数和副本数 PUT /es_db { &ldquo;settings&rdquo; : { &ldquo;number_of_shards&rdquo; : 3, &ldquo;number_of_replicas&rdquo; : 2 } } #修改索引配置 PUT /es_db/_settings { &ldquo;index&rdquo; : { &ldquo;number_of_replicas&rdquo; : 1 } }</p><p>​ <img loading=lazy src=https://note.youdao.com/yws/public/resource/d5d5718ae542f274ba0fda4284a53231/xmlnote/B26A880F2C5B42D29F264DD80DDBE815/46891 alt=0></p><h4 id=查询索引><strong>查询索引</strong><a hidden class=anchor aria-hidden=true href=#查询索引>#</a></h4><p>格式: GET /索引名称</p><p>​ #查询索引 GET /es_db #es_db是否存在 HEAD /es_db</p><p>​ <img loading=lazy src=https://note.youdao.com/yws/public/resource/d5d5718ae542f274ba0fda4284a53231/xmlnote/B22F11527C874F3DBB18313D4A2E4CF9/46896 alt=0></p><p>​</p><h4 id=删除索引><strong>删除索引</strong><a hidden class=anchor aria-hidden=true href=#删除索引>#</a></h4><p>格式: DELETE /索引名称</p><p>​ DELETE /es_db</p><h3 id=elasticsearch文档操作><strong>ElasticSearch文档操作</strong><a hidden class=anchor aria-hidden=true href=#elasticsearch文档操作>#</a></h3><p>示例数据</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-shell data-lang=shell><span class=line><span class=cl>PUT /es_db
</span></span><span class=line><span class=cl><span class=o>{</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;settings&#34;</span> : <span class=o>{</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;index&#34;</span> : <span class=o>{</span>
</span></span><span class=line><span class=cl>            <span class=s2>&#34;analysis.analyzer.default.type&#34;</span>: <span class=s2>&#34;ik_max_word&#34;</span>
</span></span><span class=line><span class=cl>        <span class=o>}</span>
</span></span><span class=line><span class=cl>    <span class=o>}</span>
</span></span><span class=line><span class=cl><span class=o>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>PUT /es_db/_doc/1
</span></span><span class=line><span class=cl><span class=o>{</span>
</span></span><span class=line><span class=cl><span class=s2>&#34;name&#34;</span>: <span class=s2>&#34;张三&#34;</span>,
</span></span><span class=line><span class=cl><span class=s2>&#34;sex&#34;</span>: 1,
</span></span><span class=line><span class=cl><span class=s2>&#34;age&#34;</span>: 25,
</span></span><span class=line><span class=cl><span class=s2>&#34;address&#34;</span>: <span class=s2>&#34;广州天河公园&#34;</span>,
</span></span><span class=line><span class=cl><span class=s2>&#34;remark&#34;</span>: <span class=s2>&#34;java developer&#34;</span>
</span></span><span class=line><span class=cl><span class=o>}</span>
</span></span><span class=line><span class=cl>PUT /es_db/_doc/2
</span></span><span class=line><span class=cl><span class=o>{</span>
</span></span><span class=line><span class=cl><span class=s2>&#34;name&#34;</span>: <span class=s2>&#34;李四&#34;</span>,
</span></span><span class=line><span class=cl><span class=s2>&#34;sex&#34;</span>: 1,
</span></span><span class=line><span class=cl><span class=s2>&#34;age&#34;</span>: 28,
</span></span><span class=line><span class=cl><span class=s2>&#34;address&#34;</span>: <span class=s2>&#34;广州荔湾大厦&#34;</span>,
</span></span><span class=line><span class=cl><span class=s2>&#34;remark&#34;</span>: <span class=s2>&#34;java assistant&#34;</span>
</span></span><span class=line><span class=cl><span class=o>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>PUT /es_db/_doc/3
</span></span><span class=line><span class=cl><span class=o>{</span>
</span></span><span class=line><span class=cl><span class=s2>&#34;name&#34;</span>: <span class=s2>&#34;王五&#34;</span>,
</span></span><span class=line><span class=cl><span class=s2>&#34;sex&#34;</span>: 0,
</span></span><span class=line><span class=cl><span class=s2>&#34;age&#34;</span>: 26,
</span></span><span class=line><span class=cl><span class=s2>&#34;address&#34;</span>: <span class=s2>&#34;广州白云山公园&#34;</span>,
</span></span><span class=line><span class=cl><span class=s2>&#34;remark&#34;</span>: <span class=s2>&#34;php developer&#34;</span>
</span></span><span class=line><span class=cl><span class=o>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>PUT /es_db/_doc/4
</span></span><span class=line><span class=cl><span class=o>{</span>
</span></span><span class=line><span class=cl><span class=s2>&#34;name&#34;</span>: <span class=s2>&#34;赵六&#34;</span>,
</span></span><span class=line><span class=cl><span class=s2>&#34;sex&#34;</span>: 0,
</span></span><span class=line><span class=cl><span class=s2>&#34;age&#34;</span>: 22,
</span></span><span class=line><span class=cl><span class=s2>&#34;address&#34;</span>: <span class=s2>&#34;长沙橘子洲&#34;</span>,
</span></span><span class=line><span class=cl><span class=s2>&#34;remark&#34;</span>: <span class=s2>&#34;python assistant&#34;</span>
</span></span><span class=line><span class=cl><span class=o>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>PUT /es_db/_doc/5
</span></span><span class=line><span class=cl><span class=o>{</span>
</span></span><span class=line><span class=cl><span class=s2>&#34;name&#34;</span>: <span class=s2>&#34;张龙&#34;</span>,
</span></span><span class=line><span class=cl><span class=s2>&#34;sex&#34;</span>: 0,
</span></span><span class=line><span class=cl><span class=s2>&#34;age&#34;</span>: 19,
</span></span><span class=line><span class=cl><span class=s2>&#34;address&#34;</span>: <span class=s2>&#34;长沙麓谷企业广场&#34;</span>,
</span></span><span class=line><span class=cl><span class=s2>&#34;remark&#34;</span>: <span class=s2>&#34;java architect assistant&#34;</span>
</span></span><span class=line><span class=cl><span class=o>}</span>	
</span></span><span class=line><span class=cl>	
</span></span><span class=line><span class=cl>PUT /es_db/_doc/6
</span></span><span class=line><span class=cl><span class=o>{</span>
</span></span><span class=line><span class=cl><span class=s2>&#34;name&#34;</span>: <span class=s2>&#34;赵虎&#34;</span>,
</span></span><span class=line><span class=cl><span class=s2>&#34;sex&#34;</span>: 1,
</span></span><span class=line><span class=cl><span class=s2>&#34;age&#34;</span>: 32,
</span></span><span class=line><span class=cl><span class=s2>&#34;address&#34;</span>: <span class=s2>&#34;长沙麓谷兴工国际产业园&#34;</span>,
</span></span><span class=line><span class=cl><span class=s2>&#34;remark&#34;</span>: <span class=s2>&#34;java architect&#34;</span>
</span></span><span class=line><span class=cl><span class=o>}</span>	
</span></span></code></pre></div><p>​</p><h4 id=添加索引文档><strong>添加（索引）文档</strong><a hidden class=anchor aria-hidden=true href=#添加索引文档>#</a></h4><ul><li>格式: [PUT | POST] /索引名称/[_doc | _create ]/id</li></ul><p>​</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-shell data-lang=shell><span class=line><span class=cl><span class=c1># 创建文档,指定id</span>
</span></span><span class=line><span class=cl><span class=c1># 如果id不存在，创建新的文档，否则先删除现有文档，再创建新的文档，版本会增加</span>
</span></span><span class=line><span class=cl>PUT /es_db/_doc/1
</span></span><span class=line><span class=cl><span class=o>{</span>
</span></span><span class=line><span class=cl><span class=s2>&#34;name&#34;</span>: <span class=s2>&#34;张三&#34;</span>,
</span></span><span class=line><span class=cl><span class=s2>&#34;sex&#34;</span>: 1,
</span></span><span class=line><span class=cl><span class=s2>&#34;age&#34;</span>: 25,
</span></span><span class=line><span class=cl><span class=s2>&#34;address&#34;</span>: <span class=s2>&#34;广州天河公园&#34;</span>,
</span></span><span class=line><span class=cl><span class=s2>&#34;remark&#34;</span>: <span class=s2>&#34;java developer&#34;</span>
</span></span><span class=line><span class=cl><span class=o>}</span>	
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1>#创建文档，ES生成id</span>
</span></span><span class=line><span class=cl>POST /es_db/_doc
</span></span><span class=line><span class=cl><span class=o>{</span>
</span></span><span class=line><span class=cl><span class=s2>&#34;name&#34;</span>: <span class=s2>&#34;张三&#34;</span>,
</span></span><span class=line><span class=cl><span class=s2>&#34;sex&#34;</span>: 1,
</span></span><span class=line><span class=cl><span class=s2>&#34;age&#34;</span>: 25,
</span></span><span class=line><span class=cl><span class=s2>&#34;address&#34;</span>: <span class=s2>&#34;广州天河公园&#34;</span>,
</span></span><span class=line><span class=cl><span class=s2>&#34;remark&#34;</span>: <span class=s2>&#34;java developer&#34;</span>
</span></span><span class=line><span class=cl><span class=o>}</span>
</span></span></code></pre></div><p>​</p><p>​ <img loading=lazy src=https://note.youdao.com/yws/public/resource/d5d5718ae542f274ba0fda4284a53231/xmlnote/68EF23CFA22A430A936F39DD7D377679/46918 alt=0></p><p>注意:POST和PUT都能起到创建/更新的作用，PUT需要对一个具体的资源进行操作也就是要确定id才能进行更新/创建，而POST是可以针对整个资源集合进行操作的，如果不写id就由ES生成一个唯一id进行创建新文档，如果填了id那就针对这个id的文档进行创建/更新</p><p>​ <img loading=lazy src=https://note.youdao.com/yws/public/resource/d5d5718ae542f274ba0fda4284a53231/xmlnote/D48D0213841441F68CFCEF24B7E5B5BD/47001 alt=0></p><p>Create -如果ID已经存在，会失败</p><p>​ <img loading=lazy src=https://note.youdao.com/yws/public/resource/d5d5718ae542f274ba0fda4284a53231/xmlnote/6A82C9E9734B4F499E4A02EF835E55D5/46977 alt=0></p><h4 id=修改文档><strong>修改文档</strong><a hidden class=anchor aria-hidden=true href=#修改文档>#</a></h4><ul><li>全量更新，整个json都会替换，格式: [PUT | POST] /索引名称/_doc/id</li></ul><p>如果文档存在，现有文档会被删除，新的文档会被索引</p><p>​</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-shell data-lang=shell><span class=line><span class=cl><span class=c1># 全量更新，替换整个json</span>
</span></span><span class=line><span class=cl>PUT /es_db/_doc/1/
</span></span><span class=line><span class=cl><span class=o>{</span>
</span></span><span class=line><span class=cl><span class=s2>&#34;name&#34;</span>: <span class=s2>&#34;张三&#34;</span>,
</span></span><span class=line><span class=cl><span class=s2>&#34;sex&#34;</span>: 1,
</span></span><span class=line><span class=cl><span class=s2>&#34;age&#34;</span>: <span class=m>25</span>
</span></span><span class=line><span class=cl><span class=o>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1>#查询文档</span>
</span></span><span class=line><span class=cl>GET /es_db/_doc/1
</span></span></code></pre></div><p>​</p><p>​ <img loading=lazy src=https://note.youdao.com/yws/public/resource/d5d5718ae542f274ba0fda4284a53231/xmlnote/5A32CFADC06244E9B6FDBBE430FF5128/46942 alt=0></p><ul><li>使用_update部分更新，格式: POST /索引名称/_update/id</li></ul><p>update不会删除原来的文档，而是实现真正的数据更新</p><p>​</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-shell data-lang=shell><span class=line><span class=cl><span class=c1># 部分更新：在原有文档上更新</span>
</span></span><span class=line><span class=cl><span class=c1># Update -文档必须已经存在，更新只会对相应字段做增量修改</span>
</span></span><span class=line><span class=cl>POST /es_db/_update/1
</span></span><span class=line><span class=cl><span class=o>{</span>
</span></span><span class=line><span class=cl>  <span class=s2>&#34;doc&#34;</span>: <span class=o>{</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;age&#34;</span>: <span class=m>28</span>
</span></span><span class=line><span class=cl>  <span class=o>}</span>
</span></span><span class=line><span class=cl><span class=o>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1>#查询文档</span>
</span></span><span class=line><span class=cl>GET /es_db/_doc/1
</span></span></code></pre></div><p>​</p><p>​ <img loading=lazy src=https://note.youdao.com/yws/public/resource/d5d5718ae542f274ba0fda4284a53231/xmlnote/7CAB85271F8A4E9ABBE395FB190C0B5F/46988 alt=0></p><ul><li>使用 _update_by_query 更新文档</li></ul><p>​</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-shell data-lang=shell><span class=line><span class=cl>POST /es_db/_update_by_query
</span></span><span class=line><span class=cl><span class=o>{</span>
</span></span><span class=line><span class=cl>  <span class=s2>&#34;query&#34;</span>: <span class=o>{</span> 
</span></span><span class=line><span class=cl>    <span class=s2>&#34;match&#34;</span>: <span class=o>{</span>
</span></span><span class=line><span class=cl>      <span class=s2>&#34;_id&#34;</span>: <span class=m>1</span>
</span></span><span class=line><span class=cl>    <span class=o>}</span>
</span></span><span class=line><span class=cl>  <span class=o>}</span>,
</span></span><span class=line><span class=cl>  <span class=s2>&#34;script&#34;</span>: <span class=o>{</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;source&#34;</span>: <span class=s2>&#34;ctx._source.age = 30&#34;</span>
</span></span><span class=line><span class=cl>  <span class=o>}</span>
</span></span><span class=line><span class=cl><span class=o>}</span>
</span></span></code></pre></div><p>​</p><p>​ <img loading=lazy src=https://note.youdao.com/yws/public/resource/d5d5718ae542f274ba0fda4284a53231/xmlnote/81CD93CAB67647FD903C1628FEE322AA/47023 alt=0></p><h4 id=并发场景下修改文档><strong>并发场景下修改文档</strong><a hidden class=anchor aria-hidden=true href=#并发场景下修改文档>#</a></h4><p>_seq_no和_primary_term是对_version的优化，7.X版本的ES默认使用这种方式控制版本，所以当在高并发环境下使用乐观锁机制修改文档时，要带上当前文档的_seq_no和_primary_term进行更新：</p><p>​</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-shell data-lang=shell><span class=line><span class=cl>POST /es_db/_doc/2?if_seq_no<span class=o>=</span>21<span class=p>&amp;</span><span class=nv>if_primary_term</span><span class=o>=</span><span class=m>6</span>
</span></span><span class=line><span class=cl><span class=o>{</span>
</span></span><span class=line><span class=cl>  <span class=s2>&#34;name&#34;</span>: <span class=s2>&#34;李四xxx&#34;</span>
</span></span><span class=line><span class=cl><span class=o>}</span>
</span></span></code></pre></div><p>如果版本号不对，会抛出版本冲突异常，如下图：</p><p>​ <img loading=lazy src=https://note.youdao.com/yws/public/resource/d5d5718ae542f274ba0fda4284a53231/xmlnote/8F94246E955746C59A653F03DCC61ED1/50609 alt=0></p><h4 id=查询文档><strong>查询文档</strong><a hidden class=anchor aria-hidden=true href=#查询文档>#</a></h4><ul><li>根据id查询文档，格式: GET /索引名称/_doc/id</li></ul><div class=highlight><pre tabindex=0 class=chroma><code class=language-shell data-lang=shell><span class=line><span class=cl>GET /es_db/_doc/1             
</span></span></code></pre></div><ul><li>条件查询 _search，格式： /索引名称/_doc/_search</li></ul><div class=highlight><pre tabindex=0 class=chroma><code class=language-shell data-lang=shell><span class=line><span class=cl><span class=c1># 查询前10条文档 </span>
</span></span><span class=line><span class=cl>GET /es_db/_doc/_search   
</span></span></code></pre></div><p>​</p><p>ES Search API提供了两种条件查询搜索方式：</p><ul><li>REST风格的请求URI，直接将参数带过去</li><li>封装到request body中，这种方式可以定义更加易读的JSON格式</li></ul><p>​</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-shell data-lang=shell><span class=line><span class=cl><span class=c1>#通过URI搜索，使用“q”指定查询字符串，“query string syntax” KV键值对</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1>#条件查询, 如要查询age等于28岁的 _search?q=*:***</span>
</span></span><span class=line><span class=cl>GET /es_db/_doc/_search?q<span class=o>=</span>age:28
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1>#范围查询, 如要查询age在25至26岁之间的 _search?q=***[** TO **]  注意: TO 必须为大写</span>
</span></span><span class=line><span class=cl>GET /es_db/_doc/_search?q<span class=o>=</span>age<span class=o>[</span><span class=m>25</span> TO 26<span class=o>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1>#查询年龄小于等于28岁的 :&lt;=</span>
</span></span><span class=line><span class=cl>GET /es_db/_doc/_search?q<span class=o>=</span>age:&lt;<span class=o>=</span><span class=m>28</span>
</span></span><span class=line><span class=cl><span class=c1>#查询年龄大于28前的 :&gt;</span>
</span></span><span class=line><span class=cl>GET /es_db/_doc/_search?q<span class=o>=</span>age:&gt;28
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1>#分页查询 from=*&amp;size=*</span>
</span></span><span class=line><span class=cl>GET /es_db/_doc/_search?q<span class=o>=</span>age<span class=o>[</span><span class=m>25</span> TO 26<span class=o>]</span><span class=p>&amp;</span><span class=nv>from</span><span class=o>=</span>0<span class=p>&amp;</span><span class=nv>size</span><span class=o>=</span><span class=m>1</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1>#对查询结果只输出某些字段 _source=字段,字段</span>
</span></span><span class=line><span class=cl>GET /es_db/_doc/_search?_source<span class=o>=</span>name,age
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1>#对查询结果排序 sort=字段:desc/asc</span>
</span></span><span class=line><span class=cl>GET /es_db/_doc/_search?sort<span class=o>=</span>age:desc
</span></span></code></pre></div><p>通过请求体的搜索方式会在后面课程详细讲解（DSL）</p><p>​</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-shell data-lang=shell><span class=line><span class=cl>GET /es_db/_search
</span></span><span class=line><span class=cl><span class=o>{</span>
</span></span><span class=line><span class=cl>  <span class=s2>&#34;query&#34;</span>: <span class=o>{</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;match&#34;</span>: <span class=o>{</span>
</span></span><span class=line><span class=cl>      <span class=s2>&#34;address&#34;</span>: <span class=s2>&#34;广州白云&#34;</span>
</span></span><span class=line><span class=cl>    <span class=o>}</span>
</span></span><span class=line><span class=cl>  <span class=o>}</span>
</span></span><span class=line><span class=cl><span class=o>}</span>
</span></span></code></pre></div><h4 id=删除文档><strong>删除文档</strong><a hidden class=anchor aria-hidden=true href=#删除文档>#</a></h4><p>格式: DELETE /索引名称/_doc/id</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-shell data-lang=shell><span class=line><span class=cl>DELETE /es_db/_doc/1              
</span></span></code></pre></div><h3 id=elasticsearch文档批量操作><strong>ElasticSearch文档批量操作</strong><a hidden class=anchor aria-hidden=true href=#elasticsearch文档批量操作>#</a></h3><p>批量操作可以减少网络连接所产生的开销，提升性能</p><ul><li>支持在一次API调用中，对不同的索引进行操作</li><li>可以在URI中指定Index，也可以在请求的Payload中进行</li><li>操作中单条操作失败，并不会影响其他操作</li><li>返回结果包括了每一条操作执行的结果</li></ul><h4 id=批量写入><strong>批量写入</strong><a hidden class=anchor aria-hidden=true href=#批量写入>#</a></h4><p>批量对文档进行写操作是通过_bulk的API来实现的</p><ul><li><p>请求方式：POST</p></li><li><p>请求地址：_bulk</p></li><li><p>请求参数：通过_bulk操作文档，一般至少有两行参数(或偶数行参数)</p></li><li><ul><li>第一行参数为指定操作的类型及操作的对象(index,type和id)</li><li>第二行参数才是操作的数据</li></ul></li></ul><p>参数类似于：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-json data-lang=json><span class=line><span class=cl><span class=p>{</span><span class=nt>&#34;actionName&#34;</span><span class=p>:{</span><span class=nt>&#34;_index&#34;</span><span class=p>:</span><span class=s2>&#34;indexName&#34;</span><span class=p>,</span> <span class=nt>&#34;_type&#34;</span><span class=p>:</span><span class=s2>&#34;typeName&#34;</span><span class=p>,</span><span class=nt>&#34;_id&#34;</span><span class=p>:</span><span class=s2>&#34;id&#34;</span><span class=p>}}</span> 
</span></span><span class=line><span class=cl><span class=p>{</span><span class=nt>&#34;field1&#34;</span><span class=p>:</span><span class=s2>&#34;value1&#34;</span><span class=p>,</span> <span class=nt>&#34;field2&#34;</span><span class=p>:</span><span class=s2>&#34;value2&#34;</span><span class=p>}</span>             
</span></span></code></pre></div><ul><li>actionName：表示操作类型，主要有create,index,delete和update</li></ul><p><strong>批量创建文档create</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-shell data-lang=shell><span class=line><span class=cl>POST _bulk
</span></span><span class=line><span class=cl><span class=o>{</span><span class=s2>&#34;create&#34;</span>:<span class=o>{</span><span class=s2>&#34;_index&#34;</span>:<span class=s2>&#34;article&#34;</span>, <span class=s2>&#34;_type&#34;</span>:<span class=s2>&#34;_doc&#34;</span>, <span class=s2>&#34;_id&#34;</span>:3<span class=o>}}</span>
</span></span><span class=line><span class=cl><span class=o>{</span><span class=s2>&#34;id&#34;</span>:3,<span class=s2>&#34;title&#34;</span>:<span class=s2>&#34;fox老师&#34;</span>,<span class=s2>&#34;content&#34;</span>:<span class=s2>&#34;fox老师666&#34;</span>,<span class=s2>&#34;tags&#34;</span>:<span class=o>[</span><span class=s2>&#34;java&#34;</span>, <span class=s2>&#34;面向对象&#34;</span><span class=o>]</span>,<span class=s2>&#34;create_time&#34;</span>:1554015482530<span class=o>}</span>
</span></span><span class=line><span class=cl><span class=o>{</span><span class=s2>&#34;create&#34;</span>:<span class=o>{</span><span class=s2>&#34;_index&#34;</span>:<span class=s2>&#34;article&#34;</span>, <span class=s2>&#34;_type&#34;</span>:<span class=s2>&#34;_doc&#34;</span>, <span class=s2>&#34;_id&#34;</span>:4<span class=o>}}</span>
</span></span><span class=line><span class=cl><span class=o>{</span><span class=s2>&#34;id&#34;</span>:4,<span class=s2>&#34;title&#34;</span>:<span class=s2>&#34;mark老师&#34;</span>,<span class=s2>&#34;content&#34;</span>:<span class=s2>&#34;mark老师NB&#34;</span>,<span class=s2>&#34;tags&#34;</span>:<span class=o>[</span><span class=s2>&#34;java&#34;</span>, <span class=s2>&#34;面向对象&#34;</span><span class=o>]</span>,<span class=s2>&#34;create_time&#34;</span>:1554015482530<span class=o>}</span>
</span></span></code></pre></div><p><strong>普通创建或全量替换index</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-shell data-lang=shell><span class=line><span class=cl>POST _bulk
</span></span><span class=line><span class=cl><span class=o>{</span><span class=s2>&#34;index&#34;</span>:<span class=o>{</span><span class=s2>&#34;_index&#34;</span>:<span class=s2>&#34;article&#34;</span>, <span class=s2>&#34;_type&#34;</span>:<span class=s2>&#34;_doc&#34;</span>, <span class=s2>&#34;_id&#34;</span>:3<span class=o>}}</span>
</span></span><span class=line><span class=cl><span class=o>{</span><span class=s2>&#34;id&#34;</span>:3,<span class=s2>&#34;title&#34;</span>:<span class=s2>&#34;图灵徐庶老师&#34;</span>,<span class=s2>&#34;content&#34;</span>:<span class=s2>&#34;图灵学院徐庶老师666&#34;</span>,<span class=s2>&#34;tags&#34;</span>:<span class=o>[</span><span class=s2>&#34;java&#34;</span>, <span class=s2>&#34;面向对象&#34;</span><span class=o>]</span>,<span class=s2>&#34;create_time&#34;</span>:1554015482530<span class=o>}</span>
</span></span><span class=line><span class=cl><span class=o>{</span><span class=s2>&#34;index&#34;</span>:<span class=o>{</span><span class=s2>&#34;_index&#34;</span>:<span class=s2>&#34;article&#34;</span>, <span class=s2>&#34;_type&#34;</span>:<span class=s2>&#34;_doc&#34;</span>, <span class=s2>&#34;_id&#34;</span>:4<span class=o>}}</span>
</span></span><span class=line><span class=cl><span class=o>{</span><span class=s2>&#34;id&#34;</span>:4,<span class=s2>&#34;title&#34;</span>:<span class=s2>&#34;图灵诸葛老师&#34;</span>,<span class=s2>&#34;content&#34;</span>:<span class=s2>&#34;图灵学院诸葛老师NB&#34;</span>,<span class=s2>&#34;tags&#34;</span>:<span class=o>[</span><span class=s2>&#34;java&#34;</span>, <span class=s2>&#34;面向对象&#34;</span><span class=o>]</span>,<span class=s2>&#34;create_time&#34;</span>:1554015482530<span class=o>}</span>
</span></span></code></pre></div><ul><li>如果原文档不存在，则是创建</li><li>如果原文档存在，则是替换(全量修改原文档)</li></ul><p><strong>批量删除delete</strong></p><p>​</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-shell data-lang=shell><span class=line><span class=cl>POST _bulk
</span></span><span class=line><span class=cl><span class=o>{</span><span class=s2>&#34;delete&#34;</span>:<span class=o>{</span><span class=s2>&#34;_index&#34;</span>:<span class=s2>&#34;article&#34;</span>, <span class=s2>&#34;_type&#34;</span>:<span class=s2>&#34;_doc&#34;</span>, <span class=s2>&#34;_id&#34;</span>:3<span class=o>}}</span>
</span></span><span class=line><span class=cl><span class=o>{</span><span class=s2>&#34;delete&#34;</span>:<span class=o>{</span><span class=s2>&#34;_index&#34;</span>:<span class=s2>&#34;article&#34;</span>, <span class=s2>&#34;_type&#34;</span>:<span class=s2>&#34;_doc&#34;</span>, <span class=s2>&#34;_id&#34;</span>:4<span class=o>}}</span>
</span></span></code></pre></div><p><strong>批量修改update</strong></p><p>​</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-shell data-lang=shell><span class=line><span class=cl>POST _bulk
</span></span><span class=line><span class=cl><span class=o>{</span><span class=s2>&#34;update&#34;</span>:<span class=o>{</span><span class=s2>&#34;_index&#34;</span>:<span class=s2>&#34;article&#34;</span>, <span class=s2>&#34;_type&#34;</span>:<span class=s2>&#34;_doc&#34;</span>, <span class=s2>&#34;_id&#34;</span>:3<span class=o>}}</span>
</span></span><span class=line><span class=cl><span class=o>{</span><span class=s2>&#34;doc&#34;</span>:<span class=o>{</span><span class=s2>&#34;title&#34;</span>:<span class=s2>&#34;ES大法必修内功&#34;</span><span class=o>}}</span>
</span></span><span class=line><span class=cl><span class=o>{</span><span class=s2>&#34;update&#34;</span>:<span class=o>{</span><span class=s2>&#34;_index&#34;</span>:<span class=s2>&#34;article&#34;</span>, <span class=s2>&#34;_type&#34;</span>:<span class=s2>&#34;_doc&#34;</span>, <span class=s2>&#34;_id&#34;</span>:4<span class=o>}}</span>
</span></span><span class=line><span class=cl><span class=o>{</span><span class=s2>&#34;doc&#34;</span>:<span class=o>{</span><span class=s2>&#34;create_time&#34;</span>:1554018421008<span class=o>}}</span>
</span></span></code></pre></div><p><strong>组合应用</strong></p><p>​</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-shell data-lang=shell><span class=line><span class=cl>POST _bulk
</span></span><span class=line><span class=cl><span class=o>{</span><span class=s2>&#34;create&#34;</span>:<span class=o>{</span><span class=s2>&#34;_index&#34;</span>:<span class=s2>&#34;article&#34;</span>, <span class=s2>&#34;_type&#34;</span>:<span class=s2>&#34;_doc&#34;</span>, <span class=s2>&#34;_id&#34;</span>:3<span class=o>}}</span>
</span></span><span class=line><span class=cl><span class=o>{</span><span class=s2>&#34;id&#34;</span>:3,<span class=s2>&#34;title&#34;</span>:<span class=s2>&#34;fox老师&#34;</span>,<span class=s2>&#34;content&#34;</span>:<span class=s2>&#34;fox老师666&#34;</span>,<span class=s2>&#34;tags&#34;</span>:<span class=o>[</span><span class=s2>&#34;java&#34;</span>, <span class=s2>&#34;面向对象&#34;</span><span class=o>]</span>,<span class=s2>&#34;create_time&#34;</span>:1554015482530<span class=o>}</span>
</span></span><span class=line><span class=cl><span class=o>{</span><span class=s2>&#34;delete&#34;</span>:<span class=o>{</span><span class=s2>&#34;_index&#34;</span>:<span class=s2>&#34;article&#34;</span>, <span class=s2>&#34;_type&#34;</span>:<span class=s2>&#34;_doc&#34;</span>, <span class=s2>&#34;_id&#34;</span>:3<span class=o>}}</span>
</span></span><span class=line><span class=cl><span class=o>{</span><span class=s2>&#34;update&#34;</span>:<span class=o>{</span><span class=s2>&#34;_index&#34;</span>:<span class=s2>&#34;article&#34;</span>, <span class=s2>&#34;_type&#34;</span>:<span class=s2>&#34;_doc&#34;</span>, <span class=s2>&#34;_id&#34;</span>:4<span class=o>}}</span>
</span></span><span class=line><span class=cl><span class=o>{</span><span class=s2>&#34;doc&#34;</span>:<span class=o>{</span><span class=s2>&#34;create_time&#34;</span>:1554018421008<span class=o>}}</span>
</span></span></code></pre></div><h4 id=批量读取><strong>批量读取</strong><a hidden class=anchor aria-hidden=true href=#批量读取>#</a></h4><p>es的批量查询可以使用mget和msearch两种。其中mget是需要我们知道它的id，可以指定不同的index，也可以指定返回值source。msearch可以通过字段查询来进行一个批量的查找。</p><p><strong>_mget</strong></p><p>​</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-shell data-lang=shell><span class=line><span class=cl><span class=c1>#可以通过ID批量获取不同index和type的数据</span>
</span></span><span class=line><span class=cl>GET _mget
</span></span><span class=line><span class=cl><span class=o>{</span>
</span></span><span class=line><span class=cl><span class=s2>&#34;docs&#34;</span>: <span class=o>[</span>
</span></span><span class=line><span class=cl><span class=o>{</span>
</span></span><span class=line><span class=cl><span class=s2>&#34;_index&#34;</span>: <span class=s2>&#34;es_db&#34;</span>,
</span></span><span class=line><span class=cl><span class=s2>&#34;_id&#34;</span>: <span class=m>1</span>
</span></span><span class=line><span class=cl><span class=o>}</span>,
</span></span><span class=line><span class=cl><span class=o>{</span>
</span></span><span class=line><span class=cl><span class=s2>&#34;_index&#34;</span>: <span class=s2>&#34;article&#34;</span>,
</span></span><span class=line><span class=cl><span class=s2>&#34;_id&#34;</span>: <span class=m>4</span>
</span></span><span class=line><span class=cl><span class=o>}</span>
</span></span><span class=line><span class=cl><span class=o>]</span>
</span></span><span class=line><span class=cl><span class=o>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1>#可以通过ID批量获取es_db的数据</span>
</span></span><span class=line><span class=cl>GET /es_db/_mget
</span></span><span class=line><span class=cl><span class=o>{</span>
</span></span><span class=line><span class=cl><span class=s2>&#34;docs&#34;</span>: <span class=o>[</span>
</span></span><span class=line><span class=cl><span class=o>{</span>
</span></span><span class=line><span class=cl><span class=s2>&#34;_id&#34;</span>: <span class=m>1</span>
</span></span><span class=line><span class=cl><span class=o>}</span>,
</span></span><span class=line><span class=cl><span class=o>{</span>
</span></span><span class=line><span class=cl><span class=s2>&#34;_id&#34;</span>: <span class=m>4</span>
</span></span><span class=line><span class=cl><span class=o>}</span>
</span></span><span class=line><span class=cl><span class=o>]</span>
</span></span><span class=line><span class=cl><span class=o>}</span>
</span></span><span class=line><span class=cl><span class=c1>#简化后</span>
</span></span><span class=line><span class=cl>GET /es_db/_mget 
</span></span><span class=line><span class=cl><span class=o>{</span>
</span></span><span class=line><span class=cl> <span class=s2>&#34;ids&#34;</span>:<span class=o>[</span><span class=s2>&#34;1&#34;</span>,<span class=s2>&#34;2&#34;</span><span class=o>]</span>  
</span></span><span class=line><span class=cl> <span class=o>}</span>
</span></span></code></pre></div><p>​</p><p>​ <img loading=lazy src=https://note.youdao.com/yws/public/resource/d5d5718ae542f274ba0fda4284a53231/xmlnote/1BEA3E4F4119479199473064220508A4/47101 alt=0></p><p><strong>_msearch</strong></p><p>在_msearch中，请求格式和bulk类似。查询一条数据需要两个对象，第一个设置index和type，第二个设置查询语句。查询语句和search相同。如果只是查询一个index，我们可以在url中带上index，这样，如果查该index可以直接用空对象表示。</p><p>​</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-shell data-lang=shell><span class=line><span class=cl>GET /es_db/_msearch
</span></span><span class=line><span class=cl><span class=o>{}</span>
</span></span><span class=line><span class=cl><span class=o>{</span><span class=s2>&#34;query&#34;</span> : <span class=o>{</span><span class=s2>&#34;match_all&#34;</span> : <span class=o>{}}</span>, <span class=s2>&#34;from&#34;</span> : 0, <span class=s2>&#34;size&#34;</span> : 2<span class=o>}</span>
</span></span><span class=line><span class=cl><span class=o>{</span><span class=s2>&#34;index&#34;</span> : <span class=s2>&#34;article&#34;</span><span class=o>}</span>
</span></span><span class=line><span class=cl><span class=o>{</span><span class=s2>&#34;query&#34;</span> : <span class=o>{</span><span class=s2>&#34;match_all&#34;</span> : <span class=o>{}}}</span>
</span></span></code></pre></div><p>​ <img loading=lazy src=https://note.youdao.com/yws/public/resource/d5d5718ae542f274ba0fda4284a53231/xmlnote/B5056B6D12034C9B82F85FBF5C1B6C1F/47219 alt=0></p><h1 id=logstash与filebeat详解以及elk整合>Logstash与FileBeat详解以及ELK整合<a hidden class=anchor aria-hidden=true href=#logstash与filebeat详解以及elk整合>#</a></h1><p>链接：http://note.youdao.com/noteshare?id=cd88d72a1c76d18efcf7fe767e8c2d20&sub=D7819084A43243FFA52E8A8741795414</p><h2 id=背景><strong>背景</strong><a hidden class=anchor aria-hidden=true href=#背景>#</a></h2><p>日志管理的挑战：</p><ul><li>关注点很多，任何一个点都有可能引起问题</li><li>日志分散在很多机器，出了问题时，才发现日志被删了</li><li>很多运维人员是消防员，哪里有问题去哪里</li></ul><p>​ <img loading=lazy src=https://note.youdao.com/yws/public/resource/cd88d72a1c76d18efcf7fe767e8c2d20/xmlnote/555E578AD4284510B89ED6C5BED01290/52366 alt=0></p><p>集中化日志管理思路：</p><p>日志收集 ——》格式化分析 ——》检索和可视化 ——》 风险告警</p><h2 id=elk架构><strong>ELK架构</strong><a hidden class=anchor aria-hidden=true href=#elk架构>#</a></h2><p>ELK架构分为两种，一种是经典的ELK，另外一种是加上消息队列（Redis或Kafka或RabbitMQ）和Nginx结构。</p><h3 id=经典的elk><strong>经典的ELK</strong><a hidden class=anchor aria-hidden=true href=#经典的elk>#</a></h3><p>经典的ELK主要是由Filebeat + Logstash + Elasticsearch + Kibana组成，如下图：（早期的ELK只有Logstash + Elasticsearch + Kibana）</p><p>​ <img loading=lazy src=https://note.youdao.com/yws/public/resource/cd88d72a1c76d18efcf7fe767e8c2d20/xmlnote/CF4108CE00D049A7A1DEC19A252C4E48/49020 alt=0></p><p>此架构主要适用于数据量小的开发环境，存在数据丢失的危险。</p><h3 id=整合消息队列nginx架构><strong>整合消息队列+Nginx架构</strong><a hidden class=anchor aria-hidden=true href=#整合消息队列nginx架构>#</a></h3><p>这种架构，主要加上了Redis或Kafka或RabbitMQ做消息队列，保证了消息的不丢失。</p><p>​ <img loading=lazy src=https://note.youdao.com/yws/public/resource/cd88d72a1c76d18efcf7fe767e8c2d20/xmlnote/34FDE50C0C194DA3BCAD47E33334B27A/49019 alt=0></p><p>此种架构，主要用在生产环境，可以处理大数据量，并且不会丢失数据。</p><h2 id=什么是logstash><strong>什么是Logstash</strong><a hidden class=anchor aria-hidden=true href=#什么是logstash>#</a></h2><p>Logstash 是免费且开放的服务器端数据处理管道，能够从多个来源采集数据，转换数据，然后将数据发送到您最喜欢的存储库中。</p><p><a href=https://www.elastic.co/cn/logstash/>https://www.elastic.co/cn/logstash/</a></p><p>应用：ETL工具 / 数据采集处理引擎</p><p>​ <img loading=lazy src=https://note.youdao.com/yws/public/resource/cd88d72a1c76d18efcf7fe767e8c2d20/xmlnote/0F80346571C14E7F91557BA085D7BCF0/50524 alt=0></p><h3 id=logstash核心概念><strong>Logstash核心概念</strong><a hidden class=anchor aria-hidden=true href=#logstash核心概念>#</a></h3><p><strong>Pipeline</strong></p><ul><li>包含了input—filter-output三个阶段的处理流程</li><li>插件生命周期管理</li><li>队列管理</li></ul><p><strong>Logstash Event</strong></p><ul><li>数据在内部流转时的具体表现形式。数据在input 阶段被转换为Event，在 output被转化成目标格式数据</li><li>Event 其实是一个Java Object，在配置文件中，对Event 的属性进行增删改查</li></ul><p><strong>Codec (Code / Decode)</strong></p><p>将原始数据decode成Event;将Event encode成目标数据</p><p>​ <img loading=lazy src=https://note.youdao.com/yws/public/resource/cd88d72a1c76d18efcf7fe767e8c2d20/xmlnote/CF82CB4EAFC44D45B868DBA196A424CC/52150 alt=0></p><h3 id=logstash数据传输原理><strong>Logstash数据传输原理</strong><a hidden class=anchor aria-hidden=true href=#logstash数据传输原理>#</a></h3><ol><li>数据采集与输入：Logstash支持各种输入选择，能够以连续的流式传输方式，轻松地从日志、指标、Web应用以及数据存储中采集数据。</li><li>实时解析和数据转换：通过Logstash过滤器解析各个事件，识别已命名的字段来构建结构，并将它们转换成通用格式，最终将数据从源端传输到存储库中。</li><li>存储与数据导出：Logstash提供多种输出选择，可以将数据发送到指定的地方。</li></ol><p>Logstash通过管道完成数据的采集与处理，管道配置中包含input、output和filter（可选）插件，input和output用来配置输入和输出数据源、filter用来对数据进行过滤或预处理。</p><p>​ <img loading=lazy src=https://note.youdao.com/yws/public/resource/cd88d72a1c76d18efcf7fe767e8c2d20/xmlnote/74593B9BBD7444CD95313B5E281D1F7D/50590 alt=0></p><h3 id=logstash配置文件结构><strong>Logstash配置文件结构</strong><a hidden class=anchor aria-hidden=true href=#logstash配置文件结构>#</a></h3><p>参考：https://www.elastic.co/guide/en/logstash/7.17/configuration.html</p><p>Logstash的管道配置文件对每种类型的插件都提供了一个单独的配置部分，用于处理管道事件。</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-shell data-lang=shell><span class=line><span class=cl>input <span class=o>{</span>
</span></span><span class=line><span class=cl>  stdin <span class=o>{</span> <span class=o>}</span>
</span></span><span class=line><span class=cl><span class=o>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>filter <span class=o>{</span>
</span></span><span class=line><span class=cl>  grok <span class=o>{</span>
</span></span><span class=line><span class=cl>    <span class=nv>match</span> <span class=o>=</span>&gt; <span class=o>{</span> <span class=s2>&#34;message&#34;</span> <span class=o>=</span>&gt; <span class=s2>&#34;%{COMBINEDAPACHELOG}&#34;</span> <span class=o>}</span>
</span></span><span class=line><span class=cl>  <span class=o>}</span>
</span></span><span class=line><span class=cl>  date <span class=o>{</span>
</span></span><span class=line><span class=cl>    <span class=nv>match</span> <span class=o>=</span>&gt; <span class=o>[</span> <span class=s2>&#34;timestamp&#34;</span> , <span class=s2>&#34;dd/MMM/yyyy:HH:mm:ss Z&#34;</span> <span class=o>]</span>
</span></span><span class=line><span class=cl>  <span class=o>}</span>
</span></span><span class=line><span class=cl><span class=o>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>output <span class=o>{</span>
</span></span><span class=line><span class=cl>  elasticsearch <span class=o>{</span> <span class=nv>hosts</span> <span class=o>=</span>&gt; <span class=o>[</span><span class=s2>&#34;localhost:9200&#34;</span><span class=o>]}</span>  
</span></span><span class=line><span class=cl>  stdout <span class=o>{</span> <span class=nv>codec</span> <span class=o>=</span>&gt; rubydebug <span class=o>}</span>
</span></span><span class=line><span class=cl><span class=o>}</span>
</span></span></code></pre></div><p>每个配置部分可以包含一个或多个插件。例如，指定多个filter插件，Logstash会按照它们在配置文件中出现的顺序进行处理。</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-shell data-lang=shell><span class=line><span class=cl><span class=c1>#运行 bin/logstash -f logstash-demo.conf              </span>
</span></span></code></pre></div><p><strong>Input Plugins</strong></p><p><a href=https://www.elastic.co/guide/en/logstash/7.17/input-plugins.html>https://www.elastic.co/guide/en/logstash/7.17/input-plugins.html</a></p><p>一个 Pipeline可以有多个input插件</p><ul><li><p>Stdin / File</p></li><li><p>Beats / Log4J /Elasticsearch / JDBC / Kafka /Rabbitmq /Redis</p></li><li><p>JMX/ HTTP / Websocket / UDP / TCP</p></li><li><p>Google Cloud Storage / S3</p></li><li><p>Github / Twitter</p></li></ul><p><strong>Output Plugins</strong></p><p><a href=https://www.elastic.co/guide/en/logstash/7.17/output-plugins.html>https://www.elastic.co/guide/en/logstash/7.17/output-plugins.html</a></p><p>将Event发送到特定的目的地，是 Pipeline 的最后一个阶段。</p><p>常见 Output Plugins：</p><ul><li>Elasticsearch</li><li>Email / Pageduty</li><li>Influxdb / Kafka / Mongodb / Opentsdb / Zabbix</li><li>Http / TCP / Websocket</li></ul><p><strong>Filter Plugins</strong></p><p><a href=https://www.elastic.co/guide/en/logstash/7.17/filter-plugins.html>https://www.elastic.co/guide/en/logstash/7.17/filter-plugins.html</a></p><p>处理Event</p><p>内置的Filter Plugins:</p><ul><li>Mutate 一操作Event的字段</li><li>Metrics — Aggregate metrics</li><li>Ruby 一执行Ruby 代码</li></ul><p><strong>Codec Plugins</strong></p><p><a href=https://www.elastic.co/guide/en/logstash/7.17/codec-plugins.html>https://www.elastic.co/guide/en/logstash/7.17/codec-plugins.html</a></p><p>将原始数据decode成Event;将Event encode成目标数据</p><p>内置的Codec Plugins:</p><ul><li>Line / Multiline</li><li>JSON / Avro / Cef (ArcSight Common Event Format)</li><li>Dots / Rubydebug</li></ul><h3 id=logstash-queue><strong>Logstash Queue</strong><a hidden class=anchor aria-hidden=true href=#logstash-queue>#</a></h3><ul><li>In Memory Queue</li></ul><p>进程Crash，机器宕机，都会引起数据的丢失</p><ul><li>Persistent Queue</li></ul><p>机器宕机，数据也不会丢失; 数据保证会被消费; 可以替代 Kafka等消息队列缓冲区的作用</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-shell data-lang=shell><span class=line><span class=cl>queue.type: persisted <span class=o>(</span>默认是memory<span class=o>)</span>
</span></span><span class=line><span class=cl>queue.max_bytes: 4gb
</span></span></code></pre></div><p>​ <img loading=lazy src=https://note.youdao.com/yws/public/resource/cd88d72a1c76d18efcf7fe767e8c2d20/xmlnote/CE4E688F6DF84A129F3F289048E0376D/52192 alt=0></p><h3 id=logstash安装><strong>Logstash安装</strong><a hidden class=anchor aria-hidden=true href=#logstash安装>#</a></h3><p>logstash官方文档: <a href=https://www.elastic.co/guide/en/logstash/7.17/installing-logstash.html>https://www.elastic.co/guide/en/logstash/7.17/installing-logstash.html</a></p><h4 id=1下载并解压logstash><strong>1）下载并解压logstash</strong><a hidden class=anchor aria-hidden=true href=#1下载并解压logstash>#</a></h4><p>下载地址： <a href=https://www.elastic.co/cn/downloads/past-releases#logstash>https://www.elastic.co/cn/downloads/past-releases#logstash</a></p><p>选择版本：7.17.3</p><p>​ <img loading=lazy src=https://note.youdao.com/yws/public/resource/cd88d72a1c76d18efcf7fe767e8c2d20/xmlnote/947FADB0499C4461A8037B0DB7A68053/50498 alt=0></p><h4 id=2测试运行最基本的logstash管道><strong>2）测试：运行最基本的logstash管道</strong><a hidden class=anchor aria-hidden=true href=#2测试运行最基本的logstash管道>#</a></h4><p>​</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-shell data-lang=shell><span class=line><span class=cl><span class=nb>cd</span> logstash-7.17.3
</span></span><span class=line><span class=cl><span class=c1>#linux</span>
</span></span><span class=line><span class=cl><span class=c1>#-e选项表示，直接把配置放在命令中，这样可以有效快速进行测试</span>
</span></span><span class=line><span class=cl>bin/logstash -e <span class=s1>&#39;input { stdin { } } output { stdout {} }&#39;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1>#windows</span>
</span></span><span class=line><span class=cl>.<span class=se>\b</span>in<span class=se>\l</span>ogstash.bat -e <span class=s2>&#34;input { stdin { } } output { stdout {} }&#34;</span>
</span></span></code></pre></div><p>​</p><p>测试结果：</p><p>​ <img loading=lazy src=https://note.youdao.com/yws/public/resource/cd88d72a1c76d18efcf7fe767e8c2d20/xmlnote/7C245A3C48024C4484A8CAAA10DE9C1F/50564 alt=0></p><p><strong>window版本的logstash-7.17.3的bug:</strong></p><p>windows出现错误提示could not find java; set JAVA_HOME or ensure java is in PATH</p><p>​ <img loading=lazy src=https://note.youdao.com/yws/public/resource/cd88d72a1c76d18efcf7fe767e8c2d20/xmlnote/4F3E54A6E6BA4D9F95F6BEFF301F164A/50547 alt=0></p><p>修改setup.bat</p><p>​ <img loading=lazy src=https://note.youdao.com/yws/public/resource/cd88d72a1c76d18efcf7fe767e8c2d20/xmlnote/823CA03558EE4C65812B9F44E6FC36B9/50544 alt=0></p><p>​ <img loading=lazy src=https://note.youdao.com/yws/public/resource/cd88d72a1c76d18efcf7fe767e8c2d20/xmlnote/ACF40D5ED8C84C23B2F268480BE69F04/50556 alt=0></p><p><strong>Codec Plugin测试</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-shell data-lang=shell><span class=line><span class=cl><span class=c1># single line</span>
</span></span><span class=line><span class=cl>bin/logstash -e <span class=s2>&#34;input{stdin{codec=&gt;line}}output{stdout{codec=&gt; rubydebug}}&#34;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>bin/logstash -e <span class=s2>&#34;input{stdin{codec=&gt;json}}output{stdout{codec=&gt; rubydebug}}&#34;</span>
</span></span></code></pre></div><p>​</p><p><strong>Codec Plugin —— Multiline</strong></p><p>设置参数:</p><ul><li><p>pattern: 设置行匹配的正则表达式</p></li><li><p>what : 如果匹配成功，那么匹配行属于上一个事件还是下一个事件</p></li><li><ul><li>previous / next</li></ul></li><li><p>negate : 是否对pattern结果取反</p></li><li><ul><li>true / false</li></ul></li></ul><p>​</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-shell data-lang=shell><span class=line><span class=cl><span class=c1># 多行数据，异常</span>
</span></span><span class=line><span class=cl>Exception in thread <span class=s2>&#34;main&#34;</span> java.lang.NullPointerException
</span></span><span class=line><span class=cl>        at com.example.myproject.Book.getTitle<span class=o>(</span>Book.java:16<span class=o>)</span>
</span></span><span class=line><span class=cl>        at com.example.myproject.Author.getBookTitles<span class=o>(</span>Author.java:25<span class=o>)</span>
</span></span><span class=line><span class=cl>        at com.example.myproject.Bootstrap.main<span class=o>(</span>Bootstrap.java:14<span class=o>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># multiline-exception.conf</span>
</span></span><span class=line><span class=cl>input <span class=o>{</span>
</span></span><span class=line><span class=cl>  stdin <span class=o>{</span>
</span></span><span class=line><span class=cl>    <span class=nv>codec</span> <span class=o>=</span>&gt; multiline <span class=o>{</span>
</span></span><span class=line><span class=cl>      <span class=nv>pattern</span> <span class=o>=</span>&gt; <span class=s2>&#34;^\s&#34;</span>
</span></span><span class=line><span class=cl>      <span class=nv>what</span> <span class=o>=</span>&gt; <span class=s2>&#34;previous&#34;</span>
</span></span><span class=line><span class=cl>    <span class=o>}</span>
</span></span><span class=line><span class=cl>  <span class=o>}</span>
</span></span><span class=line><span class=cl><span class=o>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>filter <span class=o>{}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>output <span class=o>{</span>
</span></span><span class=line><span class=cl>  stdout <span class=o>{</span> <span class=nv>codec</span> <span class=o>=</span>&gt; rubydebug <span class=o>}</span>
</span></span><span class=line><span class=cl><span class=o>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1>#执行管道</span>
</span></span><span class=line><span class=cl>bin/logstash -f multiline-exception.conf
</span></span></code></pre></div><p><strong>Input Plugin —— File</strong></p><ul><li>支持从文件中读取数据，如日志文件</li><li>文件读取需要解决的问题：只被读取一次。重启后需要从上次读取的位置继续(通过sincedb 实现)</li><li>读取到文件新内容，发现新文件</li><li>文件发生归档操作(文档位置发生变化，日志rotation)，不能影响当前的内容读取</li></ul><p><strong>Filter Plugin</strong></p><p>Filter Plugin可以对Logstash Event进行各种处理，例如解析，删除字段，类型转换</p><ul><li>Date: 日期解析</li><li>Dissect: 分割符解析</li><li>Grok: 正则匹配解析</li><li>Mutate: 处理字段。重命名，删除，替换</li><li>Ruby: 利用Ruby 代码来动态修改Event</li></ul><p><strong>Filter Plugin - Mutate</strong></p><p>对字段做各种操作:</p><ul><li>Convert : 类型转换</li><li>Gsub : 字符串替换</li><li>Split / Join /Merge: 字符串切割，数组合并字符串，数组合并数组</li><li>Rename: 字段重命名</li><li>Update / Replace: 字段内容更新替换</li><li>Remove_field: 字段删除</li></ul><h3 id=logstash导入数据到es><strong>Logstash导入数据到ES</strong><a hidden class=anchor aria-hidden=true href=#logstash导入数据到es>#</a></h3><p>1）测试数据集下载：https://grouplens.org/datasets/movielens/</p><p>​ <img loading=lazy src=https://note.youdao.com/yws/public/resource/cd88d72a1c76d18efcf7fe767e8c2d20/xmlnote/FB13DC8EC34E40CBBE6E7092BC410E74/50573 alt=0></p><p>2）准备logstash-movie.conf配置文件</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-shell data-lang=shell><span class=line><span class=cl>input <span class=o>{</span>
</span></span><span class=line><span class=cl>  file <span class=o>{</span>
</span></span><span class=line><span class=cl>    <span class=nv>path</span> <span class=o>=</span>&gt; <span class=s2>&#34;/home/es/logstash-7.17.3/dataset/movies.csv&#34;</span>
</span></span><span class=line><span class=cl>    <span class=nv>start_position</span> <span class=o>=</span>&gt; <span class=s2>&#34;beginning&#34;</span>
</span></span><span class=line><span class=cl>    <span class=nv>sincedb_path</span> <span class=o>=</span>&gt; <span class=s2>&#34;/dev/null&#34;</span>
</span></span><span class=line><span class=cl>  <span class=o>}</span>
</span></span><span class=line><span class=cl><span class=o>}</span>
</span></span><span class=line><span class=cl>filter <span class=o>{</span>
</span></span><span class=line><span class=cl>  csv <span class=o>{</span>
</span></span><span class=line><span class=cl>    <span class=nv>separator</span> <span class=o>=</span>&gt; <span class=s2>&#34;,&#34;</span>
</span></span><span class=line><span class=cl>    <span class=nv>columns</span> <span class=o>=</span>&gt; <span class=o>[</span><span class=s2>&#34;id&#34;</span>,<span class=s2>&#34;content&#34;</span>,<span class=s2>&#34;genre&#34;</span><span class=o>]</span>
</span></span><span class=line><span class=cl>  <span class=o>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  mutate <span class=o>{</span>
</span></span><span class=line><span class=cl>    <span class=nv>split</span> <span class=o>=</span>&gt; <span class=o>{</span> <span class=s2>&#34;genre&#34;</span> <span class=o>=</span>&gt; <span class=s2>&#34;|&#34;</span> <span class=o>}</span>
</span></span><span class=line><span class=cl>    <span class=nv>remove_field</span> <span class=o>=</span>&gt; <span class=o>[</span><span class=s2>&#34;path&#34;</span>, <span class=s2>&#34;host&#34;</span>,<span class=s2>&#34;@timestamp&#34;</span>,<span class=s2>&#34;message&#34;</span><span class=o>]</span>
</span></span><span class=line><span class=cl>  <span class=o>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  mutate <span class=o>{</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=nv>split</span> <span class=o>=</span>&gt; <span class=o>[</span><span class=s2>&#34;content&#34;</span>, <span class=s2>&#34;(&#34;</span><span class=o>]</span>
</span></span><span class=line><span class=cl>    <span class=nv>add_field</span> <span class=o>=</span>&gt; <span class=o>{</span> <span class=s2>&#34;title&#34;</span> <span class=o>=</span>&gt; <span class=s2>&#34;%{[content][0]}&#34;</span><span class=o>}</span>
</span></span><span class=line><span class=cl>    <span class=nv>add_field</span> <span class=o>=</span>&gt; <span class=o>{</span> <span class=s2>&#34;year&#34;</span> <span class=o>=</span>&gt; <span class=s2>&#34;%{[content][1]}&#34;</span><span class=o>}</span>
</span></span><span class=line><span class=cl>  <span class=o>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  mutate <span class=o>{</span>
</span></span><span class=line><span class=cl>    <span class=nv>convert</span> <span class=o>=</span>&gt; <span class=o>{</span>
</span></span><span class=line><span class=cl>      <span class=s2>&#34;year&#34;</span> <span class=o>=</span>&gt; <span class=s2>&#34;integer&#34;</span>
</span></span><span class=line><span class=cl>    <span class=o>}</span>
</span></span><span class=line><span class=cl>    <span class=nv>strip</span> <span class=o>=</span>&gt; <span class=o>[</span><span class=s2>&#34;title&#34;</span><span class=o>]</span>
</span></span><span class=line><span class=cl>    <span class=nv>remove_field</span> <span class=o>=</span>&gt; <span class=o>[</span><span class=s2>&#34;path&#34;</span>, <span class=s2>&#34;host&#34;</span>,<span class=s2>&#34;@timestamp&#34;</span>,<span class=s2>&#34;message&#34;</span>,<span class=s2>&#34;content&#34;</span><span class=o>]</span>
</span></span><span class=line><span class=cl>  <span class=o>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=o>}</span>
</span></span><span class=line><span class=cl>output <span class=o>{</span>
</span></span><span class=line><span class=cl>   elasticsearch <span class=o>{</span>
</span></span><span class=line><span class=cl>     <span class=nv>hosts</span> <span class=o>=</span>&gt; <span class=s2>&#34;http://localhost:9200&#34;</span>
</span></span><span class=line><span class=cl>     <span class=nv>index</span> <span class=o>=</span>&gt; <span class=s2>&#34;movies&#34;</span>
</span></span><span class=line><span class=cl>     <span class=nv>document_id</span> <span class=o>=</span>&gt; <span class=s2>&#34;%{id}&#34;</span>
</span></span><span class=line><span class=cl>     <span class=nv>user</span> <span class=o>=</span>&gt; <span class=s2>&#34;elastic&#34;</span>
</span></span><span class=line><span class=cl>     <span class=nv>password</span> <span class=o>=</span>&gt; <span class=s2>&#34;123456&#34;</span>
</span></span><span class=line><span class=cl>   <span class=o>}</span>
</span></span><span class=line><span class=cl>  stdout <span class=o>{}</span>
</span></span><span class=line><span class=cl><span class=o>}</span>
</span></span></code></pre></div><p>​</p><p>3）运行logstash</p><p>​</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-shell data-lang=shell><span class=line><span class=cl><span class=c1># linux bin/logstash -f logstash-movie.conf     </span>
</span></span></code></pre></div><p>​</p><h3 id=同步数据库数据到elasticsearch><strong>同步数据库数据到Elasticsearch</strong><a hidden class=anchor aria-hidden=true href=#同步数据库数据到elasticsearch>#</a></h3><p>需求: 将数据库中的数据同步到ES，借助ES的全文搜索,提高搜索速度</p><ul><li>需要把新增用户信息同步到Elasticsearch中</li><li>用户信息Update 后，需要能被更新到Elasticsearch</li><li>支持增量更新</li><li>用户注销后，不能被ES所搜索到</li></ul><p><strong>实现思路</strong></p><ul><li><p>基于canal同步数据（项目实战中讲解）</p></li><li><p>借助JDBC Input Plugin将数据从数据库读到Logstash</p></li><li><ul><li>需要自己提供所需的 JDBC Driver；</li><li>JDBC Input Plugin 支持定时任务 Scheduling，其语法来自 Rufus-scheduler，其扩展了 Cron，使用 Cron 的语法可以完成任务的触发；</li><li>JDBC Input Plugin 支持通过 Tracking_column / sql_last_value 的方式记录 State，最终实现增量的更新；</li><li><a href=https://www.elastic.co/cn/blog/logstash-jdbc-input-plugin>https://www.elastic.co/cn/blog/logstash-jdbc-input-plugin</a></li></ul></li></ul><p><strong>JDBC Input Plugin实现步骤</strong></p><p>1）拷贝jdbc依赖到logstash-7.17.3/drivers目录下</p><p>2）准备mysql-demo.conf配置文件</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-shell data-lang=shell><span class=line><span class=cl>input <span class=o>{</span>
</span></span><span class=line><span class=cl>  jdbc <span class=o>{</span>
</span></span><span class=line><span class=cl>    <span class=nv>jdbc_driver_library</span> <span class=o>=</span>&gt; <span class=s2>&#34;/home/es/logstash-7.17.3/drivers/mysql-connector-java-5.1.49.jar&#34;</span>
</span></span><span class=line><span class=cl>    <span class=nv>jdbc_driver_class</span> <span class=o>=</span>&gt; <span class=s2>&#34;com.mysql.jdbc.Driver&#34;</span>
</span></span><span class=line><span class=cl>    <span class=nv>jdbc_connection_string</span> <span class=o>=</span>&gt; <span class=s2>&#34;jdbc:mysql://localhost:3306/test?useSSL=false&#34;</span>
</span></span><span class=line><span class=cl>    <span class=nv>jdbc_user</span> <span class=o>=</span>&gt; <span class=s2>&#34;root&#34;</span>
</span></span><span class=line><span class=cl>    <span class=nv>jdbc_password</span> <span class=o>=</span>&gt; <span class=s2>&#34;123456&#34;</span>
</span></span><span class=line><span class=cl>    <span class=c1>#启用追踪，如果为true，则需要指定tracking_column</span>
</span></span><span class=line><span class=cl>    <span class=nv>use_column_value</span> <span class=o>=</span>&gt; <span class=nb>true</span>
</span></span><span class=line><span class=cl>    <span class=c1>#指定追踪的字段，</span>
</span></span><span class=line><span class=cl>    <span class=nv>tracking_column</span> <span class=o>=</span>&gt; <span class=s2>&#34;last_updated&#34;</span>
</span></span><span class=line><span class=cl>    <span class=c1>#追踪字段的类型，目前只有数字(numeric)和时间类型(timestamp)，默认是数字类型</span>
</span></span><span class=line><span class=cl>    <span class=nv>tracking_column_type</span> <span class=o>=</span>&gt; <span class=s2>&#34;numeric&#34;</span>
</span></span><span class=line><span class=cl>    <span class=c1>#记录最后一次运行的结果</span>
</span></span><span class=line><span class=cl>    <span class=nv>record_last_run</span> <span class=o>=</span>&gt; <span class=nb>true</span>
</span></span><span class=line><span class=cl>    <span class=c1>#上面运行结果的保存位置</span>
</span></span><span class=line><span class=cl>    <span class=nv>last_run_metadata_path</span> <span class=o>=</span>&gt; <span class=s2>&#34;jdbc-position.txt&#34;</span>
</span></span><span class=line><span class=cl>    <span class=nv>statement</span> <span class=o>=</span>&gt; <span class=s2>&#34;SELECT * FROM user where last_updated &gt;:sql_last_value;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=nv>schedule</span> <span class=o>=</span>&gt; <span class=s2>&#34; * * * * * *&#34;</span>
</span></span><span class=line><span class=cl>  <span class=o>}</span>
</span></span><span class=line><span class=cl><span class=o>}</span>
</span></span><span class=line><span class=cl>output <span class=o>{</span>
</span></span><span class=line><span class=cl>  elasticsearch <span class=o>{</span>
</span></span><span class=line><span class=cl>    <span class=nv>document_id</span> <span class=o>=</span>&gt; <span class=s2>&#34;%{id}&#34;</span>
</span></span><span class=line><span class=cl>    <span class=nv>document_type</span> <span class=o>=</span>&gt; <span class=s2>&#34;_doc&#34;</span>
</span></span><span class=line><span class=cl>    <span class=nv>index</span> <span class=o>=</span>&gt; <span class=s2>&#34;users&#34;</span>
</span></span><span class=line><span class=cl>    <span class=nv>hosts</span> <span class=o>=</span>&gt; <span class=o>[</span><span class=s2>&#34;http://localhost:9200&#34;</span><span class=o>]</span>
</span></span><span class=line><span class=cl>    <span class=nv>user</span> <span class=o>=</span>&gt; <span class=s2>&#34;elastic&#34;</span>
</span></span><span class=line><span class=cl>    <span class=nv>password</span> <span class=o>=</span>&gt; <span class=s2>&#34;123456&#34;</span>
</span></span><span class=line><span class=cl>  <span class=o>}</span>
</span></span><span class=line><span class=cl>  stdout<span class=o>{</span>
</span></span><span class=line><span class=cl>    <span class=nv>codec</span> <span class=o>=</span>&gt; rubydebug
</span></span><span class=line><span class=cl>  <span class=o>}</span>
</span></span><span class=line><span class=cl><span class=o>}</span>
</span></span></code></pre></div><p>3）运行logstash</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-shell data-lang=shell><span class=line><span class=cl>bin/logstash -f mysql-demo.conf           
</span></span></code></pre></div><p><img loading=lazy src=https://note.youdao.com/yws/public/resource/cd88d72a1c76d18efcf7fe767e8c2d20/xmlnote/0283538D60E14EFAA693BAA42277AC11/52312 alt=0></p><p>测试</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-sql data-lang=sql><span class=line><span class=cl><span class=o>#</span><span class=n>user表</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=k>CREATE</span><span class=w> </span><span class=k>TABLE</span><span class=w> </span><span class=o>`</span><span class=k>user</span><span class=o>`</span><span class=w> </span><span class=p>(</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=o>`</span><span class=n>id</span><span class=o>`</span><span class=w> </span><span class=nb>int</span><span class=w> </span><span class=k>NOT</span><span class=w> </span><span class=k>NULL</span><span class=w> </span><span class=n>AUTO_INCREMENT</span><span class=p>,</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=o>`</span><span class=n>name</span><span class=o>`</span><span class=w> </span><span class=nb>varchar</span><span class=p>(</span><span class=mi>50</span><span class=p>)</span><span class=w> </span><span class=k>DEFAULT</span><span class=w> </span><span class=k>NULL</span><span class=p>,</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=o>`</span><span class=n>address</span><span class=o>`</span><span class=w> </span><span class=nb>varchar</span><span class=p>(</span><span class=mi>50</span><span class=p>)</span><span class=w> </span><span class=nb>CHARACTER</span><span class=w> </span><span class=k>DEFAULT</span><span class=w> </span><span class=k>NULL</span><span class=p>,</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=o>`</span><span class=n>last_updated</span><span class=o>`</span><span class=w> </span><span class=nb>bigint</span><span class=w> </span><span class=k>DEFAULT</span><span class=w> </span><span class=k>NULL</span><span class=p>,</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=o>`</span><span class=n>is_deleted</span><span class=o>`</span><span class=w> </span><span class=nb>int</span><span class=w> </span><span class=k>DEFAULT</span><span class=w> </span><span class=k>NULL</span><span class=p>,</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=k>PRIMARY</span><span class=w> </span><span class=k>KEY</span><span class=w> </span><span class=p>(</span><span class=o>`</span><span class=n>id</span><span class=o>`</span><span class=p>)</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=p>)</span><span class=w> </span><span class=n>ENGINE</span><span class=o>=</span><span class=n>InnoDB</span><span class=w> </span><span class=n>AUTO_INCREMENT</span><span class=o>=</span><span class=mi>2</span><span class=w> </span><span class=k>DEFAULT</span><span class=w> </span><span class=n>CHARSET</span><span class=o>=</span><span class=n>utf8mb4</span><span class=w> </span><span class=k>COLLATE</span><span class=o>=</span><span class=n>utf8mb4_0900_ai_ci</span><span class=p>;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=o>#</span><span class=err>插入数据</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=k>INSERT</span><span class=w> </span><span class=k>INTO</span><span class=w> </span><span class=k>user</span><span class=p>(</span><span class=n>name</span><span class=p>,</span><span class=n>address</span><span class=p>,</span><span class=n>last_updated</span><span class=p>,</span><span class=n>is_deleted</span><span class=p>)</span><span class=w> </span><span class=k>VALUES</span><span class=p>(</span><span class=s2>&#34;张三&#34;</span><span class=p>,</span><span class=s2>&#34;广州天河&#34;</span><span class=p>,</span><span class=n>unix_timestamp</span><span class=p>(</span><span class=n>NOW</span><span class=p>()),</span><span class=mi>0</span><span class=p>)</span><span class=w>
</span></span></span></code></pre></div><p>​ <img loading=lazy src=https://note.youdao.com/yws/public/resource/cd88d72a1c76d18efcf7fe767e8c2d20/xmlnote/63AD9310E21343A8BAA846C84661E31F/52314 alt=0></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-sql data-lang=sql><span class=line><span class=cl><span class=o>#</span><span class=w> </span><span class=err>更新</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=k>update</span><span class=w> </span><span class=k>user</span><span class=w> </span><span class=k>set</span><span class=w> </span><span class=n>address</span><span class=o>=</span><span class=s2>&#34;广州白云山&#34;</span><span class=p>,</span><span class=n>last_updated</span><span class=o>=</span><span class=n>unix_timestamp</span><span class=p>(</span><span class=n>NOW</span><span class=p>())</span><span class=w> </span><span class=k>where</span><span class=w> </span><span class=n>name</span><span class=o>=</span><span class=s2>&#34;张三&#34;</span><span class=w>
</span></span></span></code></pre></div><p>​</p><p>​ <img loading=lazy src=https://note.youdao.com/yws/public/resource/cd88d72a1c76d18efcf7fe767e8c2d20/xmlnote/0BACB4E2B47345698F97C332779954FF/52326 alt=0></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-sql data-lang=sql><span class=line><span class=cl><span class=o>#</span><span class=err>删除</span><span class=w> 
</span></span></span><span class=line><span class=cl><span class=w></span><span class=k>update</span><span class=w> </span><span class=k>user</span><span class=w> </span><span class=k>set</span><span class=w> </span><span class=n>is_deleted</span><span class=o>=</span><span class=mi>1</span><span class=p>,</span><span class=n>last_updated</span><span class=o>=</span><span class=n>unix_timestamp</span><span class=p>(</span><span class=n>NOW</span><span class=p>())</span><span class=w> </span><span class=k>where</span><span class=w> </span><span class=n>name</span><span class=o>=</span><span class=s2>&#34;张三&#34;</span><span class=w>           
</span></span></span></code></pre></div><p>​ <img loading=lazy src=https://note.youdao.com/yws/public/resource/cd88d72a1c76d18efcf7fe767e8c2d20/xmlnote/8D6ED1B8A61240AE8934C7DFB2F78AB0/52334 alt=0></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-shell data-lang=shell><span class=line><span class=cl><span class=c1>#ES中查询</span>
</span></span><span class=line><span class=cl><span class=c1># 创建 alias，只显示没有被标记 deleted的用户</span>
</span></span><span class=line><span class=cl>POST /_aliases
</span></span><span class=line><span class=cl><span class=o>{</span>
</span></span><span class=line><span class=cl>  <span class=s2>&#34;actions&#34;</span>: <span class=o>[</span>
</span></span><span class=line><span class=cl>    <span class=o>{</span>
</span></span><span class=line><span class=cl>      <span class=s2>&#34;add&#34;</span>: <span class=o>{</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;index&#34;</span>: <span class=s2>&#34;users&#34;</span>,
</span></span><span class=line><span class=cl>        <span class=s2>&#34;alias&#34;</span>: <span class=s2>&#34;view_users&#34;</span>,
</span></span><span class=line><span class=cl>         <span class=s2>&#34;filter&#34;</span> : <span class=o>{</span> <span class=s2>&#34;term&#34;</span> : <span class=o>{</span> <span class=s2>&#34;is_deleted&#34;</span> : 0<span class=o>}</span> <span class=o>}</span>
</span></span><span class=line><span class=cl>      <span class=o>}</span>
</span></span><span class=line><span class=cl>    <span class=o>}</span>
</span></span><span class=line><span class=cl>  <span class=o>]</span>
</span></span><span class=line><span class=cl><span class=o>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 通过 Alias查询，查不到被标记成 deleted的用户</span>
</span></span><span class=line><span class=cl>POST view_users/_search
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>POST view_users/_search
</span></span><span class=line><span class=cl><span class=o>{</span>
</span></span><span class=line><span class=cl>  <span class=s2>&#34;query&#34;</span>: <span class=o>{</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;term&#34;</span>: <span class=o>{</span>
</span></span><span class=line><span class=cl>      <span class=s2>&#34;name.keyword&#34;</span>: <span class=o>{</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;value&#34;</span>: <span class=s2>&#34;张三&#34;</span>
</span></span><span class=line><span class=cl>      <span class=o>}</span>
</span></span><span class=line><span class=cl>    <span class=o>}</span>
</span></span><span class=line><span class=cl>  <span class=o>}</span>
</span></span><span class=line><span class=cl><span class=o>}</span>
</span></span></code></pre></div><p>​</p><h2 id=什么是beats><strong>什么是Beats</strong><a hidden class=anchor aria-hidden=true href=#什么是beats>#</a></h2><p>轻量型数据采集器，文档地址： <a href=https://www.elastic.co/guide/en/beats/libbeat/7.17/index.html>https://www.elastic.co/guide/en/beats/libbeat/7.17/index.html</a></p><p>Beats 是一个免费且开放的平台，集合了多种单一用途的数据采集器。它们从成百上千或成千上万台机器和系统向 Logstash 或 Elasticsearch 发送数据。</p><p>​ <img loading=lazy src=https://note.youdao.com/yws/public/resource/cd88d72a1c76d18efcf7fe767e8c2d20/xmlnote/35F887BBDE2547EDB65BC5144FAA26F2/52346 alt=0></p><h4 id=filebeat简介><strong>FileBeat简介</strong><a hidden class=anchor aria-hidden=true href=#filebeat简介>#</a></h4><p>FileBeat专门用于转发和收集日志数据的轻量级采集工具。它可以作为代理安装在服务器上，FileBeat监视指定路径的日志文件，收集日志数据，并将收集到的日志转发到Elasticsearch或者Logstash。</p><h4 id=filebeat的工作原理><strong>FileBeat的工作原理</strong><a hidden class=anchor aria-hidden=true href=#filebeat的工作原理>#</a></h4><p>启动FileBeat时，会启动一个或者多个输入（Input），这些Input监控指定的日志数据位置。FileBeat会针对每一个文件启动一个Harvester（收割机）。Harvester读取每一个文件的日志，将新的日志发送到libbeat，libbeat将数据收集到一起，并将数据发送给输出（Output）。</p><p>​ <img loading=lazy src=https://note.youdao.com/yws/public/resource/cd88d72a1c76d18efcf7fe767e8c2d20/xmlnote/867736E6C783400A8BEFF89B901CC427/52385 alt=0></p><h4 id=logstash-vs-filebeat><strong>logstash vs FileBeat</strong><a hidden class=anchor aria-hidden=true href=#logstash-vs-filebeat>#</a></h4><ul><li>Logstash是在jvm上运行的，资源消耗比较大。而FileBeat是基于golang编写的，功能较少但资源消耗也比较小，更轻量级。</li><li>Logstash 和Filebeat都具有日志收集功能，Filebeat更轻量，占用资源更少</li><li>Logstash 具有Filter功能，能过滤分析日志</li><li>一般结构都是Filebeat采集日志，然后发送到消息队列、Redis、MQ中，然后Logstash去获取，利用Filter功能过滤分析，然后存储到Elasticsearch中</li><li>FileBeat和Logstash配合，实现背压机制。当将数据发送到Logstash或 Elasticsearch时，Filebeat使用背压敏感协议，以应对更多的数据量。如果Logstash正在忙于处理数据，则会告诉Filebeat 减慢读取速度。一旦拥堵得到解决，Filebeat就会恢复到原来的步伐并继续传输数据。</li></ul><h4 id=filebeat安装><strong>Filebeat安装</strong><a hidden class=anchor aria-hidden=true href=#filebeat安装>#</a></h4><p><a href=https://www.elastic.co/guide/en/beats/filebeat/7.17/filebeat-installation-configuration.html>https://www.elastic.co/guide/en/beats/filebeat/7.17/filebeat-installation-configuration.html</a></p><p><strong>1）下载并解压Filebeat</strong></p><p>下载地址：https://www.elastic.co/cn/downloads/past-releases#filebeat</p><p>选择版本：7.17.3</p><p>​ <img loading=lazy src=https://note.youdao.com/yws/public/resource/cd88d72a1c76d18efcf7fe767e8c2d20/xmlnote/A056706105A64F20B051E42986D0EEF0/50501 alt=0></p><p><strong>2）编辑配置</strong></p><p>修改 filebeat.yml 以设置连接信息：</p><p>​</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-yaml data-lang=yaml><span class=line><span class=cl><span class=nt>output.elasticsearch</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>hosts</span><span class=p>:</span><span class=w> </span><span class=p>[</span><span class=s2>&#34;192.168.65.174:9200&#34;</span><span class=p>,</span><span class=s2>&#34;192.168.65.192:9200&#34;</span><span class=p>,</span><span class=s2>&#34;192.168.65.204:9200&#34;</span><span class=p>]</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>username</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;elastic&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>password</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;123456&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nt>setup.kibana</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>host</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;192.168.65.174:5601&#34;</span><span class=w>
</span></span></span></code></pre></div><p>​</p><p><strong>3) 启用和配置数据收集模块</strong></p><p>从安装目录中，运行：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-shell data-lang=shell><span class=line><span class=cl><span class=c1># 查看可以模块列表</span>
</span></span><span class=line><span class=cl>./filebeat modules list
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1>#启用nginx模块</span>
</span></span><span class=line><span class=cl>./filebeat modules <span class=nb>enable</span> nginx
</span></span><span class=line><span class=cl><span class=c1>#如果需要更改nginx日志路径,修改modules.d/nginx.yml</span>
</span></span><span class=line><span class=cl>- module: nginx
</span></span><span class=line><span class=cl>  access:
</span></span><span class=line><span class=cl>    var.paths: <span class=o>[</span><span class=s2>&#34;/var/log/nginx/access.log*&#34;</span><span class=o>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1>#启用 Logstash 模块</span>
</span></span><span class=line><span class=cl>./filebeat modules <span class=nb>enable</span> logstash
</span></span><span class=line><span class=cl><span class=c1>#在 modules.d/logstash.yml 文件中修改设置</span>
</span></span><span class=line><span class=cl>- module: logstash
</span></span><span class=line><span class=cl>  log:
</span></span><span class=line><span class=cl>    enabled: <span class=nb>true</span>
</span></span><span class=line><span class=cl>    var.paths: <span class=o>[</span><span class=s2>&#34;/home/es/logstash-7.17.3/logs/*.log&#34;</span><span class=o>]</span>
</span></span></code></pre></div><p><strong>4）启动 Filebeat</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-shell data-lang=shell><span class=line><span class=cl><span class=c1># setup命令加载Kibana仪表板。 如果仪表板已经设置，则忽略此命令。 </span>
</span></span><span class=line><span class=cl>./filebeat setup
</span></span><span class=line><span class=cl><span class=c1># 启动Filebeat</span>
</span></span><span class=line><span class=cl>./filebeat -e 
</span></span></code></pre></div><h2 id=elk整合实战><strong>ELK整合实战</strong><a hidden class=anchor aria-hidden=true href=#elk整合实战>#</a></h2><h3 id=案例采集tomcat服务器日志><strong>案例：采集tomcat服务器日志</strong><a hidden class=anchor aria-hidden=true href=#案例采集tomcat服务器日志>#</a></h3><p>Tomcat服务器运行过程中产生很多日志信息，通过Logstash采集并存储日志信息至ElasticSearch中</p><h3 id=使用filebeats将日志发送到logstash><strong>使用FileBeats将日志发送到Logstash</strong><a hidden class=anchor aria-hidden=true href=#使用filebeats将日志发送到logstash>#</a></h3><p>1）创建配置文件filebeat-logstash.yml，配置FileBeats将数据发送到Logstash</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-shell data-lang=shell><span class=line><span class=cl>vim filebeat-logstash.yml
</span></span><span class=line><span class=cl>chmod <span class=m>644</span> filebeat-logstash.yml
</span></span><span class=line><span class=cl><span class=c1>#因为Tomcat的web log日志都是以IP地址开头的，所以我们需要修改下匹配字段。</span>
</span></span><span class=line><span class=cl><span class=c1># 不以ip地址开头的行追加到上一行</span>
</span></span><span class=line><span class=cl>filebeat.inputs:
</span></span><span class=line><span class=cl>- type: log
</span></span><span class=line><span class=cl>  enabled: <span class=nb>true</span>
</span></span><span class=line><span class=cl>  paths:
</span></span><span class=line><span class=cl>    - /home/es/apache-tomcat-8.5.33/logs/*access*.*
</span></span><span class=line><span class=cl>  multiline.pattern: <span class=s1>&#39;^\\d+\\.\\d+\\.\\d+\\.\\d+ &#39;</span>
</span></span><span class=line><span class=cl>  multiline.negate: <span class=nb>true</span>
</span></span><span class=line><span class=cl>  multiline.match: after
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>output.logstash:
</span></span><span class=line><span class=cl>  enabled: <span class=nb>true</span>
</span></span><span class=line><span class=cl>  hosts: <span class=o>[</span><span class=s2>&#34;192.168.65.204:5044&#34;</span><span class=o>]</span>
</span></span></code></pre></div><p>​</p><ul><li>pattern：正则表达式</li><li>negate：true 或 false；默认是false，匹配pattern的行合并到上一行；true，不匹配pattern的行合并到上一行</li><li>match：after 或 before，合并到上一行的末尾或开头</li></ul><p>2）启动FileBeat，并指定使用指定的配置文件</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-shell data-lang=shell><span class=line><span class=cl>./filebeat -e -c filebeat-logstash.yml            
</span></span></code></pre></div><p><strong>可能出现的异常：</strong></p><p>异常1：Exiting: error loading config file: config file (&ldquo;filebeat-logstash.yml&rdquo;) can only be writable by the owner but the permissions are &ldquo;-rw-rw-r&ndash;&rdquo; (to fix the permissions use: &lsquo;chmod go-w /home/es/filebeat-7.17.3-linux-x86_64/filebeat-logstash.yml&rsquo;)</p><p>因为安全原因不要其他用户写的权限，去掉写的权限就可以了</p><p>​ chmod 644 filebeat-logstash.yml</p><p>异常2：Failed to connect to backoff(async(tcp://192.168.65.204:5044)): dial tcp 192.168.65.204:5044: connect: connection refused</p><p>FileBeat将尝试建立与Logstash监听的IP和端口号进行连接。但此时，我们并没有开启并配置Logstash，所以FileBeat是无法连接到Logstash的。</p><h3 id=配置logstash接收filebeat收集的数据并打印><strong>配置Logstash接收FileBeat收集的数据并打印</strong><a hidden class=anchor aria-hidden=true href=#配置logstash接收filebeat收集的数据并打印>#</a></h3><div class=highlight><pre tabindex=0 class=chroma><code class=language-shell data-lang=shell><span class=line><span class=cl>vim config/filebeat-console.conf
</span></span><span class=line><span class=cl><span class=c1># 配置从FileBeat接收数据</span>
</span></span><span class=line><span class=cl>input <span class=o>{</span>
</span></span><span class=line><span class=cl>    beats <span class=o>{</span>
</span></span><span class=line><span class=cl>      <span class=nv>port</span> <span class=o>=</span>&gt; <span class=m>5044</span>
</span></span><span class=line><span class=cl>    <span class=o>}</span>
</span></span><span class=line><span class=cl><span class=o>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>output <span class=o>{</span>
</span></span><span class=line><span class=cl>    stdout <span class=o>{</span>
</span></span><span class=line><span class=cl>      <span class=nv>codec</span> <span class=o>=</span>&gt; rubydebug
</span></span><span class=line><span class=cl>    <span class=o>}</span>
</span></span><span class=line><span class=cl><span class=o>}</span>
</span></span></code></pre></div><p>测试logstash配置是否正确</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-shell data-lang=shell><span class=line><span class=cl>bin/logstash -f config/filebeat-console.conf --config.test_and_exit     
</span></span></code></pre></div><p><strong>启动logstash</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-shell data-lang=shell><span class=line><span class=cl><span class=c1># reload.automatic：修改配置文件时自动重新加载</span>
</span></span><span class=line><span class=cl>bin/logstash -f config/filebeat-console.conf --config.reload.automatic
</span></span></code></pre></div><p>​</p><p>测试访问tomcat，logstash是否接收到了Filebeat传过来的tomcat日志</p><h3 id=logstash输出数据到elasticsearch><strong>Logstash输出数据到Elasticsearch</strong><a hidden class=anchor aria-hidden=true href=#logstash输出数据到elasticsearch>#</a></h3><p>如果我们需要将数据输出值ES而不是控制台的话，我们修改Logstash的output配置。</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-shell data-lang=shell><span class=line><span class=cl>vim config/filebeat-elasticSearch.conf
</span></span><span class=line><span class=cl>input <span class=o>{</span>
</span></span><span class=line><span class=cl>    beats <span class=o>{</span>
</span></span><span class=line><span class=cl>      <span class=nv>port</span> <span class=o>=</span>&gt; <span class=m>5044</span>
</span></span><span class=line><span class=cl>    <span class=o>}</span>
</span></span><span class=line><span class=cl><span class=o>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>output <span class=o>{</span>
</span></span><span class=line><span class=cl>  elasticsearch <span class=o>{</span>
</span></span><span class=line><span class=cl>    <span class=nv>hosts</span> <span class=o>=</span>&gt; <span class=o>[</span><span class=s2>&#34;http://localhost:9200&#34;</span><span class=o>]</span>
</span></span><span class=line><span class=cl>    <span class=nv>user</span> <span class=o>=</span>&gt; <span class=s2>&#34;elastic&#34;</span>
</span></span><span class=line><span class=cl>    <span class=nv>password</span> <span class=o>=</span>&gt; <span class=s2>&#34;123456&#34;</span>
</span></span><span class=line><span class=cl>  <span class=o>}</span>
</span></span><span class=line><span class=cl>  stdout<span class=o>{</span>
</span></span><span class=line><span class=cl>    <span class=nv>codec</span> <span class=o>=</span>&gt; rubydebug
</span></span><span class=line><span class=cl>  <span class=o>}</span>
</span></span><span class=line><span class=cl><span class=o>}</span>
</span></span></code></pre></div><p><strong>启动logstash</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-shell data-lang=shell><span class=line><span class=cl>bin/logstash -f config/filebeat-elasticSearch.conf --config.reload.automatic  
</span></span></code></pre></div><p>​</p><p>ES中会生成一个以logstash开头的索引，测试日志是否保存到了ES。</p><p>思考：日志信息都保证在message字段中，是否可以把日志进行解析一个个的字段？例如：IP字段、时间、请求方式、请求URL、响应结果。</p><h3 id=利用logstash过滤器解析日志><strong>利用Logstash过滤器解析日志</strong><a hidden class=anchor aria-hidden=true href=#利用logstash过滤器解析日志>#</a></h3><p>从日志文件中收集到的数据包含了很多有效信息，比如IP、时间等，在Logstash中可以配置过滤器Filter对采集到的数据进行过滤处理，Logstash中有大量的插件可以供我们使用。</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-shell data-lang=shell><span class=line><span class=cl><span class=c1>#查看Logstash已经安装的插件 </span>
</span></span><span class=line><span class=cl>bin/logstash-plugin list              
</span></span></code></pre></div><p><strong>Grok插件</strong></p><p>Grok是一种将非结构化日志解析为结构化的插件。这个工具非常适合用来解析系统日志、Web服务器日志、MySQL或者是任意其他的日志格式。</p><p><a href=https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-grok.html>https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-grok.html</a></p><p><strong>Grok语法</strong></p><p>Grok是通过模式匹配的方式来识别日志中的数据,可以把Grok插件简单理解为升级版本的正则表达式。它拥有更多的模式，默认Logstash拥有120个模式。如果这些模式不满足我们解析日志的需求，我们可以直接使用正则表达式来进行匹配。</p><p>grok模式的语法是：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-json data-lang=json><span class=line><span class=cl><span class=err>%</span><span class=p>{</span><span class=err>SYNTAX:SEMANTIC</span><span class=p>}</span>  
</span></span></code></pre></div><p>SYNTAX（语法）指的是Grok模式名称，SEMANTIC（语义）是给模式匹配到的文本字段名。例如：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-json data-lang=json><span class=line><span class=cl>  <span class=err>%</span><span class=p>{</span><span class=err>NUMBER:duration</span><span class=p>}</span> <span class=err>%</span><span class=p>{</span><span class=err>IP:client</span><span class=p>}</span> 
</span></span><span class=line><span class=cl>  <span class=err>duration表示：匹配一个数字，client表示匹配一个IP地址。</span> 
</span></span></code></pre></div><p>默认在Grok中，所有匹配到的的数据类型都是字符串，如果要转换成int类型（目前只支持int和float），可以这样：%{NUMBER:duration:int} %{IP:client}</p><p>常用的Grok模式</p><p><a href="https://help.aliyun.com/document_detail/129387.html?scm=20140722.184.2.173">https://help.aliyun.com/document_detail/129387.html?scm=20140722.184.2.173</a></p><p><strong>用法</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-shell data-lang=shell><span class=line><span class=cl>filter <span class=o>{</span>
</span></span><span class=line><span class=cl>  grok <span class=o>{</span>
</span></span><span class=line><span class=cl>    <span class=nv>match</span> <span class=o>=</span>&gt; <span class=o>{</span> <span class=s2>&#34;message&#34;</span> <span class=o>=</span>&gt; <span class=s2>&#34;%{IP:client} %{WORD:method} %{URIPATHPARAM:request} %{NUMBER:bytes} %{NUMBER:duration}&#34;</span> <span class=o>}</span>
</span></span><span class=line><span class=cl>  <span class=o>}</span>
</span></span><span class=line><span class=cl><span class=o>}</span>
</span></span></code></pre></div><p>比如，tomacat日志</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-shell data-lang=shell><span class=line><span class=cl>192.168.65.103 - - <span class=o>[</span>23/Jun/2022:22:37:23 +0800<span class=o>]</span> <span class=s2>&#34;GET /docs/images/docs-stylesheet.css HTTP/1.1&#34;</span> <span class=m>200</span> <span class=m>5780</span>      
</span></span></code></pre></div><p>解析后的字段</p><table><thead><tr><th>字段名</th><th>说明</th></tr></thead><tbody><tr><td>client IP</td><td>浏览器端IP</td></tr><tr><td>timestamp</td><td>请求的时间戳</td></tr><tr><td>method</td><td>请求方式（GET/POST）</td></tr><tr><td>uri</td><td>请求的链接地址</td></tr><tr><td>status</td><td>服务器端响应状态</td></tr><tr><td>length</td><td>响应的数据长度</td></tr></tbody></table><p>grok模式</p><p>​</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-shell data-lang=shell><span class=line><span class=cl>%<span class=o>{</span>IP:ip<span class=o>}</span> - - <span class=se>\[</span>%<span class=o>{</span>HTTPDATE:date<span class=o>}</span><span class=se>\]</span> <span class=se>\&#34;</span>%<span class=o>{</span>WORD:method<span class=o>}</span> %<span class=o>{</span>PATH:uri<span class=o>}</span> %<span class=o>{</span>DATA:protocol<span class=o>}</span><span class=se>\&#34;</span> %<span class=o>{</span>INT:status<span class=o>}</span> %<span class=o>{</span>INT:length<span class=o>}</span>  
</span></span></code></pre></div><p>​</p><p>为了方便测试，我们可以使用Kibana来进行Grok开发：</p><p>​ <img loading=lazy src=https://note.youdao.com/yws/public/resource/cd88d72a1c76d18efcf7fe767e8c2d20/xmlnote/B11C53901C84493D99F3D89FBAC40AFB/52568 alt=0></p><p>修改Logstash配置文件</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-shell data-lang=shell><span class=line><span class=cl>vim config/filebeat-console.conf
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>input <span class=o>{</span>
</span></span><span class=line><span class=cl>    beats <span class=o>{</span>
</span></span><span class=line><span class=cl>      <span class=nv>port</span> <span class=o>=</span>&gt; <span class=m>5044</span>
</span></span><span class=line><span class=cl>    <span class=o>}</span>
</span></span><span class=line><span class=cl><span class=o>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>filter <span class=o>{</span>
</span></span><span class=line><span class=cl>  grok <span class=o>{</span>
</span></span><span class=line><span class=cl>    <span class=nv>match</span> <span class=o>=</span>&gt; <span class=o>{</span> 
</span></span><span class=line><span class=cl>    <span class=s2>&#34;message&#34;</span> <span class=o>=</span>&gt; <span class=s2>&#34;%{IP:ip} - - \[%{HTTPDATE:date}\] \&#34;%{WORD:method} %{PATH:uri} %{DATA:protocol}\&#34; %{INT:status:int} %{INT:length:int}&#34;</span> 
</span></span><span class=line><span class=cl>    <span class=o>}</span>
</span></span><span class=line><span class=cl><span class=o>}</span>
</span></span><span class=line><span class=cl><span class=o>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>output <span class=o>{</span>
</span></span><span class=line><span class=cl>    stdout <span class=o>{</span>
</span></span><span class=line><span class=cl>      <span class=nv>codec</span> <span class=o>=</span>&gt; rubydebug
</span></span><span class=line><span class=cl>    <span class=o>}</span>
</span></span><span class=line><span class=cl><span class=o>}</span>
</span></span></code></pre></div><p>启动logstash测试</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-shell data-lang=shell><span class=line><span class=cl> bin/logstash -f config/filebeat-console.conf --config.reload.automatic
</span></span></code></pre></div><p>使用mutate插件过滤掉不需要的字段</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-shell data-lang=shell><span class=line><span class=cl>mutate <span class=o>{</span>
</span></span><span class=line><span class=cl>    <span class=nv>enable_metric</span> <span class=o>=</span>&gt; <span class=s2>&#34;false&#34;</span>
</span></span><span class=line><span class=cl>    <span class=nv>remove_field</span> <span class=o>=</span>&gt; <span class=o>[</span><span class=s2>&#34;message&#34;</span>, <span class=s2>&#34;log&#34;</span>, <span class=s2>&#34;tags&#34;</span>, <span class=s2>&#34;input&#34;</span>, <span class=s2>&#34;agent&#34;</span>, <span class=s2>&#34;host&#34;</span>, <span class=s2>&#34;ecs&#34;</span>, <span class=s2>&#34;@version&#34;</span><span class=o>]</span>
</span></span><span class=line><span class=cl><span class=o>}</span>
</span></span></code></pre></div><p>要将日期格式进行转换，我们可以使用Date插件来实现。该插件专门用来解析字段中的日期，官方说明文档：https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-date.html</p><p>用法如下：</p><p>​ <img loading=lazy src=https://note.youdao.com/yws/public/resource/cd88d72a1c76d18efcf7fe767e8c2d20/xmlnote/6CD8135DD5F84D0D8AF0C937D385EDE0/52596 alt=0></p><p>将date字段转换为「年月日 时分秒」格式。默认字段经过date插件处理后，会输出到@timestamp字段，所以，我们可以通过修改target属性来重新定义输出字段。</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-shell data-lang=shell><span class=line><span class=cl>date <span class=o>{</span>
</span></span><span class=line><span class=cl>    <span class=nv>match</span> <span class=o>=</span>&gt; <span class=o>[</span><span class=s2>&#34;date&#34;</span>,<span class=s2>&#34;dd/MMM/yyyy:HH:mm:ss Z&#34;</span>,<span class=s2>&#34;yyyy-MM-dd HH:mm:ss&#34;</span><span class=o>]</span>
</span></span><span class=line><span class=cl>    <span class=nv>target</span> <span class=o>=</span>&gt; <span class=s2>&#34;date&#34;</span>
</span></span><span class=line><span class=cl><span class=o>}</span>
</span></span></code></pre></div><p>​</p><h3 id=输出到elasticsearch指定索引><strong>输出到Elasticsearch指定索引</strong><a hidden class=anchor aria-hidden=true href=#输出到elasticsearch指定索引>#</a></h3><p>index来指定索引名称，默认输出的index名称为：logstash-%{+yyyy.MM.dd}。但注意，要在index中使用时间格式化，filter的输出必须包含 @timestamp字段，否则将无法解析日期。</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-shell data-lang=shell><span class=line><span class=cl>output <span class=o>{</span>
</span></span><span class=line><span class=cl>  elasticsearch <span class=o>{</span>
</span></span><span class=line><span class=cl>    <span class=nv>index</span> <span class=o>=</span>&gt; <span class=s2>&#34;tomcat_web_log_%{+YYYY-MM}&#34;</span>
</span></span><span class=line><span class=cl>    <span class=nv>hosts</span> <span class=o>=</span>&gt; <span class=o>[</span><span class=s2>&#34;http://localhost:9200&#34;</span><span class=o>]</span>
</span></span><span class=line><span class=cl>    <span class=nv>user</span> <span class=o>=</span>&gt; <span class=s2>&#34;elastic&#34;</span>
</span></span><span class=line><span class=cl>    <span class=nv>password</span> <span class=o>=</span>&gt; <span class=s2>&#34;123456&#34;</span>
</span></span><span class=line><span class=cl>  <span class=o>}</span>
</span></span><span class=line><span class=cl>  stdout<span class=o>{</span>
</span></span><span class=line><span class=cl>    <span class=nv>codec</span> <span class=o>=</span>&gt; rubydebug
</span></span><span class=line><span class=cl>  <span class=o>}</span>
</span></span><span class=line><span class=cl><span class=o>}</span>
</span></span></code></pre></div><p>注意：index名称中，不能出现大写字符</p><p>完整的Logstash配置文件</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-shell data-lang=shell><span class=line><span class=cl>vim config/filebeat-filter-es.conf
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>input <span class=o>{</span>
</span></span><span class=line><span class=cl>    beats <span class=o>{</span>
</span></span><span class=line><span class=cl>    <span class=nv>port</span> <span class=o>=</span>&gt; <span class=m>5044</span>
</span></span><span class=line><span class=cl>    <span class=o>}</span>
</span></span><span class=line><span class=cl><span class=o>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>filter <span class=o>{</span>
</span></span><span class=line><span class=cl>    grok <span class=o>{</span>
</span></span><span class=line><span class=cl>    <span class=nv>match</span> <span class=o>=</span>&gt; <span class=o>{</span> 
</span></span><span class=line><span class=cl>    <span class=s2>&#34;message&#34;</span> <span class=o>=</span>&gt; <span class=s2>&#34;%{IP:ip} - - \[%{HTTPDATE:date}\] \&#34;%{WORD:method} %{PATH:uri} %{DATA:protocol}\&#34; %{INT:status:int} %{INT:length:int}&#34;</span> 
</span></span><span class=line><span class=cl>    <span class=o>}</span>
</span></span><span class=line><span class=cl><span class=o>}</span>
</span></span><span class=line><span class=cl>mutate <span class=o>{</span>
</span></span><span class=line><span class=cl>    <span class=nv>enable_metric</span> <span class=o>=</span>&gt; <span class=s2>&#34;false&#34;</span>
</span></span><span class=line><span class=cl>    <span class=nv>remove_field</span> <span class=o>=</span>&gt; <span class=o>[</span><span class=s2>&#34;message&#34;</span>, <span class=s2>&#34;log&#34;</span>, <span class=s2>&#34;tags&#34;</span>, <span class=s2>&#34;input&#34;</span>, <span class=s2>&#34;agent&#34;</span>, <span class=s2>&#34;host&#34;</span>, <span class=s2>&#34;ecs&#34;</span>, <span class=s2>&#34;@version&#34;</span><span class=o>]</span>
</span></span><span class=line><span class=cl><span class=o>}</span>
</span></span><span class=line><span class=cl>date <span class=o>{</span>
</span></span><span class=line><span class=cl>    <span class=nv>match</span> <span class=o>=</span>&gt; <span class=o>[</span><span class=s2>&#34;date&#34;</span>,<span class=s2>&#34;dd/MMM/yyyy:HH:mm:ss Z&#34;</span>,<span class=s2>&#34;yyyy-MM-dd HH:mm:ss&#34;</span><span class=o>]</span>
</span></span><span class=line><span class=cl>    <span class=nv>target</span> <span class=o>=</span>&gt; <span class=s2>&#34;date&#34;</span>
</span></span><span class=line><span class=cl>    <span class=o>}</span>
</span></span><span class=line><span class=cl><span class=o>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>output <span class=o>{</span>
</span></span><span class=line><span class=cl>    stdout <span class=o>{</span>
</span></span><span class=line><span class=cl>    <span class=nv>codec</span> <span class=o>=</span>&gt; rubydebug
</span></span><span class=line><span class=cl><span class=o>}</span>
</span></span><span class=line><span class=cl>elasticsearch <span class=o>{</span>
</span></span><span class=line><span class=cl>    <span class=nv>index</span> <span class=o>=</span>&gt; <span class=s2>&#34;tomcat_web_log_%{+YYYY-MM}&#34;</span>
</span></span><span class=line><span class=cl>    <span class=nv>hosts</span> <span class=o>=</span>&gt; <span class=o>[</span><span class=s2>&#34;http://localhost:9200&#34;</span><span class=o>]</span>
</span></span><span class=line><span class=cl>    <span class=nv>user</span> <span class=o>=</span>&gt; <span class=s2>&#34;elastic&#34;</span>
</span></span><span class=line><span class=cl>    <span class=nv>password</span> <span class=o>=</span>&gt; <span class=s2>&#34;123456&#34;</span>
</span></span><span class=line><span class=cl>  <span class=o>}</span>
</span></span><span class=line><span class=cl><span class=o>}</span>
</span></span></code></pre></div><p><strong>启动logstash</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-shell data-lang=shell><span class=line><span class=cl>bin/logstash -f config/filebeat-filter-es.conf --config.reload.automatic
</span></span></code></pre></div><div class=highlight><pre tabindex=0 class=chroma><code class=language-shell data-lang=shell><span class=line><span class=cl>input <span class=o>{</span>
</span></span><span class=line><span class=cl>  redis <span class=o>{</span>
</span></span><span class=line><span class=cl>  <span class=nv>host</span><span class=o>=</span>&gt; <span class=s2>&#34;localhost&#34;</span>
</span></span><span class=line><span class=cl>  <span class=nv>port</span> <span class=o>=</span>&gt; <span class=s2>&#34;6379&#34;</span>
</span></span><span class=line><span class=cl>  <span class=nv>password</span> <span class=o>=</span>&gt; <span class=s2>&#34;9ed99d6b&#34;</span>
</span></span><span class=line><span class=cl>  <span class=nv>key</span> <span class=o>=</span>&gt; <span class=s2>&#34;filebeat&#34;</span>
</span></span><span class=line><span class=cl>  <span class=nb>type</span> <span class=o>=</span>&gt; <span class=s2>&#34;redis-input&#34;</span>
</span></span><span class=line><span class=cl>  <span class=nv>data_type</span> <span class=o>=</span>&gt; <span class=s2>&#34;list&#34;</span>
</span></span><span class=line><span class=cl>  <span class=nv>threads</span> <span class=o>=</span>&gt;4 
</span></span><span class=line><span class=cl>  <span class=nv>batch_count</span> <span class=o>=</span>&gt; <span class=m>10</span> 
</span></span><span class=line><span class=cl>  <span class=nv>db</span> <span class=o>=</span>&gt; <span class=m>0</span>
</span></span><span class=line><span class=cl>  <span class=o>}</span>
</span></span><span class=line><span class=cl><span class=o>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>filter <span class=o>{</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=o>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>output <span class=o>{</span>   
</span></span><span class=line><span class=cl>elasticsearch 
</span></span><span class=line><span class=cl><span class=o>{</span>    
</span></span><span class=line><span class=cl> <span class=nv>hosts</span> <span class=o>=</span>&gt; <span class=s2>&#34;http://cqzwy-mgmt-log-platform-grc055ce-0.cqzwy-mgmt-log-platform-grc055ce.013497775a1b4580924a00009a20c887.svc.cluster.local:9200&#34;</span>     
</span></span><span class=line><span class=cl> <span class=nv>index</span> <span class=o>=</span>&gt; <span class=s2>&#34;netlog&#34;</span>     
</span></span><span class=line><span class=cl> <span class=nv>user</span> <span class=o>=</span>&gt; <span class=s2>&#34;elastic&#34;</span>     
</span></span><span class=line><span class=cl> <span class=nv>password</span> <span class=o>=</span>&gt; <span class=s2>&#34;kuGmFNENeZyYuGkYZ4BU&#34;</span>   
</span></span><span class=line><span class=cl> <span class=o>}</span>  
</span></span><span class=line><span class=cl><span class=o>}</span>             
</span></span></code></pre></div><p>logstash 问题处理</p><p><a href=https://blog.csdn.net/King_weng/article/details/106506996>https://blog.csdn.net/King_weng/article/details/106506996</a></p><h2 id=elfk整合实战2>ELFK整合实战2<a hidden class=anchor aria-hidden=true href=#elfk整合实战2>#</a></h2><p>filebeat => redis => logstash => elasticsearch => kinbana</p><h3 id=filebeat的配置>filebeat的配置<a hidden class=anchor aria-hidden=true href=#filebeat的配置>#</a></h3><p>filebeat.yml</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-yaml data-lang=yaml><span class=line><span class=cl><span class=nt>filebeat.inputs</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span>- <span class=nt>type</span><span class=p>:</span><span class=w> </span><span class=l>filestream</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>paths</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span>- <span class=l>/var/log/data/10.42.76.202/*.log</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span>- <span class=l>/var/log/data/10.42.76.201/*.log</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span>- <span class=l>/var/log/data/10.42.76.204/*.log</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>encoding</span><span class=p>:</span><span class=w> </span><span class=l>gbk </span><span class=w> </span><span class=c># 对非utf-8的数据进行转码</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>ignore_older</span><span class=p>:</span><span class=w> </span><span class=l>5m </span><span class=w> </span><span class=c>#只采集5分钟内更新的文件</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span>- <span class=nt>type</span><span class=p>:</span><span class=w> </span><span class=l>filestream</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>paths</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span>- <span class=l>/var/log/data/10.42.76.206/*.log</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span>- <span class=l>/var/log/data/10.42.76.207/*.log</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>ignore_older</span><span class=p>:</span><span class=w> </span><span class=l>5m</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nt>output.redis</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>hosts</span><span class=p>:</span><span class=w> </span><span class=p>[</span><span class=s2>&#34;10.43.152.65:6379&#34;</span><span class=p>]</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>password</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;9ed99d6b&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>key</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;filebeat&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>db</span><span class=p>:</span><span class=w> </span><span class=m>0</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>timeout</span><span class=p>:</span><span class=w> </span><span class=m>5</span><span class=w>
</span></span></span></code></pre></div><p>filebeat 启动命令</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-shell data-lang=shell><span class=line><span class=cl>nohup ./filebeat -e -c filebeat.yml &gt;/dev/null <span class=p>&amp;</span>
</span></span></code></pre></div><h3 id=logstash的配置>logstash的配置<a hidden class=anchor aria-hidden=true href=#logstash的配置>#</a></h3><p>logstash_run.yml</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-yaml data-lang=yaml><span class=line><span class=cl><span class=l>input {</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=l>redis {</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=l>host=&gt; &#34;localhost&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=l>port =&gt; &#34;6379&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=l>password =&gt; &#34;9ed99d6b&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=l>key =&gt; &#34;filebeat&#34; </span><span class=w> </span><span class=c># 对应redis中的key名称</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=l>type =&gt; &#34;redis-input&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=l>data_type =&gt; &#34;list&#34;</span><span class=w> </span><span class=c># key的类型</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=l>threads =&gt;4 </span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=l>batch_count =&gt; 10 </span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=l>db =&gt; 0</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span>}<span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span>}<span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=l>filter {</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span>}<span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=l>output {   </span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=l>elasticsearch </span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span>{<span class=w>    
</span></span></span><span class=line><span class=cl><span class=w> </span><span class=l>hosts =&gt; &#34;http://cqzwy-mgmt-log-platform-grc055ce-0.cqzwy-mgmt-log-platform-grc055ce.013497775a1b4580924a00009a20c887.svc.cluster.local:9200&#34;     </span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w> </span><span class=l>index =&gt; &#34;netlog&#34; </span><span class=w> </span><span class=c># 在es中的索引名称</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w> </span><span class=l>user =&gt; &#34;elastic&#34;     </span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w> </span><span class=l>password =&gt; &#34;kuGmFNENeZyYuGkYZ4BU&#34;   </span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w> </span>}<span class=w>  
</span></span></span><span class=line><span class=cl><span class=w></span>}<span class=w>             
</span></span></span></code></pre></div><p>通过jvm.options文件修改jvm参数</p><h4 id=制作logstash镜像可选>制作logstash镜像(可选)<a hidden class=anchor aria-hidden=true href=#制作logstash镜像可选>#</a></h4><p>start.sh启动脚本</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-shell data-lang=shell><span class=line><span class=cl><span class=cp>#!/bin/bash
</span></span></span><span class=line><span class=cl><span class=cp></span><span class=c1># -f 后指定的配置文件需是新的文件</span>
</span></span><span class=line><span class=cl>bin/logstash -f config/logstash_run.yml --config.reload.automatic
</span></span></code></pre></div><p>Dockerfile文件</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-dockerfile data-lang=dockerfile><span class=line><span class=cl><span class=k>FROM</span><span class=s> centos:7</span><span class=err>
</span></span></span><span class=line><span class=cl><span class=err></span><span class=k>MAINTAINER</span><span class=s> wandong</span><span class=err>
</span></span></span><span class=line><span class=cl><span class=err>
</span></span></span><span class=line><span class=cl><span class=err></span><span class=k>RUN</span> yum install -y wget java-1.8.0-openjdk curl unzip iproute net-tools <span class=o>&amp;&amp;</span> <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>    yum clean all <span class=o>&amp;&amp;</span> <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>    rm -rf /var/cache/yum/*<span class=err>
</span></span></span><span class=line><span class=cl><span class=err>
</span></span></span><span class=line><span class=cl><span class=err></span><span class=k>ADD</span> logstash-7.15.2-linux-x86_64.tar.gz /opt/<span class=err>
</span></span></span><span class=line><span class=cl><span class=err></span><span class=k>WORKDIR</span><span class=s> /opt/logstash-7.15.2</span><span class=err>
</span></span></span><span class=line><span class=cl><span class=err></span><span class=k>COPY</span> start.sh /opt/logstash-7.15.2<span class=err>
</span></span></span><span class=line><span class=cl><span class=err></span><span class=k>EXPOSE</span><span class=s> 5044 9600</span><span class=err>
</span></span></span><span class=line><span class=cl><span class=err>
</span></span></span><span class=line><span class=cl><span class=err></span><span class=k>CMD</span> <span class=p>[</span><span class=s2>&#34;sh&#34;</span><span class=p>,</span><span class=s2>&#34;start.sh&#34;</span><span class=p>]</span><span class=err>
</span></span></span></code></pre></div><p>log.file.path : 10.42.76.201 and message : 39.144.219.132</p></div><footer class=post-footer><ul class=post-tags><li><a href=https://www.sulvblog.cn/tags/es/>ES</a></li></ul><nav class=paginav><a class=prev href=https://www.sulvblog.cn/post/elasticsearch/><span class=title>« Prev Page</span><br><span>ElasticSearch快速入门实战</span></a>
<a class=next href=https://www.sulvblog.cn/post/%E7%A6%BB%E7%BA%BF%E5%AE%89%E8%A3%85docker/><span class=title>Next Page »</span><br><span>离线安装docker</span></a></nav><div class=share-buttons><a target=_blank rel="noopener noreferrer" aria-label="share 离线安装docker on twitter" href="https://twitter.com/intent/tweet/?text=%e7%a6%bb%e7%ba%bf%e5%ae%89%e8%a3%85docker&url=https%3a%2f%2fwww.sulvblog.cn%2fpost%2felasticsearch%25E5%2585%25A5%25E9%2597%25A8%2f&hashtags=ES"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM195.519 424.544c135.939.0 210.268-112.643 210.268-210.268.0-3.218.0-6.437-.153-9.502 14.406-10.421 26.973-23.448 36.935-38.314-13.18 5.824-27.433 9.809-42.452 11.648 15.326-9.196 26.973-23.602 32.49-40.92-14.252 8.429-30.038 14.56-46.896 17.931-13.487-14.406-32.644-23.295-53.946-23.295-40.767.0-73.87 33.104-73.87 73.87.0 5.824.613 11.494 1.992 16.858-61.456-3.065-115.862-32.49-152.337-77.241-6.284 10.881-9.962 23.601-9.962 37.088.0 25.594 13.027 48.276 32.95 61.456-12.107-.307-23.448-3.678-33.41-9.196v.92c0 35.862 25.441 65.594 59.311 72.49-6.13 1.686-12.72 2.606-19.464 2.606-4.751.0-9.348-.46-13.946-1.38 9.349 29.426 36.628 50.728 68.965 51.341-25.287 19.771-57.164 31.571-91.8 31.571-5.977.0-11.801-.306-17.625-1.073 32.337 21.15 71.264 33.41 112.95 33.41z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share 离线安装docker on linkedin" href="https://www.linkedin.com/shareArticle?mini=true&url=https%3a%2f%2fwww.sulvblog.cn%2fpost%2felasticsearch%25E5%2585%25A5%25E9%2597%25A8%2f&title=%e7%a6%bb%e7%ba%bf%e5%ae%89%e8%a3%85docker&summary=%e7%a6%bb%e7%ba%bf%e5%ae%89%e8%a3%85docker&source=https%3a%2f%2fwww.sulvblog.cn%2fpost%2felasticsearch%25E5%2585%25A5%25E9%2597%25A8%2f"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM160.461 423.278V197.561h-75.04v225.717h75.04zm270.539.0V293.839c0-69.333-37.018-101.586-86.381-101.586-39.804.0-57.634 21.891-67.617 37.266v-31.958h-75.021c.995 21.181.0 225.717.0 225.717h75.02V297.222c0-6.748.486-13.492 2.474-18.315 5.414-13.475 17.767-27.434 38.494-27.434 27.135.0 38.007 20.707 38.007 51.037v120.768H431zM123.448 88.722C97.774 88.722 81 105.601 81 127.724c0 21.658 16.264 39.002 41.455 39.002h.484c26.165.0 42.452-17.344 42.452-39.002-.485-22.092-16.241-38.954-41.943-39.002z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share 离线安装docker on reddit" href="https://reddit.com/submit?url=https%3a%2f%2fwww.sulvblog.cn%2fpost%2felasticsearch%25E5%2585%25A5%25E9%2597%25A8%2f&title=%e7%a6%bb%e7%ba%bf%e5%ae%89%e8%a3%85docker"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM446 265.638c0-22.964-18.616-41.58-41.58-41.58-11.211.0-21.361 4.457-28.841 11.666-28.424-20.508-67.586-33.757-111.204-35.278l18.941-89.121 61.884 13.157c.756 15.734 13.642 28.29 29.56 28.29 16.407.0 29.706-13.299 29.706-29.701.0-16.403-13.299-29.702-29.706-29.702-11.666.0-21.657 6.792-26.515 16.578l-69.105-14.69c-1.922-.418-3.939-.042-5.585 1.036-1.658 1.073-2.811 2.761-3.224 4.686l-21.152 99.438c-44.258 1.228-84.046 14.494-112.837 35.232-7.468-7.164-17.589-11.591-28.757-11.591-22.965.0-41.585 18.616-41.585 41.58.0 16.896 10.095 31.41 24.568 37.918-.639 4.135-.99 8.328-.99 12.576.0 63.977 74.469 115.836 166.33 115.836s166.334-51.859 166.334-115.836c0-4.218-.347-8.387-.977-12.493 14.564-6.47 24.735-21.034 24.735-38.001zM326.526 373.831c-20.27 20.241-59.115 21.816-70.534 21.816-11.428.0-50.277-1.575-70.522-21.82-3.007-3.008-3.007-7.882.0-10.889 3.003-2.999 7.882-3.003 10.885.0 12.777 12.781 40.11 17.317 59.637 17.317 19.522.0 46.86-4.536 59.657-17.321 3.016-2.999 7.886-2.995 10.885.008 3.008 3.011 3.003 7.882-.008 10.889zm-5.23-48.781c-16.373.0-29.701-13.324-29.701-29.698.0-16.381 13.328-29.714 29.701-29.714 16.378.0 29.706 13.333 29.706 29.714.0 16.374-13.328 29.698-29.706 29.698zM160.91 295.348c0-16.381 13.328-29.71 29.714-29.71 16.369.0 29.689 13.329 29.689 29.71.0 16.373-13.32 29.693-29.689 29.693-16.386.0-29.714-13.32-29.714-29.693z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share 离线安装docker on facebook" href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2fwww.sulvblog.cn%2fpost%2felasticsearch%25E5%2585%25A5%25E9%2597%25A8%2f"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H342.978V319.085h66.6l12.672-82.621h-79.272v-53.617c0-22.603 11.073-44.636 46.58-44.636H425.6v-70.34s-32.71-5.582-63.982-5.582c-65.288.0-107.96 39.569-107.96 111.204v62.971h-72.573v82.621h72.573V512h-191.104c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share 离线安装docker on whatsapp" href="https://api.whatsapp.com/send?text=%e7%a6%bb%e7%ba%bf%e5%ae%89%e8%a3%85docker%20-%20https%3a%2f%2fwww.sulvblog.cn%2fpost%2felasticsearch%25E5%2585%25A5%25E9%2597%25A8%2f"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zm-58.673 127.703c-33.842-33.881-78.847-52.548-126.798-52.568-98.799.0-179.21 80.405-179.249 179.234-.013 31.593 8.241 62.428 23.927 89.612l-25.429 92.884 95.021-24.925c26.181 14.28 55.659 21.807 85.658 21.816h.074c98.789.0 179.206-80.413 179.247-179.243.018-47.895-18.61-92.93-52.451-126.81zM263.976 403.485h-.06c-26.734-.01-52.954-7.193-75.828-20.767l-5.441-3.229-56.386 14.792 15.05-54.977-3.542-5.637c-14.913-23.72-22.791-51.136-22.779-79.287.033-82.142 66.867-148.971 149.046-148.971 39.793.014 77.199 15.531 105.329 43.692 28.128 28.16 43.609 65.592 43.594 105.4-.034 82.149-66.866 148.983-148.983 148.984zm81.721-111.581c-4.479-2.242-26.499-13.075-30.604-14.571-4.105-1.495-7.091-2.241-10.077 2.241-2.986 4.483-11.569 14.572-14.182 17.562-2.612 2.988-5.225 3.364-9.703 1.12-4.479-2.241-18.91-6.97-36.017-22.23C231.8 264.15 222.81 249.484 220.198 245s-.279-6.908 1.963-9.14c2.016-2.007 4.48-5.232 6.719-7.847 2.24-2.615 2.986-4.484 4.479-7.472 1.493-2.99.747-5.604-.374-7.846-1.119-2.241-10.077-24.288-13.809-33.256-3.635-8.733-7.327-7.55-10.077-7.688-2.609-.13-5.598-.158-8.583-.158-2.986.0-7.839 1.121-11.944 5.604-4.105 4.484-15.675 15.32-15.675 37.364.0 22.046 16.048 43.342 18.287 46.332 2.24 2.99 31.582 48.227 76.511 67.627 10.685 4.615 19.028 7.371 25.533 9.434 10.728 3.41 20.492 2.929 28.209 1.775 8.605-1.285 26.499-10.833 30.231-21.295 3.732-10.464 3.732-19.431 2.612-21.298-1.119-1.869-4.105-2.99-8.583-5.232z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share 离线安装docker on telegram" href="https://telegram.me/share/url?text=%e7%a6%bb%e7%ba%bf%e5%ae%89%e8%a3%85docker&url=https%3a%2f%2fwww.sulvblog.cn%2fpost%2felasticsearch%25E5%2585%25A5%25E9%2597%25A8%2f"><svg viewBox="2 2 28 28"><path d="M26.49 29.86H5.5a3.37 3.37.0 01-2.47-1 3.35 3.35.0 01-1-2.47V5.48A3.36 3.36.0 013 3 3.37 3.37.0 015.5 2h21A3.38 3.38.0 0129 3a3.36 3.36.0 011 2.46V26.37a3.35 3.35.0 01-1 2.47 3.38 3.38.0 01-2.51 1.02zm-5.38-6.71a.79.79.0 00.85-.66L24.73 9.24a.55.55.0 00-.18-.46.62.62.0 00-.41-.17q-.08.0-16.53 6.11a.59.59.0 00-.41.59.57.57.0 00.43.52l4 1.24 1.61 4.83a.62.62.0 00.63.43.56.56.0 00.4-.17L16.54 20l4.09 3A.9.9.0 0021.11 23.15zM13.8 20.71l-1.21-4q8.72-5.55 8.78-5.55c.15.0.23.0.23.16a.18.18.0 010 .06s-2.51 2.3-7.52 6.8z"/></svg></a></div></footer></article></main><footer class=footer><span>&copy; 2022 <a href=https://www.sulvblog.cn>万东的云计算运维博客</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://git.io/hugopapermod rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerText="copy";function s(){t.innerText="copied!",setTimeout(()=>{t.innerText="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>