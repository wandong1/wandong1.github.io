[{"content":"Helm Helm是一个Kubernetes的包管理工具，就像Linux下的包管理器，如yum/apt等，可以很方便的将之前\n打包好的yaml文件部署到kubernetes上。\nHelm有3个重要概念：\n• **helm：**一个命令行客户端工具，主要用于Kubernetes应用chart的创建、打包、发布和管理。\n• **Chart：**应用描述，一系列用于描述 k8s 资源相关文件的集合。\n• **Release：**基于Chart的部署实体，一个 chart 被 Helm 运行后将会生成对应的一个 release；将在\nk8s中创建出真实运行的资源对象。\nHelm客户端 使用helm很简单，你只需要下载一个二进制客户端包即可，会通过kubeconfig配置（通常$HOME/.kube/config）来连接Kubernetes。\n项目地址：https://github.com/helm/helm\n下载Helm客户端：\nwget https://get.helm.sh/helm-v3.4.2-linux-amd64.tar.gz tar zxvf helm-v3.4.2-linux-amd64.tar.gz mv linux-amd64/helm /usr/bin/ Helm常用命令 Helm管理应用生命周期： • helm create 创建Chart示例\n• helm install 部署\n• helm upgrade 更新\n• helm rollback 回滚\n• helm uninstall 卸载\nHelm基本使用：创建Chart示例 创建chart：\n# 默认示例中部署的是一个nginx服务 helm create mychart 打包chart：\nhelm package mychart • charts：目录里存放这个chart依赖的所有子chart。\n• Chart.yaml：用于描述这个 Chart的基本信息，包括名字、描述信息以及版本等。\n• values.yaml ：用于存储 templates 目录中模板文件中用到变量的值。\n• Templates： 目录里面存放所有yaml模板文件。\n• NOTES.txt ：用于介绍Chart帮助信息， helm install 部署后展示给用户。例如：\n如何使用这个 Chart、列出缺省的设置等。\n• _helpers.tpl：放置模板的地方，可以在整个 chart 中重复使用。\nHelm基本使用：部署 部署Chart：\nhelm install web mychart 查看Release：\nhelm list -n default 查看部署的Pod：\nkubectl get pods,svc Helm基本使用：升级 使用Chart升级应用有两种方法：\n• \u0026ndash;values，-f：指定YAML文件覆盖值\n• \u0026ndash;set：在命令行上指定覆盖值\n注：如果一起使用，\u0026ndash;set优先级高\n例如将nginx服务升级到1.17版本：\n第一种方式： # vi values.yaml #任意路径 image: tag: \u0026#34;1.17“ helm upgrade -f values.yaml web mychart 第二种方式： helm upgrade --set image.tag=1.17 web mychart Helm基本使用：回滚、卸载 回滚到上一个版本：\nhelm rollback web 查看历史版本：\nhelm history web 回滚到指定版本：\nhelm rollback web 2 卸载应用：\nhelm uninstall web Helm工作流程 Helm模板 Helm核心是模板，即模板化K8s YAML文件。\n通过模板实现Chart高效复用，当部署多个应用时，可以将差异化的字段进行模板化，在部署时使用-f或\n者\u0026ndash;set动态覆盖默认值，从而适配多个应用。\nHelm模板由Go Template编写，指令由{{ }}包裹。\n# values.yaml\nreplicaCount: 1 image: repository: nginx tag: \u0026#34;latest\u0026#34; selectorLabels: \u0026#34;nginx\u0026#34; # templates/deployment.yaml\napiVersion: apps/v1 kind: Deployment metadata: labels: app: nginx name: {{ .Release.Name }} spec: replicas: {{ .Values.replicaCount }} selector: matchLabels: app: {{ .Values.selectorLabels }} template: metadata: labels: app: {{ .Values.selectorLabels }} spec: containers: - image: {{ .Values.image.repository }}:{{ .Values.image.tag }} name: web Chart模板：内置对象 在上面示例中，模板文件中.Release、.Values是Helm内置对象，顶级开头写。\n**Release对象：**获取发布记录信息\n**Values对象：**为Chart模板提供值，这个对象的值有4个来源：\n• chart包中的values.yaml文件\n• helm install或者helm upgrade的-f或者\u0026ndash;values参数传入的自定义yaml文件\n• \u0026ndash;set参数传入值\n**Chart对象：**可以通过Chart对象访问Chart.yaml文件的内容，例如：{{ .Chart.AppVersion }}\nChart模板：调试 使用helm install提供了\u0026ndash;dry-run和\u0026ndash;debug调试参数，帮助你验证模板正确性，并把渲染后的模板打印出来，而\n不会真正的去部署。\n# helm install \u0026ndash;dry-run web mychart\n","permalink":"https://www.sulvblog.cn/post/helm%E7%9A%84%E4%BD%BF%E7%94%A8%E6%96%B9%E6%B3%95/","summary":"Helm Helm是一个Kubernetes的包管理工具，就像Linux下的包管理器，如yum/apt等，可以很方便的将之前\n打包好的yaml文件部署到kubernetes上。\nHelm有3个重要概念：\n• **helm：**一个命令行客户端工具，主要用于Kubernetes应用chart的创建、打包、发布和管理。\n• **Chart：**应用描述，一系列用于描述 k8s 资源相关文件的集合。\n• **Release：**基于Chart的部署实体，一个 chart 被 Helm 运行后将会生成对应的一个 release；将在\nk8s中创建出真实运行的资源对象。\nHelm客户端 使用helm很简单，你只需要下载一个二进制客户端包即可，会通过kubeconfig配置（通常$HOME/.kube/config）来连接Kubernetes。\n项目地址：https://github.com/helm/helm\n下载Helm客户端：\nwget https://get.helm.sh/helm-v3.4.2-linux-amd64.tar.gz tar zxvf helm-v3.4.2-linux-amd64.tar.gz mv linux-amd64/helm /usr/bin/ Helm常用命令 Helm管理应用生命周期： • helm create 创建Chart示例\n• helm install 部署\n• helm upgrade 更新\n• helm rollback 回滚\n• helm uninstall 卸载\nHelm基本使用：创建Chart示例 创建chart：\n# 默认示例中部署的是一个nginx服务 helm create mychart 打包chart：\nhelm package mychart • charts：目录里存放这个chart依赖的所有子chart。\n• Chart.yaml：用于描述这个 Chart的基本信息，包括名字、描述信息以及版本等。\n• values.yaml ：用于存储 templates 目录中模板文件中用到变量的值。","title":"helm的使用方法介绍"},{"content":"推荐博客 https://www.liwenzhou.com/posts/Go/golang-menu/\nLinux 安装go语言环境 # 下载地址 https://golang.google.cn/dl/ tar -xvzf go1.17.11.linux-386.tar.gz -C /usr/local yum install glibc.i686 -y mkdir -p /root/workspace cat \u0026lt;\u0026lt;EOF \u0026gt;\u0026gt; /etc/profile export PATH=$PATH:/usr/local/go/bin export GOPATH=\u0026#34;$HOME/workspace\u0026#34; EOF source /etc/profile #设置国内代理 go env -w GOPROXY=https://goproxy.cn,direct #查看go env go env Linux下创建一个go项目 #查看GOPATH go env | grep -i gopath #GOPATH=\u0026#34;/root/workspace\u0026#34; cd /root/workspace;mkdir {src,bin,pkg} #进入src目录创建项目 cd src \u0026amp;\u0026amp; mkdir GoRedis #随后编写main.go文件 构建多平台运行代码 go env -w GOOS=linux go env -w GOARCH=amd64 go build go env -w GOOS=windwos go env -w GOARCH=amd64 go build main.go文件内容 package main import ( \u0026#34;context\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;github.com/go-redis/redis/v8\u0026#34; ) var ctx = context.Background() func main() { rdb := redis.NewClient(\u0026amp;redis.Options{ Addr: \u0026#34;10.43.152.50:10001\u0026#34;, Password: \u0026#34;f1543f7c\u0026#34;, // 密码 DB: 1, // 数据库 PoolSize: 20, // 连接池大小 }) pong, err := rdb.Ping(ctx).Result() fmt.Println(pong, err) } # 执行命令初始化mod go mod init GoRedis # 安装三方依赖包 go get github.com/go-redis/redis/v8 # 整个目录编译，编译后会生成对应系统的执行文件 go build # 运行文件 ./GoRedis Golang指针 任何程序数据载入内存后，在内存都有他们的地址，这就是指针。而为了保存一个数据在内存中的地址，我们就需要指针变量。\n比如，“永远不要高估自己”这句话是我的座右铭，我想把它写入程序中，程序一启动这句话是要加载到内存（假设内存地址0x123456），我在程序中把这段话赋值给变量A，把内存地址赋值给变量B。这时候变量B就是一个指针变量。通过变量A和变量B都能找到我的座右铭。\nGo语言中的指针不能进行偏移和运算，因此Go语言中的指针操作非常简单，我们只需要记住两个符号：\u0026amp;（取地址）和*（根据地址取值）。\nx := 1 p := \u0026amp;x fmt.Println(p) // 变量的内存地址 指针 fmt.Println(*p) //输出 1 *p = 2 // 相当于 x = 2 fmt.Println(x) // 输出2 var x,y int fmt.Println(\u0026amp;x == \u0026amp;x,\u0026amp;x == \u0026amp;y, \u0026amp;x == nil) // 输出 true false false 总结： 取地址操作符\u0026amp;和取值操作符*是一对互补操作符，\u0026amp;取出地址，*根据地址取出地址指向的值。\n变量、指针地址、指针变量、取地址、取值的相互关系和特性如下：\n对变量进行取地址（\u0026amp;）操作，可以获得这个变量的指针变量。 指针变量的值是指针地址。 对指针变量进行取值（*）操作，可以获得指针变量指向的原变量的值。 Golang并发编程 多线程介绍 A. 线程是由操作系统进行管理，也就是处于内核态。\nB. 线程之间进行切换，需要发生用户态到内核态的切换。\nC. 当系统中运行大量线程，系统会变的非常慢。\nD. 用户态的线程，支持大量线程创建。也叫协程或goroutine。\n1、串行、并发与并行 串行：我们都是先读小学，小学毕业后再读初中，读完初中再读高中。\n并发：同一时间段内执行多个任务（你在用微信和两个女朋友聊天）。\n并行：同一时刻执行多个任务（你和你朋友都在用微信和女朋友聊天）。\n2、进程、线程和协程 进程（process）：程序在操作系统中的一次执行过程，系统进行资源分配和调度的一个独立单位。\n线程（thread）：操作系统基于进程开启的轻量级进程，是操作系统调度执行的最小单位。\n协程（coroutine）：非操作系统提供而是由用户自行创建和控制的用户态‘线程’，比线程更轻量级。\n3、并发模型 业界将如何实现并发编程总结归纳为各式各样的并发模型，常见的并发模型有以下几种：\n线程\u0026amp;锁模型\nActor模型\nCSP模型\nFork\u0026amp;Join模型\nGo语言中的并发程序主要是通过基于CSP（communicating sequential processes）的goroutine和channel来实现，当然也支持使用传统的多线程共享内存的并发方式。\npackage main import ( \u0026#34;fmt\u0026#34; ) func hello() { fmt.Println(\u0026#34;hello\u0026#34;) } func main() { go hello() // 开启线程 fmt.Println(\u0026#34;你好\u0026#34;) } 多线程问题 执行以上代码，程序会退出，主线程执行完退出，主线程下开启的所有线程都会结束，hello()还没来得及执行就被打断了。\n解决办法：\n方法一： 在主函数中添加sleep，使用time.Sleep让 main goroutine 等待 hello goroutine执行结束是不优雅的，当然也是不准确的。\nfunc main() { go hello() fmt.Println(\u0026#34;你好\u0026#34;) time.Sleep(time.Second) } 方法二： Go 语言中通过sync包为我们提供了一些常用的并发原语，我们会在后面的小节单独介绍sync包中的内容。在这一小节，我们会先介绍一下 sync 包中的WaitGroup。当你并不关心并发操作的结果或者有其它方式收集并发操作的结果时，WaitGroup是实现等待一组并发操作完成的好方法。\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;sync\u0026#34; ) // 声明全局等待组变量 var wg sync.WaitGroup func hello() { fmt.Println(\u0026#34;hello\u0026#34;) wg.Done() // 告知当前goroutine完成 } func main() { wg.Add(1) // 登记1个goroutine。启动一个goroutine，就需登记一个 go hello() fmt.Println(\u0026#34;你好\u0026#34;) wg.Wait() // 阻塞等待登记的goroutine完成 } 登记多个goroutine\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;sync\u0026#34; ) // 声明全局等待组变量 var wg sync.WaitGroup func hello(num int) { fmt.Println(\u0026#34;hello\u0026#34;, num) wg.Done() // 告知当前goroutine完成 } func main() { for i := 0; i \u0026lt; 10; i++ { wg.Add(1) // 登记1个goroutine go hello(i) } fmt.Println(\u0026#34;你好\u0026#34;) wg.Wait() // 阻塞等待登记的goroutine完成 } 方法三： 利用channel。。。\npackage main import \u0026#34;fmt\u0026#34; func hello(num int, ch chan bool) { ch \u0026lt;- true fmt.Println(\u0026#34;hellooooo\u0026#34;, num) } func main() { var num = 15 ch := make(chan bool, num) for i := 0; i \u0026lt; num; i++ { go hello(i, ch) } for j := 0; j \u0026lt; num; j++ { \u0026lt;-ch } fmt.Println(\u0026#34;All go routines finished executing\u0026#34;) } GOMAXPROCS Go运行时的调度器使用GOMAXPROCS参数来确定需要使用多少个 OS 线程来同时执行 Go 代码。默认值是机器上的 CPU 核心数。例如在一个 8 核心的机器上，GOMAXPROCS 默认为 8。Go语言中可以通过runtime.GOMAXPROCS函数设置当前程序并发时占用的 CPU逻辑核心数。（Go1.5版本之前，默认使用的是单核心执行。Go1.5 版本之后，默认使用全部的CPU 逻辑核心数。）\nchannel 单纯地将函数并发执行是没有意义的。函数与函数间需要交换数据才能体现并发执行函数的意义。\n虽然可以使用共享内存进行数据交换，但是共享内存在不同的 goroutine 中容易发生竞态问题。为了保证数据交换的正确性，很多并发模型中必须使用互斥量对内存进行加锁，这种做法势必造成性能问题。\nGo语言采用的并发模型是CSP（Communicating Sequential Processes），提倡通过通信共享内存而不是通过共享内存而实现通信。\n如果说 goroutine 是Go程序并发的执行体，channel就是它们之间的连接。channel是可以让一个 goroutine 发送特定值到另一个 goroutine 的通信机制。\nGo 语言中的通道（channel）是一种特殊的类型。通道像一个传送带或者队列，总是遵循先入先出（First In First Out）的规则，保证收发数据的顺序。每一个通道都是一个具体类型的导管，也就是声明channel的时候需要为其指定元素类型。\nchannel类型 channel是 Go 语言中一种特有的类型。声明通道类型变量的格式如下：\nvar 变量名称 chan 元素类型 //元素类型：是指通道中传递元素的类型 //举例 var ch1 chan int // 声明一个传递整型的通道 var ch2 chan bool // 声明一个传递布尔型的通道 var ch3 chan []int // 声明一个传递int切片的通道 channel零值 未初始化的通道类型变量其默认零值是nil。\nvar ch chan int fmt.Println(ch) // \u0026lt;nil\u0026gt; 初始化channel 声明的通道类型变量需要使用内置的make函数初始化之后才能使用。具体格式如下：\nmake(chan 元素类型, [缓冲大小]) //channel的缓冲大小是可选的。 // 举个例子 ch4 := make(chan int) ch5 := make(chan bool, 1) // 声明一个缓冲区大小为1的通道 channel操作 通道共有发送（send）、接收(receive）和关闭（close）三种操作。而发送和接收操作都使用\u0026lt;-符号。\nch := make(chan int) //发送 ch \u0026lt;- 10 // 把10发送到ch中 //接收 x := \u0026lt;- ch // 从ch中接收值并赋值给变量x \u0026lt;-ch // 从ch中接收值，忽略结果 //关闭 close(ch) 关闭后的通道有以下特点：\n对一个关闭的通道再发送值就会导致 panic。 对一个关闭的通道进行接收会一直获取值直到通道为空。 对一个关闭的并且没有值的通道执行接收操作会得到对应类型的零值。 关闭一个已经关闭的通道会导致 panic。 无缓冲的通道 无缓冲的通道又称为阻塞的通道。我们来看一下如下代码片段。\nfunc main() { ch := make(chan int) ch \u0026lt;- 10 fmt.Println(\u0026#34;发送成功\u0026#34;) } 有缓冲的通道 func main() { ch := make(chan int, 1) // 创建一个容量为1的有缓冲区通道 ch \u0026lt;- 10 fmt.Println(\u0026#34;发送成功\u0026#34;) } 有缓冲通道的死锁情况 package main import ( \u0026#34;fmt\u0026#34; ) func main() { ch := make(chan string, 2) \u0026lt;-ch //死锁 ch \u0026lt;- \u0026#34;hello\u0026#34; ch \u0026lt;- \u0026#34;world\u0026#34; ch \u0026lt;- \u0026#34;!\u0026#34; // 死锁 fmt.Println(\u0026lt;-ch) fmt.Println(\u0026lt;-ch) } 多返回值模式 value, ok := \u0026lt;- ch //value：从通道中取出的值，如果通道被关闭则返回对应类型的零值。 //ok：通道ch关闭时返回 false，否则返回 true。 for range接收值 通常我们会选择使用for range循环从通道中接收值，当通道被关闭后，会在通道内的所有值被接收完毕后会自动退出循环。上面那个示例我们使用for range改写后会很简洁。\nfunc f3(ch chan int) { for v := range ch { fmt.Println(v) } } select多路复用 package main import \u0026#34;fmt\u0026#34; func main() { ch := make(chan int, 1) // 打印基数 for i := 1; i \u0026lt;= 10; i++ { select { case x := \u0026lt;-ch: fmt.Println(x) case ch \u0026lt;- i: } } } channel练习 解法1： package main import ( \u0026#34;fmt\u0026#34; \u0026#34;math\u0026#34; \u0026#34;math/rand\u0026#34; ) type Result struct { TaskId int Res string } var resultChan chan *Result func wsum(num int) string { needSum := []int{} for { if num \u0026gt;= 10 { numOne := num % 10 needSum = append(needSum, numOne) num_buf := num / 10 num = int(math.Floor(float64(num_buf))) } else { needSum = append(needSum, num) break } } ret_sum := 0 for i := 0; i \u0026lt; len(needSum); i++ { ret_sum += needSum[i] } // for v := range needSum { // ret_sum += v // fmt.Println(ret_sum) // } // fmt.Printf(\u0026#34;%v sum is %d\\n\u0026#34;, needSum, ret_sum) return fmt.Sprintf(\u0026#34;%v sum is %d\\n\u0026#34;, needSum, ret_sum) } func worker(tId int) { new_num := rand.Int() resInfo := Result{ TaskId: tId, Res: fmt.Sprintf(\u0026#34;%v,%v\u0026#34;, new_num, wsum(new_num)), } // fmt.Println(resInfo) resultChan \u0026lt;- \u0026amp;resInfo } func main() { times := 100 resultChan = make(chan *Result, times) for i := 0; i \u0026lt; times; i++ { go worker(i) } // for v := range resultChan { // fmt.Println(v) // } for j := 0; j \u0026lt; times; j++ { fmt.Println(\u0026lt;-resultChan) } } 解法2 package main import ( \u0026#34;fmt\u0026#34; \u0026#34;math/rand\u0026#34; \u0026#34;strconv\u0026#34; \u0026#34;time\u0026#34; ) type res struct { Num int EachSum int } var jobChan chan int var resultChan chan *res func computeInt(num int) (sumNum int) { time.Sleep(time.Second) strNum := strconv.Itoa(num) fmt.Printf(\u0026#34;%v is %T\\n\u0026#34;, strNum, strNum) for i := 0; i \u0026lt; len(strNum); i++ { eachNum := string(strNum[i]) eachNumInt, _ := strconv.Atoi(eachNum) sumNum += eachNumInt } return } func computeInt2(num int) (sumNum int) { for num \u0026gt; 10 { sumNum += num % 10 num = num / 10 } time.Sleep(time.Second) return } func makeRandInt(jobChan chan int) { rand.Seed(time.Nanosecond.Nanoseconds()) for { num := rand.Int() jobChan \u0026lt;- num } } func computeEachNumSum(jobChan chan int, resultChan chan *res) { for { num := \u0026lt;-jobChan res := \u0026amp;res{Num: num, EachSum: computeInt2(num)} resultChan \u0026lt;- res } } func main() { jobChan = make(chan int) resultChan = make(chan *res) go makeRandInt(jobChan) for i := 0; i \u0026lt; 24; i++ { go computeEachNumSum(jobChan, resultChan) } for v := range resultChan { fmt.Printf(\u0026#34;%#v\\n\u0026#34;, *v) } } Golang Gin框架 go env -w GO111MODULE=on go env -w GOPROXY=https://goproxy.io,direct # 安装gin框架 go get -u github.com/gin-gonic/gin # 解决飘红 go mod init gin go mod edit -require github.com/gin-gonic/gin@latest go mod vendor go env -w GO111MODULE=on\rgo env -w GOPROXY=https://goproxy.io,direct 创建项目后，执行初始命令\ngo mod init 项目名 第一个Gin程序 package main import \u0026#34;github.com/gin-gonic/gin\u0026#34; func main() { r := gin.Default() // func 匿名函数 r.GET(\u0026#34;/ping\u0026#34;, func(c *gin.Context) { //输出json结果给调用方 c.JSON(200, gin.H{ \u0026#34;message\u0026#34;: \u0026#34;pong\u0026#34;, }) }) r.Run() // listen and serve on 0.0.0.0:8080 } 另外一种写法 package main import \u0026#34;github.com/gin-gonic/gin\u0026#34; func testping(c *gin.Context) { c.JSON(200, gin.H{ \u0026#34;message\u0026#34;: \u0026#34;pong\u0026#34;, }) } func main() { r := gin.Default() r.GET(\u0026#34;/ping\u0026#34;, testping) r.Run() // listen and serve on 0.0.0.0:8080 } GET和POST方法 package main import \u0026#34;github.com/gin-gonic/gin\u0026#34; func getPing(c *gin.Context) { c.JSON(200, gin.H{ \u0026#34;message\u0026#34;: \u0026#34;get pong\u0026#34;, }) } func postPing(c *gin.Context) { c.JSON(200, gin.H{ \u0026#34;message\u0026#34;: \u0026#34;post pong\u0026#34;, }) } func main() { r := gin.Default() r.GET(\u0026#34;/ping\u0026#34;, getPing) r.POST(\u0026#34;/ping\u0026#34;, postPing) r.Run() // listen and serve on 0.0.0.0:8080 } Gin框架路由分组 package main import \u0026#34;github.com/gin-gonic/gin\u0026#34; func login(ctx *gin.Context) { ctx.JSON(200, gin.H{ \u0026#34;message\u0026#34;: \u0026#34;success\u0026#34;, }) } func submit(ctx *gin.Context) { ctx.JSON(200, gin.H{ \u0026#34;message\u0026#34;: \u0026#34;success\u0026#34;, }) } func main() { //Default返回一个默认的路由引擎 router := gin.Default() // Simple group: v1 v1 := router.Group(\u0026#34;/api/v1\u0026#34;) { v1.POST(\u0026#34;/login\u0026#34;, login) v1.POST(\u0026#34;/submit\u0026#34;, submit) } // Simple group: v2 v2 := router.Group(\u0026#34;/api/v2\u0026#34;) { v2.POST(\u0026#34;/login\u0026#34;, login) v2.POST(\u0026#34;/submit\u0026#34;, submit) } _ = router.Run(\u0026#34;:8080\u0026#34;) } 参数绑定 package main import ( \u0026#34;net/http\u0026#34; \u0026#34;github.com/gin-gonic/gin\u0026#34; ) // Binding from JSON type Login struct { User string `form:\u0026#34;user\u0026#34; json:\u0026#34;user\u0026#34; binding:\u0026#34;required\u0026#34;` UserId int `form:\u0026#34;user_id\u0026#34; json:\u0026#34;user_id\u0026#34;` Password string `form:\u0026#34;password\u0026#34; json:\u0026#34;password\u0026#34; binding:\u0026#34;required\u0026#34;` } func main() { router := gin.Default() // Example for binding JSON ({\u0026#34;user\u0026#34;: \u0026#34;manu\u0026#34;, \u0026#34;password\u0026#34;: \u0026#34;123\u0026#34;}) router.POST(\u0026#34;/loginJSON\u0026#34;, func(c *gin.Context) { var login Login if err := c.ShouldBindJSON(\u0026amp;login); err == nil { c.JSON(http.StatusOK, gin.H{ \u0026#34;user\u0026#34;: login.User, \u0026#34;user_id\u0026#34;: login.UserId, \u0026#34;password\u0026#34;: login.Password, }) } else { c.JSON(http.StatusBadRequest, gin.H{\u0026#34;error\u0026#34;: err.Error()}) } }) // Example for binding a HTML form (user=manu\u0026amp;password=123) router.POST(\u0026#34;/loginForm\u0026#34;, func(c *gin.Context) { var login Login // This will infer what binder to use depending on the content-type header. if err := c.ShouldBind(\u0026amp;login); err == nil { c.JSON(http.StatusOK, gin.H{ \u0026#34;user\u0026#34;: login.User, \u0026#34;password\u0026#34;: login.Password, }) } else { c.JSON(http.StatusBadRequest, gin.H{\u0026#34;error\u0026#34;: err.Error()}) } }) // Example for binding a HTML querystring (user=manu\u0026amp;password=123) router.GET(\u0026#34;/loginForm\u0026#34;, func(c *gin.Context) { var login Login if err := c.ShouldBind(\u0026amp;login); err == nil { c.JSON(http.StatusOK, gin.H{ \u0026#34;user\u0026#34;: login.User, \u0026#34;password\u0026#34;: login.Password, }) } else { c.JSON(http.StatusBadRequest, gin.H{\u0026#34;error\u0026#34;: err.Error()}) } }) _ = router.Run(\u0026#34;:8080\u0026#34;) } json返回数据渲染 package main import ( \u0026#34;net/http\u0026#34; \u0026#34;github.com/gin-gonic/gin\u0026#34; ) func main() { r := gin.Default() // gin.H is a shortcut for map[string]interface{} r.GET(\u0026#34;/someJSON\u0026#34;, func(c *gin.Context) { //第一种方式,自己拼json c.JSON(http.StatusOK, gin.H{\u0026#34;message\u0026#34;: \u0026#34;hey\u0026#34;, \u0026#34;status\u0026#34;: http.StatusOK}) }) r.GET(\u0026#34;/moreJSON\u0026#34;, func(c *gin.Context) { // 第二种方式 You also can use a struct var msg struct { Name string `json:\u0026#34;user\u0026#34;` Message string Number int } msg.Name = \u0026#34;Lena\u0026#34; msg.Message = \u0026#34;hey\u0026#34; msg.Number = 123 // Note that msg.Name becomes \u0026#34;user\u0026#34; in the JSON c.JSON(http.StatusOK, msg) }) // Listen and serve on 0.0.0.0:8080 r.Run(\u0026#34;:8080\u0026#34;) } swagger 生成接口文档 go get -u github.com/swaggo/swag/cmd/swag swag init package main import ( _ \u0026#34;GinTest2/docs\u0026#34; \u0026#34;github.com/gin-gonic/gin\u0026#34; swaggerFiles \u0026#34;github.com/swaggo/files\u0026#34; ginSwagger \u0026#34;github.com/swaggo/gin-swagger\u0026#34; ) func login(ctx *gin.Context) { ctx.JSON(200, gin.H{ \u0026#34;message\u0026#34;: \u0026#34;success\u0026#34;, }) } func submit(ctx *gin.Context) { ctx.JSON(200, gin.H{ \u0026#34;message\u0026#34;: \u0026#34;success\u0026#34;, }) } func main() { //Default返回一个默认的路由引擎 router := gin.Default() // Simple group: v1 v1 := router.Group(\u0026#34;/api/v1\u0026#34;) { v1.POST(\u0026#34;/login\u0026#34;, login) v1.POST(\u0026#34;/submit\u0026#34;, submit) } // Simple group: v2 v2 := router.Group(\u0026#34;/api/v2\u0026#34;) { v2.POST(\u0026#34;/login\u0026#34;, login) v2.POST(\u0026#34;/submit\u0026#34;, submit) } router.GET(\u0026#34;/swagger/*any\u0026#34;, ginSwagger.WrapHandler(swaggerFiles.Handler)) _ = router.Run(\u0026#34;:8080\u0026#34;) } 访问接口文档 http://localhost:8080/swagger/index.html Golang 使用sqlx连接mysql数据库 安装三方包 go get github.com/go-sql-driver/mysql\rgo get github.com/jmoiron/sqlx main.go文件代码 package main import ( \u0026#34;fmt\u0026#34; _ \u0026#34;github.com/go-sql-driver/mysql\u0026#34; \u0026#34;github.com/jmoiron/sqlx\u0026#34; ) var db *sqlx.DB type user struct { Id int64 UserName string Pwd string } func initDB() (err error) { dsn := \u0026#34;slbtraffic:1qaz#EDC@tcp(10.47.69.231:7306)/billing?charset=utf8mb4\u0026amp;parseTime=True\u0026#34; // 也可以使用MustConnect连接不成功就panic db, err = sqlx.Connect(\u0026#34;mysql\u0026#34;, dsn) if err != nil { fmt.Printf(\u0026#34;connect DB failed, err:%v\\n\u0026#34;, err) return } db.SetMaxOpenConns(20) db.SetMaxIdleConns(10) return } // 查询单条数据示例 func queryRowDemo() { sqlStr := \u0026#34;select id, username, pwd from users where id=?\u0026#34; var u user err := db.Get(\u0026amp;u, sqlStr, 1) if err != nil { fmt.Printf(\u0026#34;get failed, err:%v\\n\u0026#34;, err) return } fmt.Printf(\u0026#34;id:%d name:%s age:%d\\n\u0026#34;, u.Id, u.UserName, u.Pwd) } // 查询多条数据示例 func queryMultiRowDemo() { sqlStr := \u0026#34;select id, username, pwd from users\u0026#34; var u []user err := db.Select(\u0026amp;u, sqlStr) if err != nil { fmt.Printf(\u0026#34;get multi row failed, err:%v\\n\u0026#34;, err) return } for _, val := range u { fmt.Printf(\u0026#34;id:%d name:%s pwd:%s\\n\u0026#34;, val.Id, val.UserName, val.Pwd) } } // 插入数据 func insertRowDemo() { sqlStr := \u0026#34;insert into users(username, pwd) values (?,?)\u0026#34; ret, err := db.Exec(sqlStr, \u0026#34;沙河小王子\u0026#34;, \u0026#34;1235asd124142\u0026#34;) if err != nil { fmt.Printf(\u0026#34;insert failed, err:%v\\n\u0026#34;, err) return } theID, err := ret.LastInsertId() // 新插入数据的id if err != nil { fmt.Printf(\u0026#34;get lastinsert ID failed, err:%v\\n\u0026#34;, err) return } fmt.Printf(\u0026#34;insert success, the id is %d.\\n\u0026#34;, theID) } // 更新数据 func updateRowDemo() { sqlStr := \u0026#34;update users set username=? where username=? limit 1\u0026#34; ret, err := db.Exec(sqlStr, \u0026#34;沙河小王子sb\u0026#34;, \u0026#34;沙河小王子\u0026#34;) if err != nil { fmt.Printf(\u0026#34;upadte failed, err:%v\\n\u0026#34;, err) return } n, err := ret.RowsAffected() // 操作影响的行数 if err != nil { fmt.Printf(\u0026#34;get RowsAffected failed, err:%v\\n\u0026#34;, err) return } fmt.Printf(\u0026#34;update success, RowsAffected is %d.\\n\u0026#34;, n) } // 删除数据 func deleteRowDemo() { sqlStr := \u0026#34;delete from users where id = ?\u0026#34; ret, err := db.Exec(sqlStr, 6) if err != nil { fmt.Printf(\u0026#34;delete failed, err:%v\\n\u0026#34;, err) return } n, err := ret.RowsAffected() // 操作影响的行数 if err != nil { fmt.Printf(\u0026#34;get RowsAffected failed, err:%v\\n\u0026#34;, err) return } fmt.Printf(\u0026#34;delete success, affected rows:%d\\n\u0026#34;, n) } func main() { initDB() queryRowDemo() // insertRowDemo() updateRowDemo() deleteRowDemo() queryMultiRowDemo() } Golang GORM教程 安装和连接 官方文档 https://gorm.io/zh_CN/docs/index.html\n# 创建项目 go mod init 项目名称 go get -u gorm.io/gorm go get -u gorm.io/driver/mysql package main import ( \u0026#34;fmt\u0026#34; \u0026#34;gorm.io/driver/mysql\u0026#34; \u0026#34;gorm.io/gorm\u0026#34; ) type Product struct { gorm.Model Code string `gorm:\u0026#34;type:varchar(255)\u0026#34;` Price uint } func main() { dsn := \u0026#34;slbtraffic:1qaz#EDC@tcp(10.47.69.231:7306)/billing?charset=utf8mb4\u0026amp;parseTime=True\u0026amp;loc=Local\u0026#34; db, err := gorm.Open(mysql.Open(dsn), \u0026amp;gorm.Config{}) if err != nil { panic(\u0026#34;failed to connect database\u0026#34;) } // 迁移 schema // db.AutoMigrate(\u0026amp;Product{}) // // Create // db.Create(\u0026amp;Product{Code: \u0026#34;D43\u0026#34;, Price: 120}) // db.Create(\u0026amp;Product{Code: \u0026#34;D44\u0026#34;, Price: 120}) // db.Create(\u0026amp;Product{Code: \u0026#34;D45\u0026#34;, Price: 120}) // db.Create(\u0026amp;Product{Code: \u0026#34;D46\u0026#34;, Price: 120}) // 查询记录 var productData Product db.First(\u0026amp;productData, 1) fmt.Printf(\u0026#34;productData=%v\\n\u0026#34;, productData) // db.First(\u0026amp;productData, \u0026#34;code = ?\u0026#34;, \u0026#34;D46\u0026#34;) // fmt.Printf(\u0026#34;productData=%#v\\n\u0026#34;, productData) // 修改记录 将D46 修改为D666 // db.Model(\u0026amp;productData).Update(\u0026#34;code\u0026#34;, \u0026#34;D666\u0026#34;) // Update - 更新多个字段 // db.Model(\u0026amp;productData).Updates(Product{Price: 200, Code: \u0026#34;F42\u0026#34;}) // 仅更新非零值字段 // db.Model(\u0026amp;productData).Updates(map[string]interface{}{\u0026#34;Price\u0026#34;: 200, \u0026#34;Code\u0026#34;: \u0026#34;F42\u0026#34;}) // 删除 // db.Delete(\u0026amp;productData, 1) } Golang 操作redis 连接池 安装redis连接库 # 安装三方包 go get github.com/go-redis/redis/v8 # 插件官方 https://github.com/go-redis/redis # 官方文档 https://redis.uptrace.dev/guide/go-redis.html#installation package main import ( \u0026#34;context\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;github.com/go-redis/redis/v8\u0026#34; \u0026#34;time\u0026#34; ) var ctx = context.Background() func main() { rdb := redis.NewClient(\u0026amp;redis.Options{ Addr: \u0026#34;10.43.152.50:10001\u0026#34;, Password: \u0026#34;f1543f7c\u0026#34;, // 密码 DB: 1, // 数据库 PoolSize: 20, // 连接池大小 }) pong, err := rdb.Ping(ctx).Result() fmt.Println(pong, err) // 直接执行命令获取错误 err = rdb.Set(ctx, \u0026#34;key\u0026#34;, 520, time.Hour).Err() // 直接执行命令获取值 value := rdb.Get(ctx, \u0026#34;key\u0026#34;).Val() fmt.Println(value) } Gin 框架 JWT的实现（重要） package main import ( \u0026#34;errors\u0026#34; \u0026#34;net/http\u0026#34; \u0026#34;strings\u0026#34; \u0026#34;time\u0026#34; \u0026#34;github.com/gin-gonic/gin\u0026#34; \u0026#34;github.com/golang-jwt/jwt/v4\u0026#34; ) // jwt 过期时间 const TokenExpireDuration = time.Hour * 2 // CustomSecret 用于加盐的字符串 var CustomSecret = []byte(\u0026#34;夏天夏天悄悄过去\u0026#34;) type UserInfo struct { Username string Password string } type CustomClaims struct { // 可根据需要自行添加字段 Username string `json:\u0026#34;username\u0026#34;` jwt.RegisteredClaims // 内嵌标准的声明 } // GenToken 生成JWT func GenToken(username string) (string, error) { // 创建一个我们自己的声明 claims := CustomClaims{ username, // 自定义字段 jwt.RegisteredClaims{ ExpiresAt: jwt.NewNumericDate(time.Now().Add(TokenExpireDuration)), Issuer: \u0026#34;my-project\u0026#34;, // 签发人 }, } // 使用指定的签名方法创建签名对象 token := jwt.NewWithClaims(jwt.SigningMethodHS256, claims) // 使用指定的secret签名并获得完整的编码后的字符串token return token.SignedString(CustomSecret) } func authHandler(c *gin.Context) { // 用户发送用户名和密码过来 var user UserInfo err := c.ShouldBind(\u0026amp;user) if err != nil { c.JSON(http.StatusOK, gin.H{ \u0026#34;code\u0026#34;: 2001, \u0026#34;msg\u0026#34;: \u0026#34;无效的参数\u0026#34;, }) return } // 校验用户名和密码是否正确 if user.Username == \u0026#34;q1mi\u0026#34; \u0026amp;\u0026amp; user.Password == \u0026#34;q1mi123\u0026#34; { // 生成Token tokenString, _ := GenToken(user.Username) c.JSON(http.StatusOK, gin.H{ \u0026#34;code\u0026#34;: 2000, \u0026#34;msg\u0026#34;: \u0026#34;success\u0026#34;, \u0026#34;data\u0026#34;: gin.H{\u0026#34;token\u0026#34;: tokenString}, }) return } c.JSON(http.StatusOK, gin.H{ \u0026#34;code\u0026#34;: 2002, \u0026#34;msg\u0026#34;: \u0026#34;鉴权失败\u0026#34;, }) return } // ParseToken 解析JWT func ParseToken(tokenString string) (*CustomClaims, error) { // 解析token // 如果是自定义Claim结构体则需要使用 ParseWithClaims 方法 token, err := jwt.ParseWithClaims(tokenString, \u0026amp;CustomClaims{}, func(token *jwt.Token) (i interface{}, err error) { // 直接使用标准的Claim则可以直接使用Parse方法 //token, err := jwt.Parse(tokenString, func(token *jwt.Token) (i interface{}, err error) { return CustomSecret, nil }) if err != nil { return nil, err } // 对token对象中的Claim进行类型断言 if claims, ok := token.Claims.(*CustomClaims); ok \u0026amp;\u0026amp; token.Valid { // 校验token return claims, nil } return nil, errors.New(\u0026#34;invalid token\u0026#34;) } // JWTAuthMiddleware 基于JWT的认证中间件 func JWTAuthMiddleware() func(c *gin.Context) { return func(c *gin.Context) { // 客户端携带Token有三种方式 1.放在请求头 2.放在请求体 3.放在URI // 这里假设Token放在Header的Authorization中，并使用Bearer开头 // 这里的具体实现方式要依据你的实际业务情况决定 authHeader := c.Request.Header.Get(\u0026#34;Authorization\u0026#34;) if authHeader == \u0026#34;\u0026#34; { c.JSON(http.StatusOK, gin.H{ \u0026#34;code\u0026#34;: 2003, \u0026#34;msg\u0026#34;: \u0026#34;请求头中auth为空\u0026#34;, }) c.Abort() return } // 按空格分割 parts := strings.SplitN(authHeader, \u0026#34; \u0026#34;, 2) if !(len(parts) == 2 \u0026amp;\u0026amp; parts[0] == \u0026#34;Bearer\u0026#34;) { c.JSON(http.StatusOK, gin.H{ \u0026#34;code\u0026#34;: 2004, \u0026#34;msg\u0026#34;: \u0026#34;请求头中auth格式有误\u0026#34;, }) c.Abort() return } // parts[1]是获取到的tokenString，我们使用之前定义好的解析JWT的函数来解析它 mc, err := ParseToken(parts[1]) if err != nil { c.JSON(http.StatusOK, gin.H{ \u0026#34;code\u0026#34;: 2005, \u0026#34;msg\u0026#34;: \u0026#34;无效的Token\u0026#34;, }) c.Abort() return } // 将当前请求的username信息保存到请求的上下文c上 c.Set(\u0026#34;username\u0026#34;, mc.Username) c.Next() // 后续的处理函数可以用过c.Get(\u0026#34;username\u0026#34;)来获取当前请求的用户信息 } } func homeHandler(c *gin.Context) { username := c.MustGet(\u0026#34;username\u0026#34;).(string) c.JSON(http.StatusOK, gin.H{ \u0026#34;code\u0026#34;: 2000, \u0026#34;msg\u0026#34;: \u0026#34;success\u0026#34;, \u0026#34;data\u0026#34;: gin.H{\u0026#34;username\u0026#34;: username}, }) } func main() { r := gin.Default() r.POST(\u0026#34;/auth\u0026#34;, authHandler) r.GET(\u0026#34;/home\u0026#34;, JWTAuthMiddleware(), homeHandler) r.Run() } swagger接口文档 用法步骤 按照swagger要求给接口代码添加声明式注释，具体参照声明式注释格式。 使用swag工具扫描代码自动生成API接口文档数据 使用gin-swagger渲染在线接口文档页面 安装swag工具，在注释编写完成后使用 go get -u github.com/swaggo/swag/cmd/swag swag init # 会生成docs目录 #./docs #├── docs.go #├── swagger.json #└── swagger.yaml 引入gin-swagger import ( _ \u0026#34;GinJwt/docs\u0026#34; // 千万不要忘了导入把你上一步生成的docs \u0026#34;github.com/gin-gonic/gin\u0026#34; swaggerFiles \u0026#34;github.com/swaggo/files\u0026#34; gs \u0026#34;github.com/swaggo/gin-swagger\u0026#34; ) 下载三方包 go get github.com/swaggo/gin-swagger go get github.com/swaggo/files package main import ( \u0026#34;errors\u0026#34; \u0026#34;net/http\u0026#34; \u0026#34;strings\u0026#34; \u0026#34;time\u0026#34; _ \u0026#34;GinJwt/docs\u0026#34; // 千万不要忘了导入把你上一步生成的docs \u0026#34;github.com/gin-gonic/gin\u0026#34; \u0026#34;github.com/golang-jwt/jwt/v4\u0026#34; swaggerFiles \u0026#34;github.com/swaggo/files\u0026#34; gs \u0026#34;github.com/swaggo/gin-swagger\u0026#34; ) // jwt 过期时间 const TokenExpireDuration = time.Hour * 2 // CustomSecret 用于加盐的字符串 var CustomSecret = []byte(\u0026#34;夏天夏天悄悄过去\u0026#34;) type UserInfo struct { Username string Password string } type CustomClaims struct { // 可根据需要自行添加字段 Username string `json:\u0026#34;username\u0026#34;` jwt.RegisteredClaims // 内嵌标准的声明 } // GenToken 生成JWT func GenToken(username string) (string, error) { // 创建一个我们自己的声明 claims := CustomClaims{ username, // 自定义字段 jwt.RegisteredClaims{ ExpiresAt: jwt.NewNumericDate(time.Now().Add(TokenExpireDuration)), Issuer: \u0026#34;my-project\u0026#34;, // 签发人 }, } // 使用指定的签名方法创建签名对象 token := jwt.NewWithClaims(jwt.SigningMethodHS256, claims) // 使用指定的secret签名并获得完整的编码后的字符串token return token.SignedString(CustomSecret) } func authHandler(c *gin.Context) { // 用户发送用户名和密码过来 var user UserInfo err := c.ShouldBind(\u0026amp;user) if err != nil { c.JSON(http.StatusOK, gin.H{ \u0026#34;code\u0026#34;: 2001, \u0026#34;msg\u0026#34;: \u0026#34;无效的参数\u0026#34;, }) return } // 校验用户名和密码是否正确 if user.Username == \u0026#34;q1mi\u0026#34; \u0026amp;\u0026amp; user.Password == \u0026#34;q1mi123\u0026#34; { // 生成Token tokenString, _ := GenToken(user.Username) c.JSON(http.StatusOK, gin.H{ \u0026#34;code\u0026#34;: 2000, \u0026#34;msg\u0026#34;: \u0026#34;success\u0026#34;, \u0026#34;data\u0026#34;: gin.H{\u0026#34;token\u0026#34;: tokenString}, }) return } c.JSON(http.StatusOK, gin.H{ \u0026#34;code\u0026#34;: 2002, \u0026#34;msg\u0026#34;: \u0026#34;鉴权失败\u0026#34;, }) return } // ParseToken 解析JWT func ParseToken(tokenString string) (*CustomClaims, error) { // 解析token // 如果是自定义Claim结构体则需要使用 ParseWithClaims 方法 token, err := jwt.ParseWithClaims(tokenString, \u0026amp;CustomClaims{}, func(token *jwt.Token) (i interface{}, err error) { // 直接使用标准的Claim则可以直接使用Parse方法 //token, err := jwt.Parse(tokenString, func(token *jwt.Token) (i interface{}, err error) { return CustomSecret, nil }) if err != nil { return nil, err } // 对token对象中的Claim进行类型断言 if claims, ok := token.Claims.(*CustomClaims); ok \u0026amp;\u0026amp; token.Valid { // 校验token return claims, nil } return nil, errors.New(\u0026#34;invalid token\u0026#34;) } // JWTAuthMiddleware 基于JWT的认证中间件 func JWTAuthMiddleware() func(c *gin.Context) { return func(c *gin.Context) { // 客户端携带Token有三种方式 1.放在请求头 2.放在请求体 3.放在URI // 这里假设Token放在Header的Authorization中，并使用Bearer开头 // 这里的具体实现方式要依据你的实际业务情况决定 authHeader := c.Request.Header.Get(\u0026#34;Authorization\u0026#34;) if authHeader == \u0026#34;\u0026#34; { c.JSON(http.StatusOK, gin.H{ \u0026#34;code\u0026#34;: 2003, \u0026#34;msg\u0026#34;: \u0026#34;请求头中auth为空\u0026#34;, }) c.Abort() return } // 按空格分割 parts := strings.SplitN(authHeader, \u0026#34; \u0026#34;, 2) if !(len(parts) == 2 \u0026amp;\u0026amp; parts[0] == \u0026#34;Bearer\u0026#34;) { c.JSON(http.StatusOK, gin.H{ \u0026#34;code\u0026#34;: 2004, \u0026#34;msg\u0026#34;: \u0026#34;请求头中auth格式有误\u0026#34;, }) c.Abort() return } // parts[1]是获取到的tokenString，我们使用之前定义好的解析JWT的函数来解析它 mc, err := ParseToken(parts[1]) if err != nil { c.JSON(http.StatusOK, gin.H{ \u0026#34;code\u0026#34;: 2005, \u0026#34;msg\u0026#34;: \u0026#34;无效的Token\u0026#34;, }) c.Abort() return } // 将当前请求的username信息保存到请求的上下文c上 c.Set(\u0026#34;username\u0026#34;, mc.Username) c.Next() // 后续的处理函数可以用过c.Get(\u0026#34;username\u0026#34;)来获取当前请求的用户信息 } } // homeHandler 测试jwt功能接口 // @Summary 测试jwt功能接口 // @Description 测试jwt功能接口 // @Tags 测试jwt功能接口 // @Accept application/json // @Produce application/json // @Param Authorization header string false \u0026#34;Bearer 用户令牌\u0026#34; // @Security ApiKeyAuth // @Success 200 // @Router /home [get] {\u0026#34;username\u0026#34;: username} func homeHandler(c *gin.Context) { username := c.MustGet(\u0026#34;username\u0026#34;).(string) c.JSON(http.StatusOK, gin.H{ \u0026#34;code\u0026#34;: 2000, \u0026#34;msg\u0026#34;: \u0026#34;success\u0026#34;, \u0026#34;data\u0026#34;: gin.H{\u0026#34;username\u0026#34;: username}, }) } func main() { r := gin.Default() r.POST(\u0026#34;/auth\u0026#34;, authHandler) r.GET(\u0026#34;/home\u0026#34;, JWTAuthMiddleware(), homeHandler) r.GET(\u0026#34;/swagger/*any\u0026#34;, gs.WrapHandler(swaggerFiles.Handler)) r.Run() } 访问地址 http://localhost:8080/swagger/index.html\nGolang三方库 gopsutil psutil是一个跨平台进程和系统监控的Python库，而gopsutil是其Go语言版本的实现。本文介绍了它的基本使用。\nGo语言部署简单、性能好的特点非常适合做一些诸如采集系统信息和监控的服务，本文介绍的gopsutil库是知名Python库：psutil的一个Go语言版本的实现。\n安装 go get github.com/shirou/gopsutil windows额外安装\ngo get github.com/yusufpapurcu/wmi go get golang.org/x/sys/windows 使用 采集CPU相关信息 import \u0026#34;github.com/shirou/gopsutil/cpu\u0026#34; import \u0026#34;github.com/shirou/gopsutil/load\u0026#34; import \u0026#34;github.com/shirou/gopsutil/mem\u0026#34; import \u0026#34;github.com/shirou/gopsutil/host\u0026#34; import \u0026#34;github.com/shirou/gopsutil/disk\u0026#34; import \u0026#34;github.com/shirou/gopsutil/net\u0026#34; // cpu info func getCpuInfo() { cpuInfos, err := cpu.Info() if err != nil { fmt.Printf(\u0026#34;get cpu info failed, err:%v\u0026#34;, err) } for _, ci := range cpuInfos { fmt.Println(ci) } // CPU使用率 for { percent, _ := cpu.Percent(time.Second, false) fmt.Printf(\u0026#34;cpu percent:%v\\n\u0026#34;, percent) } } func getCpuLoad() { info, _ := load.Avg() fmt.Printf(\u0026#34;%v\\n\u0026#34;, info) } // mem info func getMemInfo() { memInfo, _ := mem.VirtualMemory() fmt.Printf(\u0026#34;mem info:%v\\n\u0026#34;, memInfo) } // host info func getHostInfo() { hInfo, _ := host.Info() fmt.Printf(\u0026#34;host info:%v uptime:%v boottime:%v\\n\u0026#34;, hInfo, hInfo.Uptime, hInfo.BootTime) } // disk info func getDiskInfo() { parts, err := disk.Partitions(true) if err != nil { fmt.Printf(\u0026#34;get Partitions failed, err:%v\\n\u0026#34;, err) return } for _, part := range parts { fmt.Printf(\u0026#34;part:%v\\n\u0026#34;, part.String()) diskInfo, _ := disk.Usage(part.Mountpoint) fmt.Printf(\u0026#34;disk info:used:%v free:%v\\n\u0026#34;, diskInfo.UsedPercent, diskInfo.Free) } ioStat, _ := disk.IOCounters() for k, v := range ioStat { fmt.Printf(\u0026#34;%v:%v\\n\u0026#34;, k, v) } } // net IO func getNetInfo() { info, _ := net.IOCounters(true) for index, v := range info { fmt.Printf(\u0026#34;%v:%v send:%v recv:%v\\n\u0026#34;, index, v, v.BytesSent, v.BytesRecv) } } // get ip func GetLocalIP() (ip string, err error) { addrs, err := net.InterfaceAddrs() if err != nil { return } for _, addr := range addrs { ipAddr, ok := addr.(*net.IPNet) if !ok { continue } if ipAddr.IP.IsLoopback() { continue } if !ipAddr.IP.IsGlobalUnicast() { continue } return ipAddr.IP.String(), nil } return } 适用工具，上传下载文件 package main import ( \u0026#34;flag\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;github.com/gin-gonic/gin\u0026#34; \u0026#34;io/ioutil\u0026#34; \u0026#34;log\u0026#34; \u0026#34;net/http\u0026#34; ) var ( FileDir = flag.String(\u0026#34;d\u0026#34;, \u0026#34;D:\\\\golang_project\\\\src\\\\uploadDownload\\\\file_dir\u0026#34;, `-d 绝对路径 指定上传和下载的目录`) Port = flag.Int(\u0026#34;p\u0026#34;, 8080,`-p 监听端口号 指定程序运行端口号`) ) func main() { flag.Parse() router := gin.Default() // 处理multipart forms提交文件时默认的内存限制是32 MiB // 可以通过下面的方式修改 // router.MaxMultipartMemory = 8 \u0026lt;\u0026lt; 20 // 8 MiB router.POST(\u0026#34;/upload\u0026#34;, func(c *gin.Context) { // Multipart form form, _ := c.MultipartForm() files := form.File[\u0026#34;file\u0026#34;] for _, file := range files { log.Println(file.Filename) dst := fmt.Sprintf(\u0026#34;%s/%s\u0026#34;, *FileDir, file.Filename) fmt.Println(dst) // 上传文件到指定的目录 c.SaveUploadedFile(file, dst) } c.JSON(http.StatusOK, gin.H{ \u0026#34;message\u0026#34;: fmt.Sprintf(\u0026#34;%d files uploaded!\u0026#34;, len(files)), }) }) router.GET(\u0026#34;/listfile\u0026#34;, func(c *gin.Context) { fileInfoList, err := ioutil.ReadDir(*FileDir) var FileList []string for i := range fileInfoList { FileList = append(FileList,fileInfoList[i].Name()) } if err != nil { c.JSON(http.StatusBadRequest, gin.H{ \u0026#34;code\u0026#34;: 400, \u0026#34;msg\u0026#34;: \u0026#34;Error\u0026#34;, }) }else { c.JSON(http.StatusOK, gin.H{ \u0026#34;code\u0026#34;: 200, \u0026#34;file_list\u0026#34;: FileList, }) } }) router.GET(\u0026#34;/download/:file\u0026#34;, func(c *gin.Context) { filename := c.Param(\u0026#34;file\u0026#34;) filepath := fmt.Sprintf(\u0026#34;%s/%s\u0026#34;, *FileDir, filename) c.File(filepath) }) port := fmt.Sprintf(\u0026#34;:%d\u0026#34;,*Port) router.Run(port) } 常用函数 时间和日期相关函数 package main import ( \u0026#34;fmt\u0026#34; \u0026#34;time\u0026#34; ) func main() { // 日期和时间相关的函数 now := time.Now() fmt.Printf(\u0026#34;%v \\n\u0026#34;, now) //2022-08-16 17:08:36.0952186 +0800 CST m=+0.007682101 // 获取时间其他相关信息 fmt.Printf(\u0026#34;%v-%v-%v %v:%v:%v\\n\u0026#34;, now.Year(), int(now.Month()), now.Day(), now.Hour(), now.Minute(), now.Second()) // 格式化日期和时间 // 1、printf fmtTime := fmt.Sprintf(\u0026#34;%v-%v-%v %v:%v:%v\u0026#34;, now.Year(), int(now.Month()), now.Day(), now.Hour(), now.Minute(), now.Second()) fmt.Println(fmtTime) // 2、使用官方的format函数 (推荐) fmt.Println(time.Now().Format(\u0026#34;2006-01-02 15:04:05\u0026#34;)) fmt.Println(time.Now().Format(\u0026#34;01-02\u0026#34;)) //时间 to 时间戳 loc, _ := time.LoadLocation(\u0026#34;Asia/Shanghai\u0026#34;) //设置时区 tt, _ := time.ParseInLocation(\u0026#34;2006-01-02 15:04:05\u0026#34;, \u0026#34;2018-07-11 15:07:51\u0026#34;, loc) //2006-01-02 15:04:05是转换的格式如php的\u0026#34;Y-m-d H:i:s\u0026#34; fmt.Println(tt.Unix()) // 时间常量 const ( ns = time.Nanosecond us = time.Microsecond ms = time.Millisecond ss = time.Second ) // 时间戳 Unix UnixNano 纳秒 获取随机数字 fmt.Printf(\u0026#34;unix时间戳=%v unixnano时间戳=%v\\n\u0026#34;, now.Unix(), now.UnixNano()) // 时间戳转日期 needConvertUnix := now.Unix() needConvertUnixTime := time.Unix(needConvertUnix, 0).Format(\u0026#34;2006-01-02 15:04:05\u0026#34;) fmt.Printf(\u0026#34;时间戳:%v is %v\\n\u0026#34;, needConvertUnix, needConvertUnixTime) // 时间加减 // 一天前的时间 oneDayBefore, _ := time.ParseDuration(\u0026#34;-24h\u0026#34;) d1 := now.Add(oneDayBefore).Format(\u0026#34;2006-01-02 15:04:05\u0026#34;) fmt.Printf(\u0026#34;昨天的日期：%v \\n\u0026#34;, d1) d2 := now.AddDate(0, -1, 0).Format(\u0026#34;2006-01-02 15:04:05\u0026#34;) fmt.Printf(\u0026#34;上月的日期：%v\u0026#34;, d2) } os标准库 // 遍历所有环境遍历 envs := os.Environ() for _, value := range envs { cache := strings.Split(value, \u0026#34;=\u0026#34;) fmt.Println(cache) } // 获取指定名称的环境变量 golandEnv := os.Getenv(\u0026#34;GoLand\u0026#34;) fmt.Printf(\u0026#34;golandEnv is %s\\n\u0026#34;, golandEnv) // 打印主机名 fmt.Println(os.Hostname()) // 获取当前路径 filePath, _ := os.Getwd() fmt.Println(filePath) bytes标准库 func TestConvertAb(t *testing.T) { var b = []byte(\u0026#34;abcaBSADASD12-2131\u0026#34;) // 转大写 upper := bytes.ToUpper(b) // 转小写 lower := bytes.ToLower(b) fmt.Println(string(b), string(upper), string(lower)) var c = []byte(\u0026#34;ABC\u0026#34;) var d = []byte(\u0026#34;ABc\u0026#34;) // 忽略大小写比较 if bytes.EqualFold(c, d) { fmt.Printf(\u0026#34;c:%v,d:%v c=d成立\\n\u0026#34;, c, d) } } ","permalink":"https://www.sulvblog.cn/post/golang/","summary":"推荐博客 https://www.liwenzhou.com/posts/Go/golang-menu/\nLinux 安装go语言环境 # 下载地址 https://golang.google.cn/dl/ tar -xvzf go1.17.11.linux-386.tar.gz -C /usr/local yum install glibc.i686 -y mkdir -p /root/workspace cat \u0026lt;\u0026lt;EOF \u0026gt;\u0026gt; /etc/profile export PATH=$PATH:/usr/local/go/bin export GOPATH=\u0026#34;$HOME/workspace\u0026#34; EOF source /etc/profile #设置国内代理 go env -w GOPROXY=https://goproxy.cn,direct #查看go env go env Linux下创建一个go项目 #查看GOPATH go env | grep -i gopath #GOPATH=\u0026#34;/root/workspace\u0026#34; cd /root/workspace;mkdir {src,bin,pkg} #进入src目录创建项目 cd src \u0026amp;\u0026amp; mkdir GoRedis #随后编写main.go文件 构建多平台运行代码 go env -w GOOS=linux go env -w GOARCH=amd64 go build go env -w GOOS=windwos go env -w GOARCH=amd64 go build main.","title":"Golang学习笔记"},{"content":"golang定时任务系统 项目地址： https://github.com/ouqiang/gocron/releases 部署方法 https://github.com/ouqiang/gocron/releases/download/v1.5.3/gocron-node-v1.5.3-linux-amd64.tar.gz\nhttps://github.com/ouqiang/gocron/releases/download/v1.5.3/gocron-v1.5.3-linux-amd64.tar.gz\n项目分为两个包 gocron-node和gocron，gocron-node为任务节点，实际执行任务，gocron为web端\n创建gocron用户 useradd gocron 解压软件包并运行 tar -xvzf gocron-node-v1.5.3-linux-amd64.tar.gz -C /home/gocron tar -xvzf gocron-v1.5.3-linux-amd64.tar.gz -C /home/gocron # 修改权限 chown gocron:gocron -R /home/gocron/ # 运行gocron web端 前台运行，监听5920端口 cd /home/gocron/gocron-linux-amd64 \u0026amp;\u0026amp; su gocron \u0026amp;\u0026amp; ./gocron web # 新起窗口运行gocron node任务节点 前台运行 cd /home/gocron/gocron-node-linux-amd64 su gocron \u0026amp;\u0026amp; ./gocron-node 1、登录web页面，访问 http://localhost:5920\n2、初始化数据库，并创建登录用户，注意数据库要单独使用新库，不能有其他表\n3、然后登录，添加任务节点，添加完成后测试连接\n![image-20220721155135950](D:\\typora Note\\assets\\image-20220721155135950.png)\n4、进入系统管理配置通知配置\n使用钉钉webhook进行通知\n![image-20220721155256643](D:\\typora Note\\assets\\image-20220721155256643.png)\n模板文件写法：\n{ \u0026#34;at\u0026#34;: { \u0026#34;atMobiles\u0026#34;: [ \u0026#34;\u0026#34; ], \u0026#34;atUserIds\u0026#34;: [ \u0026#34;user123\u0026#34; ], \u0026#34;isAtAll\u0026#34;: \u0026#34;false\u0026#34; }, \u0026#34;text\u0026#34;: { \u0026#34;content\u0026#34;: \u0026#34;任务ID: {{.TaskId}} 任务名称: {{.TaskName}} 状态: {{.Status}} 执行结果: \\n{{.Result}}\u0026#34; }, \u0026#34;msgtype\u0026#34;: \u0026#34;text\u0026#34; } 5、新增定时任务\n![image-20220721155354483](D:\\typora Note\\assets\\image-20220721155354483.png)\nCrontab时间表达式 Linux-crontab时间表达式语法, 支持秒级任务定义 格式: 秒 分 时 天 月 周 示例： 1 * * * * * 每分钟第一秒运行 */20 * * * * * 每隔20秒运行一次 0 30 21 * * * 每天晚上21:30:00运行一次 0 0 23 * * 6 每周六晚上23:00:00 运行一次 快捷语法: @yearly 每年运行一次 @monthly 每月运行一次 @weekly 每周运行一次 @daily 每天运行一次 @midnight 每天午夜运行一次 @hourly 每小时运行一次 @every 30s 每隔30秒运行一次 @every 1m20s 每隔1分钟20秒运行一次 @every 3h5m10s 每隔3小时5分钟10秒运行一次 执行方式 shell: 在远程主机上执行shell命令 HTTP: 执行HTTP-GET请求 任务超时时间 任务执行超时，强制结束, 默认0，不限制 shell任务执行时间不能超过86400秒 HTTP任务执行时间不能超过300秒.\n任务执行失败重试次数 无法连接远程主机，shell返回值非0, HTTP响应码非200等异常返回, 可再次执行任务, 每次重试间隔时间 = 重试次数 * 1分钟 按1分钟、2分钟、3分钟\u0026hellip;..的间隔进行重试 取值范围1-10 例: 重试次数为2 任务执行失败, 休眠1分钟, 再次执行任务 再次执行失败, 休眠2分钟, 再次执行任务 默认0，不重试.\n开启安全 TLS双向认证（重要） 为了确保数据传输及任务节点gocron-node安全, 强烈建议开启\n下载证书制作工具 wget https://github.com/square/certstrap/releases/download/v1.1.1/certstrap-v1.1.1-linux-amd64 \u0026amp;\u0026amp; mv certstrap-v1.1.1-linux-amd64 /usr/bin/certstrap \u0026amp;\u0026amp; chmod +x /usr/bin/certstrap 生成证书 # 生成CA证书 ./certstrap init --common-name \u0026#34;Root CA\u0026#34; # 生成服务端(gocron-node)证书和私钥 ./certstrap request-cert --ip 10.43.152.50 ./certstrap sign --CA \u0026#34;Root CA\u0026#34; --years 20 10.43.152.50 # 生成客户端(gocron)证书和私钥 ./certstrap request-cert --ip 127.0.0.1 ./certstrap sign --CA \u0026#34;Root CA\u0026#34; --years 20 127.0.0.1 # 生成证书会到当前目录out文件下 # 修改私钥*.key权限,只能被运行gocron-node的用户读取 cd out/ chmod 600 10.43.152.50.key chmod 600 127.0.0.1.key # 拷贝密钥到对应文件夹 mkdir /home/gocron/gocron-linux-amd64/cert/ cp Root_CA.crt 10.43.152.50.crt 10.43.152.50.key /home/gocron/gocron-node-linux-amd64/ cp Root_CA.crt 127.0.0.1.crt 127.0.0.1.key /home/gocron/gocron-linux-amd64/cert/ 启动服务 # 启动node节点（使用非root用户） cd /home/gocron/gocron-node-linux-amd64/ ./gocron-node -enable-tls -ca-file Root_CA.crt -cert-file 10.43.152.50.crt -key-file 10.43.152.50.key # 先修改gocron web端 conf/app.ini配置文件 enable_tls = true ca_file = /home/gocron/gocron-linux-amd64/cert/Root_CA.crt cert_file = /home/gocron/gocron-linux-amd64/cert/127.0.0.1.crt key_file = /home/gocron/gocron-linux-amd64/cert/127.0.0.1.key # 启动gocron web端（使用非root用户） cd /home/gocron/gocron-linux-amd64/ \u0026amp;\u0026amp; ./gocron web 常见报错 docker容器内部发送消息失败\n![image-20220721234104982](D:\\typora Note\\assets\\image-20220721234104982.png)\nx509: certificate signed by unknown authority\n我们在构建 docker 镜像时一般使用的是 linux(centos或者ubuntu等待) 系统，默认是不带 ca-certificates 根证书的，导致无法识别外部 https 携带的数字证书。那么，在访问的时候就会抛出 x509: certificate signed by unknown authority 的错误，导致 docker 容器的接口服务返回 500。\nUbuntu构建镜像时安装ca-certificates包\napt-get -qq install -y --no-install-recommends ca-certificates curl ","permalink":"https://www.sulvblog.cn/post/golang%E5%AE%9A%E6%97%B6%E4%BB%BB%E5%8A%A1%E7%B3%BB%E7%BB%9F/","summary":"golang定时任务系统 项目地址： https://github.com/ouqiang/gocron/releases 部署方法 https://github.com/ouqiang/gocron/releases/download/v1.5.3/gocron-node-v1.5.3-linux-amd64.tar.gz\nhttps://github.com/ouqiang/gocron/releases/download/v1.5.3/gocron-v1.5.3-linux-amd64.tar.gz\n项目分为两个包 gocron-node和gocron，gocron-node为任务节点，实际执行任务，gocron为web端\n创建gocron用户 useradd gocron 解压软件包并运行 tar -xvzf gocron-node-v1.5.3-linux-amd64.tar.gz -C /home/gocron tar -xvzf gocron-v1.5.3-linux-amd64.tar.gz -C /home/gocron # 修改权限 chown gocron:gocron -R /home/gocron/ # 运行gocron web端 前台运行，监听5920端口 cd /home/gocron/gocron-linux-amd64 \u0026amp;\u0026amp; su gocron \u0026amp;\u0026amp; ./gocron web # 新起窗口运行gocron node任务节点 前台运行 cd /home/gocron/gocron-node-linux-amd64 su gocron \u0026amp;\u0026amp; ./gocron-node 1、登录web页面，访问 http://localhost:5920\n2、初始化数据库，并创建登录用户，注意数据库要单独使用新库，不能有其他表\n3、然后登录，添加任务节点，添加完成后测试连接\n![image-20220721155135950](D:\\typora Note\\assets\\image-20220721155135950.png)\n4、进入系统管理配置通知配置\n使用钉钉webhook进行通知\n![image-20220721155256643](D:\\typora Note\\assets\\image-20220721155256643.png)\n模板文件写法：\n{ \u0026#34;at\u0026#34;: { \u0026#34;atMobiles\u0026#34;: [ \u0026#34;\u0026#34; ], \u0026#34;atUserIds\u0026#34;: [ \u0026#34;user123\u0026#34; ], \u0026#34;isAtAll\u0026#34;: \u0026#34;false\u0026#34; }, \u0026#34;text\u0026#34;: { \u0026#34;content\u0026#34;: \u0026#34;任务ID: {{.","title":"golang定时任务系统"},{"content":"golang微服务 1、RPC 简介 ⚫ 远程过程调用（Remote Procedure Call，RPC）是一个计算机通信协议\n⚫ 该协议允许运行于一台计算机的程序调用另一台计算机的子程序，而程序员无需额 外地为这个交互作用编程\n⚫ 如果涉及的软件采用面向对象编程，那么远程过程调用亦可称作远程调用或远程方 法调用\n2、golang中如何实现RPC ⚫ golang 中实现 RPC 非常简单，官方提供了封装好的库，还有一些第三方的库\n⚫ golang 官方的 net/rpc 库使用 encoding/gob 进行编解码，支持 tcp 和 http 数据传输方 式，由于其他语言不支持 gob 编解码方式，所以 golang 的 RPC 只支持 golang 开发 的服务器与客户端之间的交互\n⚫ 官方还提供了 net/rpc/jsonrpc 库实现 RPC 方法，jsonrpc 采用 JSON 进行数据编解码， 因而支持跨语言调用，目前 jsonrpc 库是基于 tcp 协议实现的，暂不支持 http 传输 方式\n⚫ golang 的 RPC 必须符合 4 个条件才可以\n​\t◼ 结构体字段首字母要大写，要跨域访问，所以大写\n​\t◼ 函数名必须首字母大写（可以序列号导出的）\n​\t◼ 函数第一个参数是接收参数，第二个参数是返回给客户端参数，必须是指针类 型\n​\t◼ 函数必须有一个返回值 error\n⚫ 另外，net/rpc/jsonrpc 库通过 json 格式编解码，支持跨语言调用\n服务端代码： package main import ( \u0026#34;log\u0026#34; \u0026#34;net/http\u0026#34; \u0026#34;net/rpc\u0026#34; ) // 服务端，求矩形面积和周长 // Rect 声明矩形对象 type Rect struct { } // Params 生命参数结构体，字段首字母大写 type Params struct { Width, Height int } // Area 求矩形面积的方法 func (r *Rect) Area(p Params, ret *int) error { *ret = p.Width * p.Height return nil } // Perimeter 求矩形面积的方法 func (r *Rect) Perimeter(p Params, ret *int) error { *ret = (p.Width + p.Height) * 2 return nil } func main() { // 1、注册服务 rect := new(Rect) rpc.Register(rect) // 2、把服务处理绑定到http协议上 rpc.HandleHTTP() // 3、监听服务，等待客户端调用 err := http.ListenAndServe(\u0026#34;:8080\u0026#34;, nil) if err != nil { log.Fatal(err) } } 服务端代码（jsonrpc调用）： func main() { // 1、注册服务 rpc.Register(new(Rect)) // 2、把服务处理绑定到http协议上 lis,err := net.Listen(\u0026#34;tcp\u0026#34;,\u0026#34;127.0.0.1:8081\u0026#34;) if err != nil { log.Fatal(err) } //循环监听服务 for { conn, err := lis.Accept() if err != nil { continue } // 起协程 go func(conn net.Conn) { fmt.Println(\u0026#34;new a client\u0026#34;) jsonrpc.ServeConn(conn) }(conn) } } 客户端代码： package main import ( \u0026#34;fmt\u0026#34; \u0026#34;log\u0026#34; \u0026#34;net/rpc\u0026#34; ) // Params 定义参数结构体 type Params struct { Width, Height int } // 调用服务 func main() { // 1、连接远程rpc服务 //http调用 rp, err := rpc.DialHTTP(\u0026#34;tcp\u0026#34;, \u0026#34;127.0.0.1:8080\u0026#34;) // json rpc 调用 // rp, err := jsonrpc.Dial(\u0026#34;tcp\u0026#34;, \u0026#34;127.0.0.1:8081\u0026#34;) if err != nil { log.Fatal(err) } // 2、调用远程方法 // 定义接收服务端传回来的计算结果的变量 var ret int // ret := 0 pArgs := Params{Width: 100, Height: 50} // 求面积 err2 := rp.Call(\u0026#34;Rect.Area\u0026#34;, pArgs, \u0026amp;ret) if err2 != nil { log.Fatal(err2) } fmt.Printf(\u0026#34;width: %d,height: %d \u0026#39;s area is %d\\n\u0026#34;, pArgs.Width, pArgs.Height, ret) // 求周长 err3 := rp.Call(\u0026#34;Rect.Perimeter\u0026#34;, pArgs, \u0026amp;ret) if err3 != nil { log.Fatal(err3) } fmt.Printf(\u0026#34;width: %d,height: %d \u0026#39;s perimeter is %d\\n\u0026#34;, pArgs.Width, pArgs.Height, ret) } ","permalink":"https://www.sulvblog.cn/post/golang%E5%BE%AE%E6%9C%8D%E5%8A%A1/","summary":"golang微服务 1、RPC 简介 ⚫ 远程过程调用（Remote Procedure Call，RPC）是一个计算机通信协议\n⚫ 该协议允许运行于一台计算机的程序调用另一台计算机的子程序，而程序员无需额 外地为这个交互作用编程\n⚫ 如果涉及的软件采用面向对象编程，那么远程过程调用亦可称作远程调用或远程方 法调用\n2、golang中如何实现RPC ⚫ golang 中实现 RPC 非常简单，官方提供了封装好的库，还有一些第三方的库\n⚫ golang 官方的 net/rpc 库使用 encoding/gob 进行编解码，支持 tcp 和 http 数据传输方 式，由于其他语言不支持 gob 编解码方式，所以 golang 的 RPC 只支持 golang 开发 的服务器与客户端之间的交互\n⚫ 官方还提供了 net/rpc/jsonrpc 库实现 RPC 方法，jsonrpc 采用 JSON 进行数据编解码， 因而支持跨语言调用，目前 jsonrpc 库是基于 tcp 协议实现的，暂不支持 http 传输 方式\n⚫ golang 的 RPC 必须符合 4 个条件才可以\n​\t◼ 结构体字段首字母要大写，要跨域访问，所以大写\n​\t◼ 函数名必须首字母大写（可以序列号导出的）","title":"golang微服务"},{"content":"golang日志框架zap package main import ( \u0026#34;go.uber.org/zap\u0026#34; \u0026#34;go.uber.org/zap/zapcore\u0026#34; \u0026#34;os\u0026#34; ) var logger *zap.Logger var sugarLogger *zap.SugaredLogger func InitLogger() { writeSyncer := getLogWriter() encoder := getEncoder() core := zapcore.NewCore(encoder, writeSyncer, zapcore.DebugLevel) logger = zap.New(core) sugarLogger = logger.Sugar() } func getEncoder() zapcore.Encoder { encoderConfig := zap.NewProductionEncoderConfig() encoderConfig.EncodeTime = zapcore.ISO8601TimeEncoder encoderConfig.EncodeLevel = zapcore.CapitalLevelEncoder return zapcore.NewJSONEncoder(encoderConfig) } func getLogWriter() zapcore.WriteSyncer { file, _ := os.Create(\u0026#34;./test.log\u0026#34;) return zapcore.AddSync(file) } func main() { InitLogger() defer logger.Sync() defer sugarLogger.Sync() logger.Info(\u0026#34;日志记录成功\u0026#34;, zap.String(\u0026#34;service\u0026#34;, \u0026#34;logger service\u0026#34;)) logger.Error(\u0026#34;日志记录失败\u0026#34;, zap.String(\u0026#34;service\u0026#34;, \u0026#34;logger service\u0026#34;)) sugarLogger.Infof(\u0026#34;日志记录成功 服务：%s\u0026#34;, \u0026#34;logger service\u0026#34;) sugarLogger.Error(\u0026#34;日志记录失败\u0026#34;, \u0026#34;logger service\u0026#34;) } ","permalink":"https://www.sulvblog.cn/post/golang%E6%97%A5%E5%BF%97%E6%A1%86%E6%9E%B6zap/","summary":"golang日志框架zap package main import ( \u0026#34;go.uber.org/zap\u0026#34; \u0026#34;go.uber.org/zap/zapcore\u0026#34; \u0026#34;os\u0026#34; ) var logger *zap.Logger var sugarLogger *zap.SugaredLogger func InitLogger() { writeSyncer := getLogWriter() encoder := getEncoder() core := zapcore.NewCore(encoder, writeSyncer, zapcore.DebugLevel) logger = zap.New(core) sugarLogger = logger.Sugar() } func getEncoder() zapcore.Encoder { encoderConfig := zap.NewProductionEncoderConfig() encoderConfig.EncodeTime = zapcore.ISO8601TimeEncoder encoderConfig.EncodeLevel = zapcore.CapitalLevelEncoder return zapcore.NewJSONEncoder(encoderConfig) } func getLogWriter() zapcore.WriteSyncer { file, _ := os.Create(\u0026#34;./test.log\u0026#34;) return zapcore.AddSync(file) } func main() { InitLogger() defer logger.Sync() defer sugarLogger.","title":"golang日志框架zap"},{"content":"jdk安装 dockerfile文件\n下载地址：https://www.oracle.com/java/technologies/downloads/#java8 jdk-8u341-linux-x64.tar.gz文件\nFROM ubuntu:latest ADD jdk-8u341-linux-x64.tar.gz /usr/local/ RUN mv /usr/local/jdk1.8.0_341 /usr/local/jdk1.8 ENV JAVA_HOME=/usr/local/jdk1.8 ENV JRE_HOME=${JAVA_HOME}/jre ENV CLASSPATH=.:${JAVA_HOME}/lib:${JRE_HOME}/lib:$CLASSPATH ENV JAVA_PATH=${JAVA_HOME}/bin:${JRE_HOME}/bin ENV PATH=$PATH:${JAVA_PATH} RUN apt-get update \u0026amp;\u0026amp; apt-get install curl tree iputils-ping net-tools iproute2 vim -y CMD [\u0026#34;java\u0026#34;,\u0026#34;-version\u0026#34;] ","permalink":"https://www.sulvblog.cn/post/jdk%E5%AE%89%E8%A3%85/","summary":"jdk安装 dockerfile文件\n下载地址：https://www.oracle.com/java/technologies/downloads/#java8 jdk-8u341-linux-x64.tar.gz文件\nFROM ubuntu:latest ADD jdk-8u341-linux-x64.tar.gz /usr/local/ RUN mv /usr/local/jdk1.8.0_341 /usr/local/jdk1.8 ENV JAVA_HOME=/usr/local/jdk1.8 ENV JRE_HOME=${JAVA_HOME}/jre ENV CLASSPATH=.:${JAVA_HOME}/lib:${JRE_HOME}/lib:$CLASSPATH ENV JAVA_PATH=${JAVA_HOME}/bin:${JRE_HOME}/bin ENV PATH=$PATH:${JAVA_PATH} RUN apt-get update \u0026amp;\u0026amp; apt-get install curl tree iputils-ping net-tools iproute2 vim -y CMD [\u0026#34;java\u0026#34;,\u0026#34;-version\u0026#34;] ","title":"jdk安装教程（容器）"},{"content":"jenkins构建go项目 一、配置jenkins 1、全局工具配置 将go安装包解压后，拷贝至以上的安装目录\n自由风格构建，选go的构建环境，然后就可以在shell中执行go命令了\n","permalink":"https://www.sulvblog.cn/post/jenkins%E6%9E%84%E5%BB%BAgo%E9%A1%B9%E7%9B%AE/","summary":"jenkins构建go项目 一、配置jenkins 1、全局工具配置 将go安装包解压后，拷贝至以上的安装目录\n自由风格构建，选go的构建环境，然后就可以在shell中执行go命令了","title":"jenkins构建go项目"},{"content":"Git Git 是一个开源的分布式版本控制软件,用以有效、高速的处理从很小到非常大的项目版本管理。 Git 最初是由Linus Torvalds设计开发的，用于管理Linux内核开发。Git 是根据GNU通用公共许可证版本2的条款分发的自由/免费软件，安装参见：http://git-scm.com/\n打开git bash，初始化配置 git config --global user.name \u0026#34;wandong\u0026#34; git config --global user.email \u0026#34;993696910@qq.com\u0026#34; # 对已存在的目录进行git的初始化 git init # 添加远程仓库地址 git remote add origin http://git.cqzwymgmt.com/root/gin-project-orm.git # git add . git commit -m \u0026#34;Initial commit\u0026#34; # 推送到远程仓库 master分支 git push -u origin master 在新的环境拉取代码，进行开发 git clone http://git.cqzwymgmt.com/root/gin-project-orm.git # 创建新的分支继续开发 git branch dev # 列出所有分支 git branch # 切换分支 git checkout dev # 可以开始开发新功能了，尽量开发新的文件，避免合并的时候出现冲突进而解决冲突。 git add . git commit -m \u0026#34;change log function\u0026#34; # 推送到远程仓库 dev分支 git push -u origin dev 更新本地代码 # 拉取最新的dev分支代码，如果本地没有该分支，先创建 git branch dev # 使用pull命令更新分支代码的时候，要先处于该分支，不然会被合并 git branch dev git checkout dev git pull origin dev # 查看dev分支代码和master代码区别 将dev分支合并到master分支 git merge dev # 或者 git rebase dev 删除本地和远程仓库的分支 # 删除分支前先切换其他分支 git branch -d dev git push origin --delete dev 将你的仓库和你的gitee合并了，用填充的方法，即： git pull --rebase origin master ","permalink":"https://www.sulvblog.cn/post/git/","summary":"Git Git 是一个开源的分布式版本控制软件,用以有效、高速的处理从很小到非常大的项目版本管理。 Git 最初是由Linus Torvalds设计开发的，用于管理Linux内核开发。Git 是根据GNU通用公共许可证版本2的条款分发的自由/免费软件，安装参见：http://git-scm.com/\n打开git bash，初始化配置 git config --global user.name \u0026#34;wandong\u0026#34; git config --global user.email \u0026#34;993696910@qq.com\u0026#34; # 对已存在的目录进行git的初始化 git init # 添加远程仓库地址 git remote add origin http://git.cqzwymgmt.com/root/gin-project-orm.git # git add . git commit -m \u0026#34;Initial commit\u0026#34; # 推送到远程仓库 master分支 git push -u origin master 在新的环境拉取代码，进行开发 git clone http://git.cqzwymgmt.com/root/gin-project-orm.git # 创建新的分支继续开发 git branch dev # 列出所有分支 git branch # 切换分支 git checkout dev # 可以开始开发新功能了，尽量开发新的文件，避免合并的时候出现冲突进而解决冲突。 git add . git commit -m \u0026#34;change log function\u0026#34; # 推送到远程仓库 dev分支 git push -u origin dev 更新本地代码 # 拉取最新的dev分支代码，如果本地没有该分支，先创建 git branch dev # 使用pull命令更新分支代码的时候，要先处于该分支，不然会被合并 git branch dev git checkout dev git pull origin dev # 查看dev分支代码和master代码区别 将dev分支合并到master分支 git merge dev # 或者 git rebase dev 删除本地和远程仓库的分支 # 删除分支前先切换其他分支 git branch -d dev git push origin --delete dev 将你的仓库和你的gitee合并了，用填充的方法，即： git pull --rebase origin master ","title":"git的使用方法"},{"content":"ElasticSearch快速入门实战 主讲老师：Fox\nES版本： v7.17.3\nES环境搭建视频：https://pan.baidu.com/s/1PsTNbpDy\u0026ndash;M-pvFWb3aehQ?pwd=nwxl\n​ 文档：1.ElasticSearch快速入门实战.note 链接：http://note.youdao.com/noteshare?id=d5d5718ae542f274ba0fda4284a53231\u0026amp;sub=68E590656C7A48858C7F6997D4A1511A\n全文检索 数据分类：\n结构化数据： 固定格式，有限长度 比如mysql存的数据 非结构化数据：不定长，无固定格式 比如邮件，word文档，日志 半结构化数据： 前两者结合 比如xml，html 搜索分类：\n结构化数据搜索： 使用关系型数据库\n非结构化数据搜索\n顺序扫描 全文检索 设想一个关于搜索的场景，假设我们要搜索一首诗句内容中带“前”字的古诗\nname content author 静夜思 床前明月光,疑是地上霜。举头望明月，低头思故乡。 李白 望庐山瀑布 日照香炉生紫烟，遥看瀑布挂前川。飞流直下三千尺,疑是银河落九天。 李白 \u0026hellip; \u0026hellip; \u0026hellip; 思考：用传统关系型数据库和ES 实现会有什么差别？\n如果用像 MySQL 这样的 RDBMS 来存储古诗的话，我们应该会去使用这样的 SQL 去查询\n​ select name from poems where content like \u0026ldquo;%前%\u0026rdquo;\n这种我们称为顺序扫描法，需要遍历所有的记录进行匹配。不但效率低，而且不符合我们搜索时的期望，比如我们在搜索“ABCD\u0026quot;这样的关键词时，通常还希望看到\u0026quot;A\u0026quot;,\u0026ldquo;AB\u0026rdquo;,\u0026ldquo;CD\u0026rdquo;,“ABC”的搜索结果。\n什么是全文检索 全文检索是指：\n通过一个程序扫描文本中的每一个单词，针对单词建立索引，并保存该单词在文本中的位置、以及出现的次数 用户查询时，通过之前建立好的索引来查询，将索引中单词对应的文本位置、出现的次数返回给用户，因为有了具体文本的位置，所以就可以将具体内容读取出来了 ​ 搜索原理简单概括的话可以分为这么几步：\n内容爬取，停顿词过滤比如一些无用的像\u0026quot;的\u0026quot;，“了”之类的语气词/连接词 内容分词，提取关键词 根据关键词建立倒排索引 用户输入关键词进行搜索 倒排索引 索引就类似于目录，平时我们使用的都是索引，都是通过主键定位到某条数据，那么倒排索引呢，刚好相反，数据对应到主键。\n​ 这里以一个博客文章的内容为例:\n正排索引（正向索引） 文章ID 文章标题 文章内容 1 浅析JAVA设计模式 JAVA设计模式是每一个JAVA程序员都应该掌握的进阶知识 2 JAVA多线程设计模式 JAVA多线程与设计模式结合 倒排索引（反向索引）\n假如，我们有一个站内搜索的功能，通过某个关键词来搜索相关的文章，那么这个关键词可能出现在标题中，也可能出现在文章内容中，那我们将会在创建或修改文章的时候，建立一个关键词与文章的对应关系表，这种，我们可以称之为倒排索引。\nlike %java设计模式% java 设计模式\n关键词 文章ID JAVA 1,2 设计模式 1,2 多线程 2 简单理解，正向索引是通过key找value，反向索引则是通过value找key。ES底层在检索时底层使用的就是倒排索引。\nElasticSearch简介 ElasticSearch是什么 ElasticSearch（简称ES）是一个分布式、RESTful 风格的搜索和数据分析引擎，是用Java开发并且是当前最流行的开源的企业级搜索引擎，能够达到近实时搜索，稳定，可靠，快速，安装使用方便。\n客户端支持Java、.NET（C#）、PHP、Python、Ruby等多种语言。\n官方网站: https://www.elastic.co/\n**下载地址：**https://www.elastic.co/cn/downloads/past-releases#elasticsearch\n搜索引擎排名：\n​ 参考网站：https://db-engines.com/en/ranking/search+engine\n起源——Lucene\n基于Java语言开发的搜索引擎库类\n创建于1999年，2005年成为Apache 顶级开源项目\nLucene具有高性能、易扩展的优点\nLucene的局限性︰\n只能基于Java语言开发 类库的接口学习曲线陡峭 原生并不支持水平扩展 Elasticsearch的诞生\nElasticsearch是构建在Apache Lucene之上的开源分布式搜索引擎。\n2004年 Shay Banon 基于Lucene开发了Compass\n2010年 Shay Banon重写了Compass，取名Elasticsearch\n支持分布式，可水平扩展 降低全文检索的学习曲线，可以被任何编程语言调用 ​ Elasticsearch 与 Lucene 核心库竞争的优势在于：\n完美封装了 Lucene 核心库，设计了友好的 Restful-API，开发者无需过多关注底层机制，直接开箱即用。 分片与副本机制，直接解决了集群下性能与高可用问题。 ES Server进程 3节点 raft (奇数节点)\n数据分片 -》lucene实例 分片和副本数 1个ES节点可以有多个lucene实例。也可以指定一个索引的多个分片\n​ ElasticSearch版本特性 5.x新特性\nLucene 6.x， 性能提升，默认打分机制从TF-IDF改为BM 25\n支持Ingest节点/ Painless Scripting / Completion suggested支持/原生的Java REST客户端\nType标记成deprecated， 支持了Keyword的类型\n性能优化\n内部引擎移除了避免同一文档并发更新的竞争锁，带来15% - 20%的性能提升 Instant aggregation,支持分片，上聚合的缓存 新增了Profile API 6.x新特性\nLucene 7.x\n新功能\n跨集群复制(CCR) 索引生命周期管理 SQL的支持 更友好的的升级及数据迁移\n在主要版本之间的迁移更为简化，体验升级 全新的基于操作的数据复制框架，可加快恢复数据 性能优化\n有效存储稀疏字段的新方法，降低了存储成本 在索引时进行排序，可加快排序的查询性能 7.x新特性\nLucene 8.0\n重大改进-正式废除单个索引下多Type的支持\n7.1开始，Security 功能免费使用\nECK - Elasticseach Operator on Kubernetes\n新功能\nNew Cluster coordination Feature——Complete High Level REST Client Script Score Query 性能优化\n默认的Primary Shard数从5改为1,避免Over Sharding 性能优化， 更快的Top K 8.x新特性\nRest API相比较7.x而言做了比较大的改动（比如彻底删除_type） 默认开启安全配置 存储空间优化：对倒排文件使用新的编码集，对于keyword、match_only_text、text类型字段有效，有3.5%的空间优化提升，对于新建索引和segment自动生效。 优化geo_point，geo_shape类型的索引（写入）效率：15%的提升。 技术预览版KNN API发布，（K邻近算法），跟推荐系统、自然语言排名相关。 https://www.elastic.co/guide/en/elastic-stack/current/elasticsearch-breaking-changes.html ElasticSearch vs Solr\nSolr 是第一个基于 Lucene 核心库功能完备的搜索引擎产品，诞生远早于 Elasticsearch。\n当单纯的对已有数据进行搜索时，Solr更快。当实时建立索引时, Solr会产生io阻塞，查询性能较差, Elasticsearch具有明显的优势。\n​ ​ 大型互联网公司，实际生产环境测试，将搜索引擎从Solr转到 Elasticsearch以后的平均查询速度有了50倍的提升。\n​ 总结：\nSolr 利用 Zookeeper 进行分布式管理，而Elasticsearch 自身带有分布式协调管理功能。 Solr 支持更多格式的数据，比如JSON、XML、CSV，而 Elasticsearch 仅支持json文件格式。 Solr 在传统的搜索应用中表现好于 Elasticsearch，但在处理实时搜索应用时效率明显低于 Elasticsearch。 Solr 是传统搜索应用的有力解决方案，但 Elasticsearch更适用于新兴的实时搜索应用。 Elastic Stack介绍 在Elastic Stack之前我们听说过ELK，ELK分别是Elasticsearch，Logstash，Kibana这三款软件在一起的简称，在发展的过程中又有新的成员Beats的加入，就形成了Elastic Stack。\n​ Elastic Stack生态圈\n在Elastic Stack生态圈中Elasticsearch作为数据存储和搜索，是生态圈的基石，Kibana在上层提供用户一个可视化及操作的界面，Logstash和Beat可以对数据进行收集。在上图的右侧X-Pack部分则是Elastic公司提供的商业项目。\n指标分析/日志分析：\n​ ElasticSearch应用场景 站内搜索 日志管理与分析 大数据分析 应用性能监控 机器学习 国内现在有大量的公司都在使用 Elasticsearch，包括携程、滴滴、今日头条、饿了么、360安全、小米、vivo等诸多知名公司。除了搜索之外，结合Kibana、Logstash、Beats，Elastic Stack还被广泛运用在大数据近实时分析领域，包括日志分析、指标监控、信息安全等多个领域。它可以帮助你探索海量结构化、非结构化数据，按需创建可视化报表，对监控数据设置报警阈值，甚至通过使用机器学习技术，自动识别异常状况。\n通用数据处理流程：\n​ ElasticSearch快速开始 ElasticSearch安装运行 环境准备\n运行Elasticsearch，需安装并配置JDK\n设置$JAVA_HOME 各个版本对Java的依赖 https://www.elastic.co/support/matrix#matrix_jvm\nElasticsearch 5需要Java 8以上的版本 Elasticsearch 从6.5开始支持Java 11 7.0开始，内置了Java环境 ES比较耗内存，建议虚拟机4G或以上内存，jvm1g以上的内存分配\n可以参考es的环境文件elasticsearch-env.bat\n​ ES的jdk环境生效的优先级配置ES_JAVA_HOME\u0026gt;JAVA_HOME\u0026gt;ES_HOME\n下载并解压ElasticSearch\n下载地址： https://www.elastic.co/cn/downloads/past-releases#elasticsearch\n选择版本：7.17.3\n​ ElasticSearch文件目录结构\n目录 描述 bin 脚本文件，包括启动elasticsearch，安装插件，运行统计数据等 config 配置文件目录，如elasticsearch配置、角色配置、jvm配置等。 jdk java运行环境 data 默认的数据存放目录，包含节点、分片、索引、文档的所有数据，生产环境需要修改。 lib elasticsearch依赖的Java类库 logs 默认的日志文件存储路径，生产环境需要修改。 modules 包含所有的Elasticsearch模块，如Cluster、Discovery、Indices等。 plugins 已安装插件目录 主配置文件elasticsearch.yml\ncluster.name 当前节点所属集群名称，多个节点如果要组成同一个集群，那么集群名称一定要配置成相同。默认值elasticsearch，生产环境建议根据ES集群的使用目的修改成合适的名字。\nnode.name 当前节点名称，默认值当前节点部署所在机器的主机名，所以如果一台机器上要起多个ES节点的话，需要通过配置该属性明确指定不同的节点名称。\npath.data 配置数据存储目录，比如索引数据等，默认值 $ES_HOME/data，生产环境下强烈建议部署到另外的安全目录，防止ES升级导致数据被误删除。\npath.logs 配置日志存储目录，比如运行日志和集群健康信息等，默认值 $ES_HOME/logs，生产环境下强烈建议部署到另外的安全目录，防止ES升级导致数据被误删除。\nbootstrap.memory_lock 配置ES启动时是否进行内存锁定检查，默认值true。\nES对于内存的需求比较大，一般生产环境建议配置大内存，如果内存不足，容易导致内存交换到磁盘，严重影响ES的性能。所以默认启动时进行相应大小内存的锁定，如果无法锁定则会启动失败。\n非生产环境可能机器内存本身就很小，能够供给ES使用的就更小，如果该参数配置为true的话很可能导致无法锁定内存以致ES无法成功启动，此时可以修改为false。\nnetwork.host 配置能够访问当前节点的主机，默认值为当前节点所在机器的本机回环地址127.0.0.1 和[::1]，这就导致默认情况下只能通过当前节点所在主机访问当前节点。可以配置为 0.0.0.0 ，表示所有主机均可访问。\nhttp.port 配置当前ES节点对外提供服务的http端口，默认值 9200\ndiscovery.seed_hosts 配置参与集群节点发现过程的主机列表，说白一点就是集群中所有节点所在的主机列表，可以是具体的IP地址，也可以是可解析的域名。\ncluster.initial_master_nodes 配置ES集群初始化时参与master选举的节点名称列表，必须与node.name配置的一致。ES集群首次构建完成后，应该将集群中所有节点的配置文件中的cluster.initial_master_nodes配置项移除，重启集群或者将新节点加入某个已存在的集群时切记不要设置该配置项。\n​ #ES开启远程访问 network.host: 0.0.0.0\n修改JVM配置\n修改config/jvm.options配置文件，调整jvm堆内存大小\n​ vim jvm.options -Xms4g -Xmx4g\n配置的建议\nXms和Xms设置成—样 Xmx不要超过机器内存的50% 不要超过30GB - https://www.elastic.co/cn/blog/a-heap-of-trouble 启动ElasticSearch服务 Windows\n直接运行elasticsearch.bat\nLinux（centos7）\nES不允许使用root账号启动服务，如果你当前账号是root，则需要创建一个专有账户\n​ #非root用户 bin/elasticsearch # -d 后台启动 bin/elasticsearch -d\n​ 注意：es默认不能用root用户启动，生产环境建议为elasticsearch创建用户。\n​ #为elaticsearch创建用户并赋予相应权限 adduser es passwd es chown -R es:es elasticsearch-17.3\n运行http://localhost:9200/\n​ 如果ES服务启动异常，会有提示：\n​ 启动ES服务常见错误解决方案 [1]: max file descriptors [4096] for elasticsearch process is too low, increase to at least [65536]\nES因为需要大量的创建索引文件，需要大量的打开系统的文件，所以我们需要解除linux系统当中打开文件最大数目的限制，不然ES启动就会抛错\n​ #切换到root用户 vim /etc/security/limits.conf 末尾添加如下配置： *\tsoft nofile 65536 * hard nofile 65536 * soft nproc 4096 *\thard nproc 4096\n[2]: max number of threads [1024] for user [es] is too low, increase to at least [4096]\n无法创建本地线程问题,用户最大可创建线程数太小\n​ vim /etc/security/limits.d/20-nproc.conf 改为如下配置： * soft nproc 4096\n[3]: max virtual memory areas vm.max_map_count [65530] is too low, increase to at least [262144]\n最大虚拟内存太小,调大系统的虚拟内存\n​ vim /etc/sysctl.conf 追加以下内容： vm.max_map_count=262144 保存退出之后执行如下命令： sysctl -p\n[4]: the default discovery settings are unsuitable for production use; at least one of [discovery.seed_hosts, discovery.seed_providers, cluster.initial_master_nodes] must be configured\n缺少默认配置，至少需要配置discovery.seed_hosts/discovery.seed_providers/cluster.initial_master_nodes中的一个参数.\ndiscovery.seed_hosts: 集群主机列表 discovery.seed_providers: 基于配置文件配置集群主机列表 cluster.initial_master_nodes: 启动时初始化的参与选主的node，生产环境必填 ​ vim config/elasticsearch.yml #添加配置 discovery.seed_hosts: [\u0026ldquo;127.0.0.1\u0026rdquo;] cluster.initial_master_nodes: [\u0026ldquo;node-1\u0026rdquo;] #或者 单节点（集群单节点） discovery.type: single-node\n客户端Kibana安装 Kibana是一个开源分析和可视化平台，旨在与Elasticsearch协同工作。\n1）下载并解压缩Kibana\n下载地址：https://www.elastic.co/cn/downloads/past-releases#kibana\n选择版本：7.17.3\n​ 2）修改Kibana.yml\n​ vim config/kibana.yml server.port: 5601 server.host: \u0026ldquo;localhost\u0026rdquo; #服务器ip elasticsearch.hosts: [\u0026ldquo;http://localhost:9200\u0026rdquo;] #elasticsearch的访问地址 i18n.locale: \u0026ldquo;zh-CN\u0026rdquo; #Kibana汉化\n3）运行Kibana\n注意：kibana也需要非root用户启动\n​ bin/kibana #后台启动 nohup bin/kibana \u0026amp;\n访问Kibana: http://localhost:5601/\n​ cat API\n​ /_cat/allocation #查看单节点的shard分配整体情况 /_cat/shards #查看各shard的详细情况 /_cat/shards/{index} #查看指定分片的详细情况 /_cat/master #查看master节点信息 /_cat/nodes #查看所有节点信息 /_cat/indices #查看集群中所有index的详细信息 /_cat/indices/{index} #查看集群中指定index的详细信息 /_cat/segments #查看各index的segment详细信息,包括segment名, 所属shard, 内存(磁盘)占用大小, 是否刷盘 /_cat/segments/{index}#查看指定index的segment详细信息 /_cat/count #查看当前集群的doc数量 /_cat/count/{index} #查看指定索引的doc数量 /_cat/recovery #查看集群内每个shard的recovery过程.调整replica。 /_cat/recovery/{index}#查看指定索引shard的recovery过程 /_cat/health #查看集群当前状态：红、黄、绿 /_cat/pending_tasks #查看当前集群的pending task /_cat/aliases #查看集群中所有alias信息,路由配置等 /_cat/aliases/{alias} #查看指定索引的alias信息 /_cat/thread_pool #查看集群各节点内部不同类型的threadpool的统计信息, /_cat/plugins #查看集群各个节点上的plugin信息 /_cat/fielddata #查看当前集群各个节点的fielddata内存使用情况 /_cat/fielddata/{fields} #查看指定field的内存使用情况,里面传field属性对应的值 /_cat/nodeattrs #查看单节点的自定义属性 /_cat/repositories #输出集群中注册快照存储库 /_cat/templates #输出当前正在存在的模板信息\nElasticsearch安装分词插件 Elasticsearch提供插件机制对系统进行扩展\n以安装analysis-icu这个分词插件为例\n在线安装\n​ #查看已安装插件 bin/elasticsearch-plugin list #安装插件 bin/elasticsearch-plugin install analysis-icu #删除插件 bin/elasticsearch-plugin remove analysis-icu\n注意：安装和删除完插件后，需要重启ES服务才能生效。\n测试分词效果\n​ POST _analyze { \u0026ldquo;analyzer\u0026rdquo;:\u0026ldquo;icu_analyzer\u0026rdquo;, \u0026ldquo;text\u0026rdquo;:\u0026ldquo;中华人民共和国\u0026rdquo; }\n​ 离线安装\n本地下载相应的插件，解压，然后手动上传到elasticsearch的plugins目录，然后重启ES实例就可以了。\n比如ik中文分词插件：https://github.com/medcl/elasticsearch-analysis-ik\n测试分词效果\n​ #ES的默认分词设置是standard，会单字拆分 POST _analyze { \u0026ldquo;analyzer\u0026rdquo;:\u0026ldquo;standard\u0026rdquo;, \u0026ldquo;text\u0026rdquo;:\u0026ldquo;中华人民共和国\u0026rdquo; } #ik_smart:会做最粗粒度的拆 POST _analyze { \u0026ldquo;analyzer\u0026rdquo;: \u0026ldquo;ik_smart\u0026rdquo;, \u0026ldquo;text\u0026rdquo;: \u0026ldquo;中华人民共和国\u0026rdquo; } #ik_max_word:会将文本做最细粒度的拆分 POST _analyze { \u0026ldquo;analyzer\u0026rdquo;:\u0026ldquo;ik_max_word\u0026rdquo;, \u0026ldquo;text\u0026rdquo;:\u0026ldquo;中华人民共和国\u0026rdquo; }\n创建索引时可以指定IK分词器作为默认分词器\n​ PUT /es_db { \u0026ldquo;settings\u0026rdquo; : { \u0026ldquo;index\u0026rdquo; : { \u0026ldquo;analysis.analyzer.default.type\u0026rdquo;: \u0026ldquo;ik_max_word\u0026rdquo; } } }\n​ ElasticSearch基本概念 关系型数据库 VS ElasticSearch 在7.0之前，一个 Index可以设置多个Types\n目前Type已经被Deprecated，7.0开始，一个索引只能创建一个Type - “_doc”\n传统关系型数据库和Elasticsearch的区别:\nElasticsearch- Schemaless /相关性/高性能全文检索 RDMS —事务性/ Join ​ 索引（Index） 一个索引就是一个拥有几分相似特征的文档的集合。比如说，可以有一个客户数据的索引，另一个产品目录的索引，还有一个订单数据的索引。\n一个索引由一个名字来标识（必须全部是小写字母的），并且当我们要对对应于这个索引中的文档进行索引、搜索、更新和删除的时候，都要使用到这个名字。\n​ 文档（Document） Elasticsearch是面向文档的，文档是所有可搜索数据的最小单位。\n日志文件中的日志项 一本电影的具体信息/一张唱片的详细信息 MP3播放器里的一首歌/一篇PDF文档中的具体内容 文档会被序列化成JSON格式，保存在Elasticsearch中\nJSON对象由字段组成 每个字段都有对应的字段类型(字符串/数值/布尔/日期/二进制/范围类型) 每个文档都有一个Unique ID\n可以自己指定ID或者通过Elasticsearch自动生成 一篇文档包含了一系列字段，类似数据库表中的一条记录\nJSON文档，格式灵活，不需要预先定义格式\n字段的类型可以指定或者通过Elasticsearch自动推算 支持数组/支持嵌套 文档元数据\n​ 元数据，用于标注文档的相关信息：\n_index：文档所属的索引名 _type：文档所属的类型名 _id：文档唯—ld _source: 文档的原始Json数据 _version: 文档的版本号，修改删除操作_version都会自增1 _seq_no: 和_version一样，一旦数据发生更改，数据也一直是累计的。Shard级别严格递增，保证后写入的Doc的_seq_no大于先写入的Doc的_seq_no。 _primary_term: _primary_term主要是用来恢复数据时处理当多个文档的_seq_no一样时的冲突，避免Primary Shard上的写入被覆盖。每当Primary Shard发生重新分配时，比如重启，Primary选举等，_primary_term会递增1。 ElasticSearch索引操作 https://www.elastic.co/guide/en/elasticsearch/reference/7.17/index.html\n创建索引\n索引命名必须小写，不能以下划线开头\n格式: PUT /索引名称\n​ #创建索引 PUT /es_db #创建索引时可以设置分片数和副本数 PUT /es_db { \u0026ldquo;settings\u0026rdquo; : { \u0026ldquo;number_of_shards\u0026rdquo; : 3, \u0026ldquo;number_of_replicas\u0026rdquo; : 2 } } #修改索引配置 PUT /es_db/_settings { \u0026ldquo;index\u0026rdquo; : { \u0026ldquo;number_of_replicas\u0026rdquo; : 1 } }\n​ 查询索引\n格式: GET /索引名称\n​ #查询索引 GET /es_db #es_db是否存在 HEAD /es_db\n​ ​\n删除索引\n格式: DELETE /索引名称\n​ DELETE /es_db\nElasticSearch文档操作 示例数据\n​ PUT /es_db { \u0026ldquo;settings\u0026rdquo; : { \u0026ldquo;index\u0026rdquo; : { \u0026ldquo;analysis.analyzer.default.type\u0026rdquo;: \u0026ldquo;ik_max_word\u0026rdquo; } } } PUT /es_db/_doc/1 { \u0026ldquo;name\u0026rdquo;: \u0026ldquo;张三\u0026rdquo;, \u0026ldquo;sex\u0026rdquo;: 1, \u0026ldquo;age\u0026rdquo;: 25, \u0026ldquo;address\u0026rdquo;: \u0026ldquo;广州天河公园\u0026rdquo;, \u0026ldquo;remark\u0026rdquo;: \u0026ldquo;java developer\u0026rdquo; } PUT /es_db/_doc/2 { \u0026ldquo;name\u0026rdquo;: \u0026ldquo;李四\u0026rdquo;, \u0026ldquo;sex\u0026rdquo;: 1, \u0026ldquo;age\u0026rdquo;: 28, \u0026ldquo;address\u0026rdquo;: \u0026ldquo;广州荔湾大厦\u0026rdquo;, \u0026ldquo;remark\u0026rdquo;: \u0026ldquo;java assistant\u0026rdquo; } PUT /es_db/_doc/3 { \u0026ldquo;name\u0026rdquo;: \u0026ldquo;王五\u0026rdquo;, \u0026ldquo;sex\u0026rdquo;: 0, \u0026ldquo;age\u0026rdquo;: 26, \u0026ldquo;address\u0026rdquo;: \u0026ldquo;广州白云山公园\u0026rdquo;, \u0026ldquo;remark\u0026rdquo;: \u0026ldquo;php developer\u0026rdquo; } PUT /es_db/_doc/4 { \u0026ldquo;name\u0026rdquo;: \u0026ldquo;赵六\u0026rdquo;, \u0026ldquo;sex\u0026rdquo;: 0, \u0026ldquo;age\u0026rdquo;: 22, \u0026ldquo;address\u0026rdquo;: \u0026ldquo;长沙橘子洲\u0026rdquo;, \u0026ldquo;remark\u0026rdquo;: \u0026ldquo;python assistant\u0026rdquo; } PUT /es_db/_doc/5 { \u0026ldquo;name\u0026rdquo;: \u0026ldquo;张龙\u0026rdquo;, \u0026ldquo;sex\u0026rdquo;: 0, \u0026ldquo;age\u0026rdquo;: 19, \u0026ldquo;address\u0026rdquo;: \u0026ldquo;长沙麓谷企业广场\u0026rdquo;, \u0026ldquo;remark\u0026rdquo;: \u0026ldquo;java architect assistant\u0026rdquo; }\tPUT /es_db/_doc/6 { \u0026ldquo;name\u0026rdquo;: \u0026ldquo;赵虎\u0026rdquo;, \u0026ldquo;sex\u0026rdquo;: 1, \u0026ldquo;age\u0026rdquo;: 32, \u0026ldquo;address\u0026rdquo;: \u0026ldquo;长沙麓谷兴工国际产业园\u0026rdquo;, \u0026ldquo;remark\u0026rdquo;: \u0026ldquo;java architect\u0026rdquo; }\n添加（索引）文档\n格式: [PUT | POST] /索引名称/[_doc | _create ]/id ​ # 创建文档,指定id # 如果id不存在，创建新的文档，否则先删除现有文档，再创建新的文档，版本会增加 PUT /es_db/_doc/1 { \u0026ldquo;name\u0026rdquo;: \u0026ldquo;张三\u0026rdquo;, \u0026ldquo;sex\u0026rdquo;: 1, \u0026ldquo;age\u0026rdquo;: 25, \u0026ldquo;address\u0026rdquo;: \u0026ldquo;广州天河公园\u0026rdquo;, \u0026ldquo;remark\u0026rdquo;: \u0026ldquo;java developer\u0026rdquo; }\t#创建文档，ES生成id POST /es_db/_doc { \u0026ldquo;name\u0026rdquo;: \u0026ldquo;张三\u0026rdquo;, \u0026ldquo;sex\u0026rdquo;: 1, \u0026ldquo;age\u0026rdquo;: 25, \u0026ldquo;address\u0026rdquo;: \u0026ldquo;广州天河公园\u0026rdquo;, \u0026ldquo;remark\u0026rdquo;: \u0026ldquo;java developer\u0026rdquo; }\n​ 注意:POST和PUT都能起到创建/更新的作用，PUT需要对一个具体的资源进行操作也就是要确定id才能进行更新/创建，而POST是可以针对整个资源集合进行操作的，如果不写id就由ES生成一个唯一id进行创建新文档，如果填了id那就针对这个id的文档进行创建/更新\n​ Create -如果ID已经存在，会失败\n​ 修改文档\n全量更新，整个json都会替换，格式: [PUT | POST] /索引名称/_doc/id 如果文档存在，现有文档会被删除，新的文档会被索引\n​ # 全量更新，替换整个json PUT /es_db/_doc/1/ { \u0026ldquo;name\u0026rdquo;: \u0026ldquo;张三\u0026rdquo;, \u0026ldquo;sex\u0026rdquo;: 1, \u0026ldquo;age\u0026rdquo;: 25 } #查询文档 GET /es_db/_doc/1\n​ 使用_update部分更新，格式: POST /索引名称/_update/id update不会删除原来的文档，而是实现真正的数据更新\n​ # 部分更新：在原有文档上更新 # Update -文档必须已经存在，更新只会对相应字段做增量修改 POST /es_db/_update/1 { \u0026ldquo;doc\u0026rdquo;: { \u0026ldquo;age\u0026rdquo;: 28 } } #查询文档 GET /es_db/_doc/1\n​ 使用 _update_by_query 更新文档 ​ POST /es_db/_update_by_query { \u0026ldquo;query\u0026rdquo;: { \u0026ldquo;match\u0026rdquo;: { \u0026ldquo;_id\u0026rdquo;: 1 } }, \u0026ldquo;script\u0026rdquo;: { \u0026ldquo;source\u0026rdquo;: \u0026ldquo;ctx._source.age = 30\u0026rdquo; } }\n​ 并发场景下修改文档\n_seq_no和_primary_term是对_version的优化，7.X版本的ES默认使用这种方式控制版本，所以当在高并发环境下使用乐观锁机制修改文档时，要带上当前文档的_seq_no和_primary_term进行更新：\n​ POST /es_db/_doc/2?if_seq_no=21\u0026amp;if_primary_term=6 { \u0026ldquo;name\u0026rdquo;: \u0026ldquo;李四xxx\u0026rdquo; }\n如果版本号不对，会抛出版本冲突异常，如下图：\n​ 查询文档\n根据id查询文档，格式: GET /索引名称/_doc/id ​ GET /es_db/_doc/1\n条件查询 _search，格式： /索引名称/_doc/_search ​ # 查询前10条文档 GET /es_db/_doc/_search\nES Search API提供了两种条件查询搜索方式：\nREST风格的请求URI，直接将参数带过去 封装到request body中，这种方式可以定义更加易读的JSON格式 ​ #通过URI搜索，使用“q”指定查询字符串，“query string syntax” KV键值对 #条件查询, 如要查询age等于28岁的 _search?q=:** GET /es_db/_doc/_search?q=age:28 #范围查询, 如要查询age在25至26岁之间的 _search?q=[ TO **] 注意: TO 必须为大写 GET /es_db/_doc/_search?q=age[25 TO 26] #查询年龄小于等于28岁的 :\u0026lt;= GET /es_db/_doc/_search?q=age:\u0026lt;=28 #查询年龄大于28前的 :\u0026gt; GET /es_db/_doc/_search?q=age:\u0026gt;28 #分页查询 from=\u0026amp;size=* GET /es_db/_doc/_search?q=age[25 TO 26]\u0026amp;from=0\u0026amp;size=1 #对查询结果只输出某些字段 _source=字段,字段 GET /es_db/_doc/_search?_source=name,age #对查询结果排序 sort=字段:desc/asc GET /es_db/_doc/_search?sort=age:desc\n通过请求体的搜索方式会在后面课程详细讲解（DSL）\n​ GET /es_db/_search { \u0026ldquo;query\u0026rdquo;: { \u0026ldquo;match\u0026rdquo;: { \u0026ldquo;address\u0026rdquo;: \u0026ldquo;广州白云\u0026rdquo; } } }\n删除文档\n格式: DELETE /索引名称/_doc/id\n​ DELETE /es_db/_doc/1\nElasticSearch文档批量操作\n批量操作可以减少网络连接所产生的开销，提升性能\n支持在一次API调用中，对不同的索引进行操作 可以在URI中指定Index，也可以在请求的Payload中进行 操作中单条操作失败，并不会影响其他操作 返回结果包括了每一条操作执行的结果 批量写入\n批量对文档进行写操作是通过_bulk的API来实现的\n请求方式：POST\n请求地址：_bulk\n请求参数：通过_bulk操作文档，一般至少有两行参数(或偶数行参数)\n第一行参数为指定操作的类型及操作的对象(index,type和id) 第二行参数才是操作的数据 参数类似于：\n​ {\u0026ldquo;actionName\u0026rdquo;:{\u0026quot;_index\u0026quot;:\u0026ldquo;indexName\u0026rdquo;, \u0026ldquo;_type\u0026rdquo;:\u0026ldquo;typeName\u0026rdquo;,\u0026quot;_id\u0026quot;:\u0026ldquo;id\u0026rdquo;}} {\u0026ldquo;field1\u0026rdquo;:\u0026ldquo;value1\u0026rdquo;, \u0026ldquo;field2\u0026rdquo;:\u0026ldquo;value2\u0026rdquo;}\nactionName：表示操作类型，主要有create,index,delete和update 批量创建文档create\n​ POST _bulk {\u0026ldquo;create\u0026rdquo;:{\u0026quot;_index\u0026quot;:\u0026ldquo;article\u0026rdquo;, \u0026ldquo;_type\u0026rdquo;:\u0026quot;_doc\u0026quot;, \u0026ldquo;_id\u0026rdquo;:3}} {\u0026ldquo;id\u0026rdquo;:3,\u0026ldquo;title\u0026rdquo;:\u0026ldquo;fox老师\u0026rdquo;,\u0026ldquo;content\u0026rdquo;:\u0026ldquo;fox老师666\u0026rdquo;,\u0026ldquo;tags\u0026rdquo;:[\u0026ldquo;java\u0026rdquo;, \u0026ldquo;面向对象\u0026rdquo;],\u0026ldquo;create_time\u0026rdquo;:1554015482530} {\u0026ldquo;create\u0026rdquo;:{\u0026quot;_index\u0026quot;:\u0026ldquo;article\u0026rdquo;, \u0026ldquo;_type\u0026rdquo;:\u0026quot;_doc\u0026quot;, \u0026ldquo;_id\u0026rdquo;:4}} {\u0026ldquo;id\u0026rdquo;:4,\u0026ldquo;title\u0026rdquo;:\u0026ldquo;mark老师\u0026rdquo;,\u0026ldquo;content\u0026rdquo;:\u0026ldquo;mark老师NB\u0026rdquo;,\u0026ldquo;tags\u0026rdquo;:[\u0026ldquo;java\u0026rdquo;, \u0026ldquo;面向对象\u0026rdquo;],\u0026ldquo;create_time\u0026rdquo;:1554015482530}\n普通创建或全量替换index\n​ POST _bulk {\u0026ldquo;index\u0026rdquo;:{\u0026quot;_index\u0026quot;:\u0026ldquo;article\u0026rdquo;, \u0026ldquo;_type\u0026rdquo;:\u0026quot;_doc\u0026quot;, \u0026ldquo;_id\u0026rdquo;:3}} {\u0026ldquo;id\u0026rdquo;:3,\u0026ldquo;title\u0026rdquo;:\u0026ldquo;图灵徐庶老师\u0026rdquo;,\u0026ldquo;content\u0026rdquo;:\u0026ldquo;图灵学院徐庶老师666\u0026rdquo;,\u0026ldquo;tags\u0026rdquo;:[\u0026ldquo;java\u0026rdquo;, \u0026ldquo;面向对象\u0026rdquo;],\u0026ldquo;create_time\u0026rdquo;:1554015482530} {\u0026ldquo;index\u0026rdquo;:{\u0026quot;_index\u0026quot;:\u0026ldquo;article\u0026rdquo;, \u0026ldquo;_type\u0026rdquo;:\u0026quot;_doc\u0026quot;, \u0026ldquo;_id\u0026rdquo;:4}} {\u0026ldquo;id\u0026rdquo;:4,\u0026ldquo;title\u0026rdquo;:\u0026ldquo;图灵诸葛老师\u0026rdquo;,\u0026ldquo;content\u0026rdquo;:\u0026ldquo;图灵学院诸葛老师NB\u0026rdquo;,\u0026ldquo;tags\u0026rdquo;:[\u0026ldquo;java\u0026rdquo;, \u0026ldquo;面向对象\u0026rdquo;],\u0026ldquo;create_time\u0026rdquo;:1554015482530}\n如果原文档不存在，则是创建 如果原文档存在，则是替换(全量修改原文档) 批量删除delete\n​ POST _bulk {\u0026ldquo;delete\u0026rdquo;:{\u0026quot;_index\u0026quot;:\u0026ldquo;article\u0026rdquo;, \u0026ldquo;_type\u0026rdquo;:\u0026quot;_doc\u0026quot;, \u0026ldquo;_id\u0026rdquo;:3}} {\u0026ldquo;delete\u0026rdquo;:{\u0026quot;_index\u0026quot;:\u0026ldquo;article\u0026rdquo;, \u0026ldquo;_type\u0026rdquo;:\u0026quot;_doc\u0026quot;, \u0026ldquo;_id\u0026rdquo;:4}}\n批量修改update\n​ POST _bulk {\u0026ldquo;update\u0026rdquo;:{\u0026quot;_index\u0026quot;:\u0026ldquo;article\u0026rdquo;, \u0026ldquo;_type\u0026rdquo;:\u0026quot;_doc\u0026quot;, \u0026ldquo;_id\u0026rdquo;:3}} {\u0026ldquo;doc\u0026rdquo;:{\u0026ldquo;title\u0026rdquo;:\u0026ldquo;ES大法必修内功\u0026rdquo;}} {\u0026ldquo;update\u0026rdquo;:{\u0026quot;_index\u0026quot;:\u0026ldquo;article\u0026rdquo;, \u0026ldquo;_type\u0026rdquo;:\u0026quot;_doc\u0026quot;, \u0026ldquo;_id\u0026rdquo;:4}} {\u0026ldquo;doc\u0026rdquo;:{\u0026ldquo;create_time\u0026rdquo;:1554018421008}}\n组合应用\n​ POST _bulk {\u0026ldquo;create\u0026rdquo;:{\u0026quot;_index\u0026quot;:\u0026ldquo;article\u0026rdquo;, \u0026ldquo;_type\u0026rdquo;:\u0026quot;_doc\u0026quot;, \u0026ldquo;_id\u0026rdquo;:3}} {\u0026ldquo;id\u0026rdquo;:3,\u0026ldquo;title\u0026rdquo;:\u0026ldquo;fox老师\u0026rdquo;,\u0026ldquo;content\u0026rdquo;:\u0026ldquo;fox老师666\u0026rdquo;,\u0026ldquo;tags\u0026rdquo;:[\u0026ldquo;java\u0026rdquo;, \u0026ldquo;面向对象\u0026rdquo;],\u0026ldquo;create_time\u0026rdquo;:1554015482530} {\u0026ldquo;delete\u0026rdquo;:{\u0026quot;_index\u0026quot;:\u0026ldquo;article\u0026rdquo;, \u0026ldquo;_type\u0026rdquo;:\u0026quot;_doc\u0026quot;, \u0026ldquo;_id\u0026rdquo;:3}} {\u0026ldquo;update\u0026rdquo;:{\u0026quot;_index\u0026quot;:\u0026ldquo;article\u0026rdquo;, \u0026ldquo;_type\u0026rdquo;:\u0026quot;_doc\u0026quot;, \u0026ldquo;_id\u0026rdquo;:4}} {\u0026ldquo;doc\u0026rdquo;:{\u0026ldquo;create_time\u0026rdquo;:1554018421008}}\n批量读取\nes的批量查询可以使用mget和msearch两种。其中mget是需要我们知道它的id，可以指定不同的index，也可以指定返回值source。msearch可以通过字段查询来进行一个批量的查找。\n_mget\n​ #可以通过ID批量获取不同index和type的数据 GET _mget { \u0026ldquo;docs\u0026rdquo;: [ { \u0026ldquo;_index\u0026rdquo;: \u0026ldquo;es_db\u0026rdquo;, \u0026ldquo;_id\u0026rdquo;: 1 }, { \u0026ldquo;_index\u0026rdquo;: \u0026ldquo;article\u0026rdquo;, \u0026ldquo;_id\u0026rdquo;: 4 } ] } #可以通过ID批量获取es_db的数据 GET /es_db/_mget { \u0026ldquo;docs\u0026rdquo;: [ { \u0026ldquo;_id\u0026rdquo;: 1 }, { \u0026ldquo;_id\u0026rdquo;: 4 } ] } #简化后 GET /es_db/_mget { \u0026ldquo;ids\u0026rdquo;:[\u0026ldquo;1\u0026rdquo;,\u0026ldquo;2\u0026rdquo;] }\n​ _msearch\n在_msearch中，请求格式和bulk类似。查询一条数据需要两个对象，第一个设置index和type，第二个设置查询语句。查询语句和search相同。如果只是查询一个index，我们可以在url中带上index，这样，如果查该index可以直接用空对象表示。\n​ GET /es_db/_msearch {} {\u0026ldquo;query\u0026rdquo; : {\u0026ldquo;match_all\u0026rdquo; : {}}, \u0026ldquo;from\u0026rdquo; : 0, \u0026ldquo;size\u0026rdquo; : 2} {\u0026ldquo;index\u0026rdquo; : \u0026ldquo;article\u0026rdquo;} {\u0026ldquo;query\u0026rdquo; : {\u0026ldquo;match_all\u0026rdquo; : {}}}\n​ Logstash与FileBeat详解以及ELK整合 ​ 文档：6. Logstash与FileBeat详解以及ELK整合\u0026hellip; 链接：http://note.youdao.com/noteshare?id=cd88d72a1c76d18efcf7fe767e8c2d20\u0026amp;sub=D7819084A43243FFA52E8A8741795414\n注意：本节课的命令和配置文件不要再pdf文件中复制，为存在格式问题，保存到有道云笔记后再操作\n​ 背景\n​ ELK架构\n​ 经典的ELK\n​ 整合消息队列+Nginx架构\n​ 什么是Logstash\n​ Logstash核心概念\n​ Logstash数据传输原理\n​ Logstash配置文件结构\n​ Logstash Queue\n​ Logstash导入数据到ES\n​ 同步数据库数据到Elasticsearch\n​ 什么是Beats\n​ FileBeat简介\n​ FileBeat的工作原理\n​ logstash vs FileBeat\n​ Filebeat安装\n​ ELK整合实战\n​ 案例：采集tomcat服务器日志\n​ 使用FileBeats将日志发送到Logstash\n​ 配置Logstash接收FileBeat收集的数据并打印\n​ Logstash输出数据到Elasticsearch\n​ 利用Logstash过滤器解析日志\n​ 输出到Elasticsearch指定索引\n背景 日志管理的挑战：\n关注点很多，任何一个点都有可能引起问题 日志分散在很多机器，出了问题时，才发现日志被删了 很多运维人员是消防员，哪里有问题去哪里 ​ 集中化日志管理思路：\n日志收集 ——》格式化分析 ——》检索和可视化 ——》 风险告警\nELK架构\nELK架构分为两种，一种是经典的ELK，另外一种是加上消息队列（Redis或Kafka或RabbitMQ）和Nginx结构。\n经典的ELK\n经典的ELK主要是由Filebeat + Logstash + Elasticsearch + Kibana组成，如下图：（早期的ELK只有Logstash + Elasticsearch + Kibana）\n​ 此架构主要适用于数据量小的开发环境，存在数据丢失的危险。\n整合消息队列+Nginx架构 这种架构，主要加上了Redis或Kafka或RabbitMQ做消息队列，保证了消息的不丢失。\n​ 此种架构，主要用在生产环境，可以处理大数据量，并且不会丢失数据。\n什么是Logstash\nLogstash 是免费且开放的服务器端数据处理管道，能够从多个来源采集数据，转换数据，然后将数据发送到您最喜欢的存储库中。\nhttps://www.elastic.co/cn/logstash/\n应用：ETL工具 / 数据采集处理引擎\n​ Logstash核心概念 Pipeline\n包含了input—filter-output三个阶段的处理流程 插件生命周期管理 队列管理 Logstash Event\n数据在内部流转时的具体表现形式。数据在input 阶段被转换为Event，在 output被转化成目标格式数据 Event 其实是一个Java Object，在配置文件中，对Event 的属性进行增删改查 Codec (Code / Decode)\n将原始数据decode成Event;将Event encode成目标数据\n​ Logstash数据传输原理 数据采集与输入：Logstash支持各种输入选择，能够以连续的流式传输方式，轻松地从日志、指标、Web应用以及数据存储中采集数据。 实时解析和数据转换：通过Logstash过滤器解析各个事件，识别已命名的字段来构建结构，并将它们转换成通用格式，最终将数据从源端传输到存储库中。 存储与数据导出：Logstash提供多种输出选择，可以将数据发送到指定的地方。 Logstash通过管道完成数据的采集与处理，管道配置中包含input、output和filter（可选）插件，input和output用来配置输入和输出数据源、filter用来对数据进行过滤或预处理。\n​ Logstash配置文件结构 参考：https://www.elastic.co/guide/en/logstash/7.17/configuration.html\nLogstash的管道配置文件对每种类型的插件都提供了一个单独的配置部分，用于处理管道事件。\n​ input { stdin { } } filter { grok { match =\u0026gt; { \u0026ldquo;message\u0026rdquo; =\u0026gt; \u0026ldquo;%{COMBINEDAPACHELOG}\u0026rdquo; } } date { match =\u0026gt; [ \u0026ldquo;timestamp\u0026rdquo; , \u0026ldquo;dd/MMM/yyyy:HH:mm:ss Z\u0026rdquo; ] } } output { elasticsearch { hosts =\u0026gt; [\u0026ldquo;localhost:9200\u0026rdquo;]} stdout { codec =\u0026gt; rubydebug } }\n每个配置部分可以包含一个或多个插件。例如，指定多个filter插件，Logstash会按照它们在配置文件中出现的顺序进行处理。\n​ #运行 bin/logstash -f logstash-demo.conf\nInput Plugins\nhttps://www.elastic.co/guide/en/logstash/7.17/input-plugins.html\n一个 Pipeline可以有多个input插件\nStdin / File\nBeats / Log4J /Elasticsearch / JDBC / Kafka /Rabbitmq /Redis\nJMX/ HTTP / Websocket / UDP / TCP\nGoogle Cloud Storage / S3\nGithub / Twitter\nOutput Plugins\nhttps://www.elastic.co/guide/en/logstash/7.17/output-plugins.html\n将Event发送到特定的目的地，是 Pipeline 的最后一个阶段。\n常见 Output Plugins：\nElasticsearch Email / Pageduty Influxdb / Kafka / Mongodb / Opentsdb / Zabbix Http / TCP / Websocket Filter Plugins\nhttps://www.elastic.co/guide/en/logstash/7.17/filter-plugins.html\n处理Event\n内置的Filter Plugins:\nMutate 一操作Event的字段 Metrics — Aggregate metrics Ruby 一执行Ruby 代码 Codec Plugins\nhttps://www.elastic.co/guide/en/logstash/7.17/codec-plugins.html\n将原始数据decode成Event;将Event encode成目标数据\n内置的Codec Plugins:\nLine / Multiline JSON / Avro / Cef (ArcSight Common Event Format) Dots / Rubydebug Logstash Queue\nIn Memory Queue 进程Crash，机器宕机，都会引起数据的丢失\nPersistent Queue 机器宕机，数据也不会丢失; 数据保证会被消费; 可以替代 Kafka等消息队列缓冲区的作用\n​ queue.type: persisted (默认是memory) queue.max_bytes: 4gb\n​ Logstash安装 logstash官方文档: https://www.elastic.co/guide/en/logstash/7.17/installing-logstash.html\n1）下载并解压logstash\n下载地址： https://www.elastic.co/cn/downloads/past-releases#logstash\n选择版本：7.17.3\n​ 2）测试：运行最基本的logstash管道\n​ cd logstash-7.17.3 #linux #-e选项表示，直接把配置放在命令中，这样可以有效快速进行测试 bin/logstash -e \u0026lsquo;input { stdin { } } output { stdout {} }\u0026rsquo; #windows .\\bin\\logstash.bat -e \u0026ldquo;input { stdin { } } output { stdout {} }\u0026rdquo;\n测试结果：\n​ window版本的logstash-7.17.3的bug:\nwindows出现错误提示could not find java; set JAVA_HOME or ensure java is in PATH\n​ 修改setup.bat\n​ ​ Codec Plugin测试\n​ # single line bin/logstash -e \u0026ldquo;input{stdin{codec=\u0026gt;line}}output{stdout{codec=\u0026gt; rubydebug}}\u0026rdquo; bin/logstash -e \u0026ldquo;input{stdin{codec=\u0026gt;json}}output{stdout{codec=\u0026gt; rubydebug}}\u0026rdquo;\nCodec Plugin —— Multiline\n设置参数:\npattern: 设置行匹配的正则表达式\nwhat : 如果匹配成功，那么匹配行属于上一个事件还是下一个事件\nprevious / next negate : 是否对pattern结果取反\ntrue / false ​ # 多行数据，异常 Exception in thread \u0026ldquo;main\u0026rdquo; java.lang.NullPointerException at com.example.myproject.Book.getTitle(Book.java:16) at com.example.myproject.Author.getBookTitles(Author.java:25) at com.example.myproject.Bootstrap.main(Bootstrap.java:14) # multiline-exception.conf input { stdin { codec =\u0026gt; multiline { pattern =\u0026gt; \u0026ldquo;^\\s\u0026rdquo; what =\u0026gt; \u0026ldquo;previous\u0026rdquo; } } } filter {} output { stdout { codec =\u0026gt; rubydebug } } #执行管道 bin/logstash -f multiline-exception.conf\nInput Plugin —— File\n支持从文件中读取数据，如日志文件 文件读取需要解决的问题：只被读取一次。重启后需要从上次读取的位置继续(通过sincedb 实现) 读取到文件新内容，发现新文件 文件发生归档操作(文档位置发生变化，日志rotation)，不能影响当前的内容读取 Filter Plugin\nFilter Plugin可以对Logstash Event进行各种处理，例如解析，删除字段，类型转换\nDate: 日期解析 Dissect: 分割符解析 Grok: 正则匹配解析 Mutate: 处理字段。重命名，删除，替换 Ruby: 利用Ruby 代码来动态修改Event Filter Plugin - Mutate\n对字段做各种操作:\nConvert : 类型转换 Gsub : 字符串替换 Split / Join /Merge: 字符串切割，数组合并字符串，数组合并数组 Rename: 字段重命名 Update / Replace: 字段内容更新替换 Remove_field: 字段删除 Logstash导入数据到ES\n1）测试数据集下载：https://grouplens.org/datasets/movielens/\n​ 2）准备logstash-movie.conf配置文件\n​ input { file { path =\u0026gt; \u0026ldquo;/home/es/logstash-7.17.3/dataset/movies.csv\u0026rdquo; start_position =\u0026gt; \u0026ldquo;beginning\u0026rdquo; sincedb_path =\u0026gt; \u0026ldquo;/dev/null\u0026rdquo; } } filter { csv { separator =\u0026gt; \u0026ldquo;,\u0026rdquo; columns =\u0026gt; [\u0026ldquo;id\u0026rdquo;,\u0026ldquo;content\u0026rdquo;,\u0026ldquo;genre\u0026rdquo;] } mutate { split =\u0026gt; { \u0026ldquo;genre\u0026rdquo; =\u0026gt; \u0026ldquo;|\u0026rdquo; } remove_field =\u0026gt; [\u0026ldquo;path\u0026rdquo;, \u0026ldquo;host\u0026rdquo;,\u0026quot;@timestamp\u0026quot;,\u0026ldquo;message\u0026rdquo;] } mutate { split =\u0026gt; [\u0026ldquo;content\u0026rdquo;, \u0026ldquo;(\u0026rdquo;] add_field =\u0026gt; { \u0026ldquo;title\u0026rdquo; =\u0026gt; \u0026ldquo;%{[content][0]}\u0026rdquo;} add_field =\u0026gt; { \u0026ldquo;year\u0026rdquo; =\u0026gt; \u0026ldquo;%{[content][1]}\u0026rdquo;} } mutate { convert =\u0026gt; { \u0026ldquo;year\u0026rdquo; =\u0026gt; \u0026ldquo;integer\u0026rdquo; } strip =\u0026gt; [\u0026ldquo;title\u0026rdquo;] remove_field =\u0026gt; [\u0026ldquo;path\u0026rdquo;, \u0026ldquo;host\u0026rdquo;,\u0026quot;@timestamp\u0026quot;,\u0026ldquo;message\u0026rdquo;,\u0026ldquo;content\u0026rdquo;] } } output { elasticsearch { hosts =\u0026gt; \u0026ldquo;http://localhost:9200\u0026rdquo; index =\u0026gt; \u0026ldquo;movies\u0026rdquo; document_id =\u0026gt; \u0026ldquo;%{id}\u0026rdquo; user =\u0026gt; \u0026ldquo;elastic\u0026rdquo; password =\u0026gt; \u0026ldquo;123456\u0026rdquo; } stdout {} }\n3）运行logstash\n​ # linux bin/logstash -f logstash-movie.conf\n同步数据库数据到Elasticsearch 需求: 将数据库中的数据同步到ES，借助ES的全文搜索,提高搜索速度\n需要把新增用户信息同步到Elasticsearch中 用户信息Update 后，需要能被更新到Elasticsearch 支持增量更新 用户注销后，不能被ES所搜索到 实现思路\n基于canal同步数据（项目实战中讲解）\n借助JDBC Input Plugin将数据从数据库读到Logstash\n需要自己提供所需的 JDBC Driver； JDBC Input Plugin 支持定时任务 Scheduling，其语法来自 Rufus-scheduler，其扩展了 Cron，使用 Cron 的语法可以完成任务的触发； JDBC Input Plugin 支持通过 Tracking_column / sql_last_value 的方式记录 State，最终实现增量的更新； https://www.elastic.co/cn/blog/logstash-jdbc-input-plugin JDBC Input Plugin实现步骤\n1）拷贝jdbc依赖到logstash-7.17.3/drivers目录下\n2）准备mysql-demo.conf配置文件\n​ input { jdbc { jdbc_driver_library =\u0026gt; \u0026ldquo;/home/es/logstash-7.17.3/drivers/mysql-connector-java-5.1.49.jar\u0026rdquo; jdbc_driver_class =\u0026gt; \u0026ldquo;com.mysql.jdbc.Driver\u0026rdquo; jdbc_connection_string =\u0026gt; \u0026ldquo;jdbc:mysql://localhost:3306/test?useSSL=false\u0026rdquo; jdbc_user =\u0026gt; \u0026ldquo;root\u0026rdquo; jdbc_password =\u0026gt; \u0026ldquo;123456\u0026rdquo; #启用追踪，如果为true，则需要指定tracking_column use_column_value =\u0026gt; true #指定追踪的字段， tracking_column =\u0026gt; \u0026ldquo;last_updated\u0026rdquo; #追踪字段的类型，目前只有数字(numeric)和时间类型(timestamp)，默认是数字类型 tracking_column_type =\u0026gt; \u0026ldquo;numeric\u0026rdquo; #记录最后一次运行的结果 record_last_run =\u0026gt; true #上面运行结果的保存位置 last_run_metadata_path =\u0026gt; \u0026ldquo;jdbc-position.txt\u0026rdquo; statement =\u0026gt; \u0026ldquo;SELECT * FROM user where last_updated \u0026gt;:sql_last_value;\u0026rdquo; schedule =\u0026gt; \u0026quot; * * * * * *\u0026quot; } } output { elasticsearch { document_id =\u0026gt; \u0026ldquo;%{id}\u0026rdquo; document_type =\u0026gt; \u0026ldquo;_doc\u0026rdquo; index =\u0026gt; \u0026ldquo;users\u0026rdquo; hosts =\u0026gt; [\u0026ldquo;http://localhost:9200\u0026rdquo;] user =\u0026gt; \u0026ldquo;elastic\u0026rdquo; password =\u0026gt; \u0026ldquo;123456\u0026rdquo; } stdout{ codec =\u0026gt; rubydebug } }\n3）运行logstash\n​ bin/logstash -f mysql-demo.conf\n​ 测试\n​ #user表 CREATE TABLE user ( id int NOT NULL AUTO_INCREMENT, name varchar(50) DEFAULT NULL, address varchar(50) CHARACTER DEFAULT NULL, last_updated bigint DEFAULT NULL, is_deleted int DEFAULT NULL, PRIMARY KEY (id) ) ENGINE=InnoDB AUTO_INCREMENT=2 DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_0900_ai_ci; #插入数据 INSERT INTO user(name,address,last_updated,is_deleted) VALUES(\u0026ldquo;张三\u0026rdquo;,\u0026ldquo;广州天河\u0026rdquo;,unix_timestamp(NOW()),0)\n​ ​ # 更新 update user set address=\u0026ldquo;广州白云山\u0026rdquo;,last_updated=unix_timestamp(NOW()) where name=\u0026ldquo;张三\u0026rdquo;\n​ ​ #删除 update user set is_deleted=1,last_updated=unix_timestamp(NOW()) where name=\u0026ldquo;张三\u0026rdquo;\n​ ​ #ES中查询 # 创建 alias，只显示没有被标记 deleted的用户 POST /_aliases { \u0026ldquo;actions\u0026rdquo;: [ { \u0026ldquo;add\u0026rdquo;: { \u0026ldquo;index\u0026rdquo;: \u0026ldquo;users\u0026rdquo;, \u0026ldquo;alias\u0026rdquo;: \u0026ldquo;view_users\u0026rdquo;, \u0026ldquo;filter\u0026rdquo; : { \u0026ldquo;term\u0026rdquo; : { \u0026ldquo;is_deleted\u0026rdquo; : 0} } } } ] } # 通过 Alias查询，查不到被标记成 deleted的用户 POST view_users/_search POST view_users/_search { \u0026ldquo;query\u0026rdquo;: { \u0026ldquo;term\u0026rdquo;: { \u0026ldquo;name.keyword\u0026rdquo;: { \u0026ldquo;value\u0026rdquo;: \u0026ldquo;张三\u0026rdquo; } } } }\n什么是Beats 轻量型数据采集器，文档地址： https://www.elastic.co/guide/en/beats/libbeat/7.17/index.html\nBeats 是一个免费且开放的平台，集合了多种单一用途的数据采集器。它们从成百上千或成千上万台机器和系统向 Logstash 或 Elasticsearch 发送数据。\n​ FileBeat简介 FileBeat专门用于转发和收集日志数据的轻量级采集工具。它可以作为代理安装在服务器上，FileBeat监视指定路径的日志文件，收集日志数据，并将收集到的日志转发到Elasticsearch或者Logstash。\nFileBeat的工作原理 启动FileBeat时，会启动一个或者多个输入（Input），这些Input监控指定的日志数据位置。FileBeat会针对每一个文件启动一个Harvester（收割机）。Harvester读取每一个文件的日志，将新的日志发送到libbeat，libbeat将数据收集到一起，并将数据发送给输出（Output）。\n​ logstash vs FileBeat\nLogstash是在jvm上运行的，资源消耗比较大。而FileBeat是基于golang编写的，功能较少但资源消耗也比较小，更轻量级。 Logstash 和Filebeat都具有日志收集功能，Filebeat更轻量，占用资源更少 Logstash 具有Filter功能，能过滤分析日志 一般结构都是Filebeat采集日志，然后发送到消息队列、Redis、MQ中，然后Logstash去获取，利用Filter功能过滤分析，然后存储到Elasticsearch中 FileBeat和Logstash配合，实现背压机制。当将数据发送到Logstash或 Elasticsearch时，Filebeat使用背压敏感协议，以应对更多的数据量。如果Logstash正在忙于处理数据，则会告诉Filebeat 减慢读取速度。一旦拥堵得到解决，Filebeat就会恢复到原来的步伐并继续传输数据。 Filebeat安装 https://www.elastic.co/guide/en/beats/filebeat/7.17/filebeat-installation-configuration.html\n1）下载并解压Filebeat\n下载地址：https://www.elastic.co/cn/downloads/past-releases#filebeat\n选择版本：7.17.3\n​ 2）编辑配置\n修改 filebeat.yml 以设置连接信息：\n​ output.elasticsearch: hosts: [\u0026ldquo;192.168.65.174:9200\u0026rdquo;,\u0026ldquo;192.168.65.192:9200\u0026rdquo;,\u0026ldquo;192.168.65.204:9200\u0026rdquo;] username: \u0026ldquo;elastic\u0026rdquo; password: \u0026ldquo;123456\u0026rdquo; setup.kibana: host: \u0026ldquo;192.168.65.174:5601\u0026rdquo;\n3) 启用和配置数据收集模块\n从安装目录中，运行：\n​ # 查看可以模块列表 ./filebeat modules list #启用nginx模块 ./filebeat modules enable nginx #如果需要更改nginx日志路径,修改modules.d/nginx.yml - module: nginx access: var.paths: [\u0026quot;/var/log/nginx/access.log*\u0026quot;] #启用 Logstash 模块 ./filebeat modules enable logstash #在 modules.d/logstash.yml 文件中修改设置 - module: logstash log: enabled: true var.paths: [\u0026quot;/home/es/logstash-7.17.3/logs/*.log\u0026quot;]\n4）启动 Filebeat\n​ # setup命令加载Kibana仪表板。 如果仪表板已经设置，则忽略此命令。 ./filebeat setup # 启动Filebeat ./filebeat -e\nELK整合实战 案例：采集tomcat服务器日志\nTomcat服务器运行过程中产生很多日志信息，通过Logstash采集并存储日志信息至ElasticSearch中\n使用FileBeats将日志发送到Logstash\n1）创建配置文件filebeat-logstash.yml，配置FileBeats将数据发送到Logstash\n​ vim filebeat-logstash.yml chmod 644 filebeat-logstash.yml #因为Tomcat的web log日志都是以IP地址开头的，所以我们需要修改下匹配字段。 # 不以ip地址开头的行追加到上一行 filebeat.inputs: - type: log enabled: true paths: - /home/es/apache-tomcat-8.5.33/logs/access.* multiline.pattern: \u0026lsquo;^\\d+\\.\\d+\\.\\d+\\.\\d+ \u0026rsquo; multiline.negate: true multiline.match: after output.logstash: enabled: true hosts: [\u0026ldquo;192.168.65.204:5044\u0026rdquo;]\npattern：正则表达式 negate：true 或 false；默认是false，匹配pattern的行合并到上一行；true，不匹配pattern的行合并到上一行 match：after 或 before，合并到上一行的末尾或开头 2）启动FileBeat，并指定使用指定的配置文件\n​ ./filebeat -e -c filebeat-logstash.yml\n可能出现的异常：\n异常1：Exiting: error loading config file: config file (\u0026ldquo;filebeat-logstash.yml\u0026rdquo;) can only be writable by the owner but the permissions are \u0026ldquo;-rw-rw-r\u0026ndash;\u0026rdquo; (to fix the permissions use: \u0026lsquo;chmod go-w /home/es/filebeat-7.17.3-linux-x86_64/filebeat-logstash.yml\u0026rsquo;)\n因为安全原因不要其他用户写的权限，去掉写的权限就可以了\n​ chmod 644 filebeat-logstash.yml\n异常2：Failed to connect to backoff(async(tcp://192.168.65.204:5044)): dial tcp 192.168.65.204:5044: connect: connection refused\nFileBeat将尝试建立与Logstash监听的IP和端口号进行连接。但此时，我们并没有开启并配置Logstash，所以FileBeat是无法连接到Logstash的。\n配置Logstash接收FileBeat收集的数据并打印\n​ vim config/filebeat-console.conf # 配置从FileBeat接收数据 input { beats { port =\u0026gt; 5044 } } output { stdout { codec =\u0026gt; rubydebug } }\n测试logstash配置是否正确\n​ bin/logstash -f config/filebeat-console.conf \u0026ndash;config.test_and_exit\n启动logstash\n​ # reload.automatic：修改配置文件时自动重新加载 bin/logstash -f config/filebeat-console.conf \u0026ndash;config.reload.automatic\n测试访问tomcat，logstash是否接收到了Filebeat传过来的tomcat日志\nLogstash输出数据到Elasticsearch\n如果我们需要将数据输出值ES而不是控制台的话，我们修改Logstash的output配置。\n​ vim config/filebeat-elasticSearch.conf input { beats { port =\u0026gt; 5044 } } output { elasticsearch { hosts =\u0026gt; [\u0026ldquo;http://localhost:9200\u0026rdquo;] user =\u0026gt; \u0026ldquo;elastic\u0026rdquo; password =\u0026gt; \u0026ldquo;123456\u0026rdquo; } stdout{ codec =\u0026gt; rubydebug } }\n启动logstash\n​ bin/logstash -f config/filebeat-elasticSearch.conf \u0026ndash;config.reload.automatic\nES中会生成一个以logstash开头的索引，测试日志是否保存到了ES。\n思考：日志信息都保证在message字段中，是否可以把日志进行解析一个个的字段？例如：IP字段、时间、请求方式、请求URL、响应结果。\n利用Logstash过滤器解析日志\n从日志文件中收集到的数据包含了很多有效信息，比如IP、时间等，在Logstash中可以配置过滤器Filter对采集到的数据进行过滤处理，Logstash中有大量的插件可以供我们使用。\n​ 查看Logstash已经安装的插件 bin/logstash-plugin list\nGrok插件\nGrok是一种将非结构化日志解析为结构化的插件。这个工具非常适合用来解析系统日志、Web服务器日志、MySQL或者是任意其他的日志格式。\nhttps://www.elastic.co/guide/en/logstash/7.17/plugins-filters-grok.html\nGrok语法\nGrok是通过模式匹配的方式来识别日志中的数据,可以把Grok插件简单理解为升级版本的正则表达式。它拥有更多的模式，默认Logstash拥有120个模式。如果这些模式不满足我们解析日志的需求，我们可以直接使用正则表达式来进行匹配。\ngrok模式的语法是：\n​ %{SYNTAX:SEMANTIC}\nSYNTAX（语法）指的是Grok模式名称，SEMANTIC（语义）是给模式匹配到的文本字段名。例如：\n​ %{NUMBER:duration} %{IP:client} duration表示：匹配一个数字，client表示匹配一个IP地址。\n默认在Grok中，所有匹配到的的数据类型都是字符串，如果要转换成int类型（目前只支持int和float），可以这样：%{NUMBER:duration:int} %{IP:client}\n常用的Grok模式\nhttps://help.aliyun.com/document_detail/129387.html?scm=20140722.184.2.173\n用法\n​ filter { grok { match =\u0026gt; { \u0026ldquo;message\u0026rdquo; =\u0026gt; \u0026ldquo;%{IP:client} %{WORD:method} %{URIPATHPARAM:request} %{NUMBER:bytes} %{NUMBER:duration}\u0026rdquo; } } }\n比如，tomacat日志\n​ 192.168.65.103 - - [23/Jun/2022:22:37:23 +0800] \u0026ldquo;GET /docs/images/docs-stylesheet.css HTTP/1.1\u0026rdquo; 200 5780\n解析后的字段\n字段名 说明 client IP 浏览器端IP timestamp 请求的时间戳 method 请求方式（GET/POST） uri 请求的链接地址 status 服务器端响应状态 length 响应的数据长度 grok模式\n​ %{IP:ip} - - [%{HTTPDATE:date}] \u0026quot;%{WORD:method} %{PATH:uri} %{DATA:protocol}\u0026quot; %{INT:status} %{INT:length}\n为了方便测试，我们可以使用Kibana来进行Grok开发：\n​ 修改Logstash配置文件\n​ vim config/filebeat-console.conf input { beats { port =\u0026gt; 5044 } } filter { grok { match =\u0026gt; { \u0026ldquo;message\u0026rdquo; =\u0026gt; \u0026ldquo;%{IP:ip} - - [%{HTTPDATE:date}] \u0026quot;%{WORD:method} %{PATH:uri} %{DATA:protocol}\u0026quot; %{INT:status:int} %{INT:length:int}\u0026rdquo; } } } output { stdout { codec =\u0026gt; rubydebug } }\n启动logstash测试\n​ bin/logstash -f config/filebeat-console.conf \u0026ndash;config.reload.automatic\n使用mutate插件过滤掉不需要的字段\n​ mutate { enable_metric =\u0026gt; \u0026ldquo;false\u0026rdquo; remove_field =\u0026gt; [\u0026ldquo;message\u0026rdquo;, \u0026ldquo;log\u0026rdquo;, \u0026ldquo;tags\u0026rdquo;, \u0026ldquo;input\u0026rdquo;, \u0026ldquo;agent\u0026rdquo;, \u0026ldquo;host\u0026rdquo;, \u0026ldquo;ecs\u0026rdquo;, \u0026ldquo;@version\u0026rdquo;] }\n要将日期格式进行转换，我们可以使用Date插件来实现。该插件专门用来解析字段中的日期，官方说明文档：https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-date.html\n用法如下：\n​ 将date字段转换为「年月日 时分秒」格式。默认字段经过date插件处理后，会输出到@timestamp字段，所以，我们可以通过修改target属性来重新定义输出字段。\n​ date { match =\u0026gt; [\u0026ldquo;date\u0026rdquo;,\u0026ldquo;dd/MMM/yyyy:HH:mm:ss Z\u0026rdquo;,\u0026ldquo;yyyy-MM-dd HH:mm:ss\u0026rdquo;] target =\u0026gt; \u0026ldquo;date\u0026rdquo; }\n输出到Elasticsearch指定索引\nindex来指定索引名称，默认输出的index名称为：logstash-%{+yyyy.MM.dd}。但注意，要在index中使用时间格式化，filter的输出必须包含 @timestamp字段，否则将无法解析日期。\n​ output { elasticsearch { index =\u0026gt; \u0026ldquo;tomcat_web_log_%{+YYYY-MM}\u0026rdquo; hosts =\u0026gt; [\u0026ldquo;http://localhost:9200\u0026rdquo;] user =\u0026gt; \u0026ldquo;elastic\u0026rdquo; password =\u0026gt; \u0026ldquo;123456\u0026rdquo; } stdout{ codec =\u0026gt; rubydebug } }\n注意：index名称中，不能出现大写字符\n完整的Logstash配置文件\n​ vim config/filebeat-filter-es.conf input { beats { port =\u0026gt; 5044 } } filter { grok { match =\u0026gt; { \u0026ldquo;message\u0026rdquo; =\u0026gt; \u0026ldquo;%{IP:ip} - - [%{HTTPDATE:date}] \u0026quot;%{WORD:method} %{PATH:uri} %{DATA:protocol}\u0026quot; %{INT:status:int} %{INT:length:int}\u0026rdquo; } } mutate { enable_metric =\u0026gt; \u0026ldquo;false\u0026rdquo; remove_field =\u0026gt; [\u0026ldquo;message\u0026rdquo;, \u0026ldquo;log\u0026rdquo;, \u0026ldquo;tags\u0026rdquo;, \u0026ldquo;input\u0026rdquo;, \u0026ldquo;agent\u0026rdquo;, \u0026ldquo;host\u0026rdquo;, \u0026ldquo;ecs\u0026rdquo;, \u0026ldquo;@version\u0026rdquo;] } date { match =\u0026gt; [\u0026ldquo;date\u0026rdquo;,\u0026ldquo;dd/MMM/yyyy:HH:mm:ss Z\u0026rdquo;,\u0026ldquo;yyyy-MM-dd HH:mm:ss\u0026rdquo;] target =\u0026gt; \u0026ldquo;date\u0026rdquo; } } output { stdout { codec =\u0026gt; rubydebug } elasticsearch { index =\u0026gt; \u0026ldquo;tomcat_web_log_%{+YYYY-MM}\u0026rdquo; hosts =\u0026gt; [\u0026ldquo;http://localhost:9200\u0026rdquo;] user =\u0026gt; \u0026ldquo;elastic\u0026rdquo; password =\u0026gt; \u0026ldquo;123456\u0026rdquo; } }\n启动logstash\n​ bin/logstash -f config/filebeat-filter-es.conf \u0026ndash;config.reload.automatic\n","permalink":"https://www.sulvblog.cn/post/elasticsearch/","summary":"ElasticSearch快速入门实战 主讲老师：Fox\nES版本： v7.17.3\nES环境搭建视频：https://pan.baidu.com/s/1PsTNbpDy\u0026ndash;M-pvFWb3aehQ?pwd=nwxl\n​ 文档：1.ElasticSearch快速入门实战.note 链接：http://note.youdao.com/noteshare?id=d5d5718ae542f274ba0fda4284a53231\u0026amp;sub=68E590656C7A48858C7F6997D4A1511A\n全文检索 数据分类：\n结构化数据： 固定格式，有限长度 比如mysql存的数据 非结构化数据：不定长，无固定格式 比如邮件，word文档，日志 半结构化数据： 前两者结合 比如xml，html 搜索分类：\n结构化数据搜索： 使用关系型数据库\n非结构化数据搜索\n顺序扫描 全文检索 设想一个关于搜索的场景，假设我们要搜索一首诗句内容中带“前”字的古诗\nname content author 静夜思 床前明月光,疑是地上霜。举头望明月，低头思故乡。 李白 望庐山瀑布 日照香炉生紫烟，遥看瀑布挂前川。飞流直下三千尺,疑是银河落九天。 李白 \u0026hellip; \u0026hellip; \u0026hellip; 思考：用传统关系型数据库和ES 实现会有什么差别？\n如果用像 MySQL 这样的 RDBMS 来存储古诗的话，我们应该会去使用这样的 SQL 去查询\n​ select name from poems where content like \u0026ldquo;%前%\u0026rdquo;\n这种我们称为顺序扫描法，需要遍历所有的记录进行匹配。不但效率低，而且不符合我们搜索时的期望，比如我们在搜索“ABCD\u0026quot;这样的关键词时，通常还希望看到\u0026quot;A\u0026quot;,\u0026ldquo;AB\u0026rdquo;,\u0026ldquo;CD\u0026rdquo;,“ABC”的搜索结果。\n什么是全文检索 全文检索是指：\n通过一个程序扫描文本中的每一个单词，针对单词建立索引，并保存该单词在文本中的位置、以及出现的次数 用户查询时，通过之前建立好的索引来查询，将索引中单词对应的文本位置、出现的次数返回给用户，因为有了具体文本的位置，所以就可以将具体内容读取出来了 ​ 搜索原理简单概括的话可以分为这么几步：\n内容爬取，停顿词过滤比如一些无用的像\u0026quot;的\u0026quot;，“了”之类的语气词/连接词 内容分词，提取关键词 根据关键词建立倒排索引 用户输入关键词进行搜索 倒排索引 索引就类似于目录，平时我们使用的都是索引，都是通过主键定位到某条数据，那么倒排索引呢，刚好相反，数据对应到主键。\n​ 这里以一个博客文章的内容为例:","title":"ElasticSearch快速入门实战"},{"content":"ES版本： v7.17.3\nES环境搭建视频：https://pan.baidu.com/s/1PsTNbpDy\u0026ndash;M-pvFWb3aehQ?pwd=nwxl\nElasticSearch快速入门实战 note 链接：http://note.youdao.com/noteshare?id=d5d5718ae542f274ba0fda4284a53231\u0026amp;sub=68E590656C7A48858C7F6997D4A1511A\n全文检索 数据分类：\n结构化数据： 固定格式，有限长度 比如mysql存的数据 非结构化数据：不定长，无固定格式 比如邮件，word文档，日志 半结构化数据： 前两者结合 比如xml，html 搜索分类：\n结构化数据搜索： 使用关系型数据库\n非结构化数据搜索\n顺序扫描 全文检索 设想一个关于搜索的场景，假设我们要搜索一首诗句内容中带“前”字的古诗\nname content author 静夜思 床前明月光,疑是地上霜。举头望明月，低头思故乡。 李白 望庐山瀑布 日照香炉生紫烟，遥看瀑布挂前川。飞流直下三千尺,疑是银河落九天。 李白 \u0026hellip; \u0026hellip; \u0026hellip; 思考：用传统关系型数据库和ES 实现会有什么差别？\n如果用像 MySQL 这样的 RDBMS 来存储古诗的话，我们应该会去使用这样的 SQL 去查询\n​ select name from poems where content like \u0026ldquo;%前%\u0026rdquo;\n这种我们称为顺序扫描法，需要遍历所有的记录进行匹配。不但效率低，而且不符合我们搜索时的期望，比如我们在搜索“ABCD\u0026quot;这样的关键词时，通常还希望看到\u0026quot;A\u0026quot;,\u0026ldquo;AB\u0026rdquo;,\u0026ldquo;CD\u0026rdquo;,“ABC”的搜索结果。\n什么是全文检索 全文检索是指：\n通过一个程序扫描文本中的每一个单词，针对单词建立索引，并保存该单词在文本中的位置、以及出现的次数 用户查询时，通过之前建立好的索引来查询，将索引中单词对应的文本位置、出现的次数返回给用户，因为有了具体文本的位置，所以就可以将具体内容读取出来了 ​ 搜索原理简单概括的话可以分为这么几步：\n内容爬取，停顿词过滤比如一些无用的像\u0026quot;的\u0026quot;，“了”之类的语气词/连接词 内容分词，提取关键词 根据关键词建立倒排索引 用户输入关键词进行搜索 倒排索引 索引就类似于目录，平时我们使用的都是索引，都是通过主键定位到某条数据，那么倒排索引呢，刚好相反，数据对应到主键。\n​ 这里以一个博客文章的内容为例:\n正排索引（正向索引）\n文章ID 文章标题 文章内容 1 浅析JAVA设计模式 JAVA设计模式是每一个JAVA程序员都应该掌握的进阶知识 2 JAVA多线程设计模式 JAVA多线程与设计模式结合 倒排索引（反向索引）\n假如，我们有一个站内搜索的功能，通过某个关键词来搜索相关的文章，那么这个关键词可能出现在标题中，也可能出现在文章内容中，那我们将会在创建或修改文章的时候，建立一个关键词与文章的对应关系表，这种，我们可以称之为倒排索引。\nlike %java设计模式% java 设计模式\n关键词 文章ID JAVA 1,2 设计模式 1,2 多线程 2 简单理解，正向索引是通过key找value，反向索引则是通过value找key。ES底层在检索时底层使用的就是倒排索引。\nElasticSearch简介 ElasticSearch是什么 ElasticSearch（简称ES）是一个分布式、RESTful 风格的搜索和数据分析引擎，是用Java开发并且是当前最流行的开源的企业级搜索引擎，能够达到近实时搜索，稳定，可靠，快速，安装使用方便。\n客户端支持Java、.NET（C#）、PHP、Python、Ruby等多种语言。\n官方网站: https://www.elastic.co/\n**下载地址：**https://www.elastic.co/cn/downloads/past-releases#elasticsearch\n搜索引擎排名：\n​ 参考网站：https://db-engines.com/en/ranking/search+engine\n起源——Lucene 基于Java语言开发的搜索引擎库类\n创建于1999年，2005年成为Apache 顶级开源项目\nLucene具有高性能、易扩展的优点\nLucene的局限性︰\n只能基于Java语言开发 类库的接口学习曲线陡峭 原生并不支持水平扩展 Elasticsearch的诞生 Elasticsearch是构建在Apache Lucene之上的开源分布式搜索引擎。\n2004年 Shay Banon 基于Lucene开发了Compass\n2010年 Shay Banon重写了Compass，取名Elasticsearch\n支持分布式，可水平扩展 降低全文检索的学习曲线，可以被任何编程语言调用 ​ Elasticsearch 与 Lucene 核心库竞争的优势在于：\n完美封装了 Lucene 核心库，设计了友好的 Restful-API，开发者无需过多关注底层机制，直接开箱即用。 分片与副本机制，直接解决了集群下性能与高可用问题。 ES Server进程 3节点 raft (奇数节点)\n数据分片 -》lucene实例 分片和副本数 1个ES节点可以有多个lucene实例。也可以指定一个索引的多个分片\n​ ElasticSearch版本特性 5.x新特性\nLucene 6.x， 性能提升，默认打分机制从TF-IDF改为BM 25\n支持Ingest节点/ Painless Scripting / Completion suggested支持/原生的Java REST客户端\nType标记成deprecated， 支持了Keyword的类型\n性能优化\n内部引擎移除了避免同一文档并发更新的竞争锁，带来15% - 20%的性能提升 Instant aggregation,支持分片，上聚合的缓存 新增了Profile API 6.x新特性\nLucene 7.x\n新功能\n跨集群复制(CCR) 索引生命周期管理 SQL的支持 更友好的的升级及数据迁移\n在主要版本之间的迁移更为简化，体验升级 全新的基于操作的数据复制框架，可加快恢复数据 性能优化\n有效存储稀疏字段的新方法，降低了存储成本 在索引时进行排序，可加快排序的查询性能 7.x新特性\nLucene 8.0\n重大改进-正式废除单个索引下多Type的支持\n7.1开始，Security 功能免费使用\nECK - Elasticseach Operator on Kubernetes\n新功能\nNew Cluster coordination Feature——Complete High Level REST Client Script Score Query 性能优化\n默认的Primary Shard数从5改为1,避免Over Sharding 性能优化， 更快的Top K 8.x新特性\nRest API相比较7.x而言做了比较大的改动（比如彻底删除_type） 默认开启安全配置 存储空间优化：对倒排文件使用新的编码集，对于keyword、match_only_text、text类型字段有效，有3.5%的空间优化提升，对于新建索引和segment自动生效。 优化geo_point，geo_shape类型的索引（写入）效率：15%的提升。 技术预览版KNN API发布，（K邻近算法），跟推荐系统、自然语言排名相关。 https://www.elastic.co/guide/en/elastic-stack/current/elasticsearch-breaking-changes.html ElasticSearch vs Solr Solr 是第一个基于 Lucene 核心库功能完备的搜索引擎产品，诞生远早于 Elasticsearch。\n当单纯的对已有数据进行搜索时，Solr更快。当实时建立索引时, Solr会产生io阻塞，查询性能较差, Elasticsearch具有明显的优势。\n​ ​ 大型互联网公司，实际生产环境测试，将搜索引擎从Solr转到 Elasticsearch以后的平均查询速度有了50倍的提升。\n​ 总结：\nSolr 利用 Zookeeper 进行分布式管理，而Elasticsearch 自身带有分布式协调管理功能。 Solr 支持更多格式的数据，比如JSON、XML、CSV，而 Elasticsearch 仅支持json文件格式。 Solr 在传统的搜索应用中表现好于 Elasticsearch，但在处理实时搜索应用时效率明显低于 Elasticsearch。 Solr 是传统搜索应用的有力解决方案，但 Elasticsearch更适用于新兴的实时搜索应用。 Elastic Stack介绍 在Elastic Stack之前我们听说过ELK，ELK分别是Elasticsearch，Logstash，Kibana这三款软件在一起的简称，在发展的过程中又有新的成员Beats的加入，就形成了Elastic Stack。\n​ Elastic Stack生态圈\n在Elastic Stack生态圈中Elasticsearch作为数据存储和搜索，是生态圈的基石，Kibana在上层提供用户一个可视化及操作的界面，Logstash和Beat可以对数据进行收集。在上图的右侧X-Pack部分则是Elastic公司提供的商业项目。\n指标分析/日志分析：\n​ ElasticSearch应用场景 站内搜索 日志管理与分析 大数据分析 应用性能监控 机器学习 国内现在有大量的公司都在使用 Elasticsearch，包括携程、滴滴、今日头条、饿了么、360安全、小米、vivo等诸多知名公司。除了搜索之外，结合Kibana、Logstash、Beats，Elastic Stack还被广泛运用在大数据近实时分析领域，包括日志分析、指标监控、信息安全等多个领域。它可以帮助你探索海量结构化、非结构化数据，按需创建可视化报表，对监控数据设置报警阈值，甚至通过使用机器学习技术，自动识别异常状况。\n通用数据处理流程：\n​ ElasticSearch快速开始 安装JDK\n1、yum install -y java-1.8.0-openjdk* # 或者 mkdir /opt/jdk;tar -xvzf jdk-8u333-linux-x64.tar.gz -C /opt/jdk/; mv /opt/jdk/jdk1.8.0_333/ /opt/jdk/jdk1.8 ; cat \u0026lt;\u0026lt;EOF \u0026gt;\u0026gt; /etc/profile JAVA_HOME=/opt/jdk/jdk1.8 CLASSPATH=$JAVA_HOME/lib/ PATH=$PATH:$JAVA_HOME/bin export PATH JAVA_HOME CLASSPATH EOF source /etc/profile ElasticSearch安装运行 环境准备 运行Elasticsearch，需安装并配置JDK\n设置$JAVA_HOME 各个版本对Java的依赖 https://www.elastic.co/support/matrix#matrix_jvm\nElasticsearch 5需要Java 8以上的版本 Elasticsearch 从6.5开始支持Java 11 7.0开始，内置了Java环境 ES比较耗内存，建议虚拟机4G或以上内存，jvm1g以上的内存分配\n可以参考es的环境文件elasticsearch-env.bat\n​ ES的jdk环境生效的优先级配置ES_JAVA_HOME\u0026gt;JAVA_HOME\u0026gt;ES_HOME\n下载并解压ElasticSearch 下载地址： https://www.elastic.co/cn/downloads/past-releases#elasticsearch\n选择版本：7.17.3\n​ ElasticSearch文件目录结构\n目录 描述 bin 脚本文件，包括启动elasticsearch，安装插件，运行统计数据等 config 配置文件目录，如elasticsearch配置、角色配置、jvm配置等。 jdk java运行环境 data 默认的数据存放目录，包含节点、分片、索引、文档的所有数据，生产环境需要修改。 lib elasticsearch依赖的Java类库 logs 默认的日志文件存储路径，生产环境需要修改。 modules 包含所有的Elasticsearch模块，如Cluster、Discovery、Indices等。 plugins 已安装插件目录 主配置文件elasticsearch.yml\ncluster.name 当前节点所属集群名称，多个节点如果要组成同一个集群，那么集群名称一定要配置成相同。默认值elasticsearch，生产环境建议根据ES集群的使用目的修改成合适的名字。\nnode.name 当前节点名称，默认值当前节点部署所在机器的主机名，所以如果一台机器上要起多个ES节点的话，需要通过配置该属性明确指定不同的节点名称。\npath.data 配置数据存储目录，比如索引数据等，默认值 $ES_HOME/data，生产环境下强烈建议部署到另外的安全目录，防止ES升级导致数据被误删除。\npath.logs 配置日志存储目录，比如运行日志和集群健康信息等，默认值 $ES_HOME/logs，生产环境下强烈建议部署到另外的安全目录，防止ES升级导致数据被误删除。\nbootstrap.memory_lock 配置ES启动时是否进行内存锁定检查，默认值true。\nES对于内存的需求比较大，一般生产环境建议配置大内存，如果内存不足，容易导致内存交换到磁盘，严重影响ES的性能。所以默认启动时进行相应大小内存的锁定，如果无法锁定则会启动失败。\n非生产环境可能机器内存本身就很小，能够供给ES使用的就更小，如果该参数配置为true的话很可能导致无法锁定内存以致ES无法成功启动，此时可以修改为false。\nnetwork.host 配置能够访问当前节点的主机，默认值为当前节点所在机器的本机回环地址127.0.0.1 和[::1]，这就导致默认情况下只能通过当前节点所在主机访问当前节点。可以配置为 0.0.0.0 ，表示所有主机均可访问。\nhttp.port 配置当前ES节点对外提供服务的http端口，默认值 9200\ndiscovery.seed_hosts 配置参与集群节点发现过程的主机列表，说白一点就是集群中所有节点所在的主机列表，可以是具体的IP地址，也可以是可解析的域名。\ncluster.initial_master_nodes 配置ES集群初始化时参与master选举的节点名称列表，必须与node.name配置的一致。ES集群首次构建完成后，应该将集群中所有节点的配置文件中的cluster.initial_master_nodes配置项移除，重启集群或者将新节点加入某个已存在的集群时切记不要设置该配置项。\n​ #ES开启远程访问 network.host: 0.0.0.0\n修改JVM配置 修改config/jvm.options配置文件，调整jvm堆内存大小\n​ vim jvm.options -Xms4g -Xmx4g\n配置的建议\nXms和Xms设置成—样 Xmx不要超过机器内存的50% 不要超过30GB - https://www.elastic.co/cn/blog/a-heap-of-trouble 启动ElasticSearch服务 Windows\n直接运行elasticsearch.bat\nLinux（centos7）\nES不允许使用root账号启动服务，如果你当前账号是root，则需要创建一个专有账户\n​ #非root用户 bin/elasticsearch # -d 后台启动 bin/elasticsearch -d\n​ 注意：es默认不能用root用户启动，生产环境建议为elasticsearch创建用户。\n​ #为elaticsearch创建用户并赋予相应权限 adduser es passwd es chown -R es:es elasticsearch-17.3\n运行http://localhost:9200/\n​ 如果ES服务启动异常，会有提示：\n​ 启动ES服务常见错误解决方案\n[1]: max file descriptors [4096] for elasticsearch process is too low, increase to at least [65536]\nES因为需要大量的创建索引文件，需要大量的打开系统的文件，所以我们需要解除linux系统当中打开文件最大数目的限制，不然ES启动就会抛错\n#切换到root用户 vim /etc/security/limits.conf 末尾添加如下配置： *\tsoft nofile 65536 * hard nofile 65536 * soft nproc 4096 *\thard nproc 4096 ​\n[2]: max number of threads [1024] for user [es] is too low, increase to at least [4096]\n无法创建本地线程问题,用户最大可创建线程数太小\nvim /etc/security/limits.d/20-nproc.conf 改为如下配置： * soft nproc 4096 [3]: max virtual memory areas vm.max_map_count [65530] is too low, increase to at least [262144]\n最大虚拟内存太小,调大系统的虚拟内存\n​\nvim /etc/sysctl.conf 追加以下内容： vm.max_map_count=262144 保存退出之后执行如下命令： sysctl -p [4]: the default discovery settings are unsuitable for production use; at least one of [discovery.seed_hosts, discovery.seed_providers, cluster.initial_master_nodes] must be configured\n缺少默认配置，至少需要配置discovery.seed_hosts/discovery.seed_providers/cluster.initial_master_nodes中的一个参数.\ndiscovery.seed_hosts: 集群主机列表 discovery.seed_providers: 基于配置文件配置集群主机列表 cluster.initial_master_nodes: 启动时初始化的参与选主的node，生产环境必填 ​\nvim config/elasticsearch.yml #添加配置 discovery.seed_hosts: [\u0026#34;127.0.0.1\u0026#34;] cluster.initial_master_nodes: [\u0026#34;node-1\u0026#34;] #或者 单节点（集群单节点） discovery.type: single-node 客户端Kibana安装 Kibana是一个开源分析和可视化平台，旨在与Elasticsearch协同工作。\n1）下载并解压缩Kibana\n下载地址：https://www.elastic.co/cn/downloads/past-releases#kibana\n选择版本：7.17.3\n​ 2）修改Kibana.yml\nvim config/kibana.yml server.port: 5601 server.host: \u0026#34;0.0.0.0\u0026#34; #服务器ip elasticsearch.hosts: [\u0026#34;http://localhost:9200\u0026#34;] #elasticsearch的访问地址 i18n.locale: \u0026#34;zh-CN\u0026#34; #Kibana汉化 3）运行Kibana\n# 注意：kibana也需要非root用户启动 bin/kibana # 后台启动 nohup bin/kibana \u0026amp; # 或者 sudo -H -u es /bin/bash -c \u0026#34;nohup bin/kibana \u0026amp;\u0026#34; ​\n访问Kibana: http://localhost:5601/\n​ cat API\n/_cat/allocation #查看单节点的shard分配整体情况 /_cat/shards #查看各shard的详细情况 /_cat/shards/{index} #查看指定分片的详细情况 /_cat/master #查看master节点信息 /_cat/nodes #查看所有节点信息 /_cat/indices #查看集群中所有index的详细信息 /_cat/indices/{index} #查看集群中指定index的详细信息 /_cat/segments #查看各index的segment详细信息,包括segment名, 所属shard, 内存(磁盘)占用大小, 是否刷盘 /_cat/segments/{index}#查看指定index的segment详细信息 /_cat/count #查看当前集群的doc数量 /_cat/count/{index} #查看指定索引的doc数量 /_cat/recovery #查看集群内每个shard的recovery过程.调整replica。 /_cat/recovery/{index}#查看指定索引shard的recovery过程 /_cat/health #查看集群当前状态：红、黄、绿 /_cat/pending_tasks #查看当前集群的pending task /_cat/aliases #查看集群中所有alias信息,路由配置等 /_cat/aliases/{alias} #查看指定索引的alias信息 /_cat/thread_pool #查看集群各节点内部不同类型的threadpool的统计信息, /_cat/plugins #查看集群各个节点上的plugin信息 /_cat/fielddata #查看当前集群各个节点的fielddata内存使用情况 /_cat/fielddata/{fields} #查看指定field的内存使用情况,里面传field属性对应的值 /_cat/nodeattrs #查看单节点的自定义属性 /_cat/repositories #输出集群中注册快照存储库 /_cat/templates #输出当前正在存在的模板信息 Elasticsearch安装分词插件 Elasticsearch提供插件机制对系统进行扩展\n以安装analysis-icu这个分词插件为例\n在线安装\n​\n#查看已安装插件 bin/elasticsearch-plugin list #安装插件 bin/elasticsearch-plugin install analysis-icu #删除插件 bin/elasticsearch-plugin remove analysis-icu 注意：安装和删除完插件后，需要重启ES服务才能生效。\n测试分词效果\n​ POST _analyze { \u0026ldquo;analyzer\u0026rdquo;:\u0026ldquo;icu_analyzer\u0026rdquo;, \u0026ldquo;text\u0026rdquo;:\u0026ldquo;中华人民共和国\u0026rdquo; }\n​ 离线安装\n本地下载相应的插件，解压，然后手动上传到elasticsearch的plugins目录，然后重启ES实例就可以了。\n比如ik中文分词插件：https://github.com/medcl/elasticsearch-analysis-ik\nelasticsearch-analysis-ik-7.15.2.zip\n必须对应es版本\n测试分词效果\n#ES的默认分词设置是standard，会单字拆分 POST _analyze { \u0026#34;analyzer\u0026#34;:\u0026#34;standard\u0026#34;, \u0026#34;text\u0026#34;:\u0026#34;中华人民共和国\u0026#34; } #ik_smart:会做最粗粒度的拆 POST _analyze { \u0026#34;analyzer\u0026#34;: \u0026#34;ik_smart\u0026#34;, \u0026#34;text\u0026#34;: \u0026#34;中华人民共和国\u0026#34; } #ik_max_word:会将文本做最细粒度的拆分 POST _analyze { \u0026#34;analyzer\u0026#34;:\u0026#34;ik_max_word\u0026#34;, \u0026#34;text\u0026#34;:\u0026#34;中华人民共和国\u0026#34; } ​\n创建索引时可以指定IK分词器作为默认分词器\nPUT /es_db { \u0026#34;settings\u0026#34; : { \u0026#34;index\u0026#34; : { \u0026#34;analysis.analyzer.default.type\u0026#34;: \u0026#34;ik_max_word\u0026#34; } } } ​ ElasticSearch基本概念 关系型数据库 VS ElasticSearch 在7.0之前，一个 Index可以设置多个Types\n目前Type已经被Deprecated，7.0开始，一个索引只能创建一个Type - “_doc”\n传统关系型数据库和Elasticsearch的区别:\nElasticsearch- Schemaless /相关性/高性能全文检索 RDMS —事务性/ Join ​ 索引（Index） 一个索引就是一个拥有几分相似特征的文档的集合。比如说，可以有一个客户数据的索引，另一个产品目录的索引，还有一个订单数据的索引。\n一个索引由一个名字来标识（必须全部是小写字母的），并且当我们要对对应于这个索引中的文档进行索引、搜索、更新和删除的时候，都要使用到这个名字。\n​ 文档（Document） Elasticsearch是面向文档的，文档是所有可搜索数据的最小单位。\n日志文件中的日志项 一本电影的具体信息/一张唱片的详细信息 MP3播放器里的一首歌/一篇PDF文档中的具体内容 文档会被序列化成JSON格式，保存在Elasticsearch中\nJSON对象由字段组成 每个字段都有对应的字段类型(字符串/数值/布尔/日期/二进制/范围类型) 每个文档都有一个Unique ID\n可以自己指定ID或者通过Elasticsearch自动生成 一篇文档包含了一系列字段，类似数据库表中的一条记录\nJSON文档，格式灵活，不需要预先定义格式\n字段的类型可以指定或者通过Elasticsearch自动推算 支持数组/支持嵌套 文档元数据\n​ 元数据，用于标注文档的相关信息：\n_index：文档所属的索引名 _type：文档所属的类型名 _id：文档唯—ld _source: 文档的原始Json数据 _version: 文档的版本号，修改删除操作_version都会自增1 _seq_no: 和_version一样，一旦数据发生更改，数据也一直是累计的。Shard级别严格递增，保证后写入的Doc的_seq_no大于先写入的Doc的_seq_no。 _primary_term: _primary_term主要是用来恢复数据时处理当多个文档的_seq_no一样时的冲突，避免Primary Shard上的写入被覆盖。每当Primary Shard发生重新分配时，比如重启，Primary选举等，_primary_term会递增1。 ElasticSearch索引操作 https://www.elastic.co/guide/en/elasticsearch/reference/7.17/index.html\n创建索引 索引命名必须小写，不能以下划线开头\n格式: PUT /索引名称\n​ #创建索引 PUT /es_db #创建索引时可以设置分片数和副本数 PUT /es_db { \u0026ldquo;settings\u0026rdquo; : { \u0026ldquo;number_of_shards\u0026rdquo; : 3, \u0026ldquo;number_of_replicas\u0026rdquo; : 2 } } #修改索引配置 PUT /es_db/_settings { \u0026ldquo;index\u0026rdquo; : { \u0026ldquo;number_of_replicas\u0026rdquo; : 1 } }\n​ 查询索引 格式: GET /索引名称\n​ #查询索引 GET /es_db #es_db是否存在 HEAD /es_db\n​ ​\n删除索引 格式: DELETE /索引名称\n​ DELETE /es_db\nElasticSearch文档操作 示例数据\nPUT /es_db { \u0026#34;settings\u0026#34; : { \u0026#34;index\u0026#34; : { \u0026#34;analysis.analyzer.default.type\u0026#34;: \u0026#34;ik_max_word\u0026#34; } } } PUT /es_db/_doc/1 { \u0026#34;name\u0026#34;: \u0026#34;张三\u0026#34;, \u0026#34;sex\u0026#34;: 1, \u0026#34;age\u0026#34;: 25, \u0026#34;address\u0026#34;: \u0026#34;广州天河公园\u0026#34;, \u0026#34;remark\u0026#34;: \u0026#34;java developer\u0026#34; } PUT /es_db/_doc/2 { \u0026#34;name\u0026#34;: \u0026#34;李四\u0026#34;, \u0026#34;sex\u0026#34;: 1, \u0026#34;age\u0026#34;: 28, \u0026#34;address\u0026#34;: \u0026#34;广州荔湾大厦\u0026#34;, \u0026#34;remark\u0026#34;: \u0026#34;java assistant\u0026#34; } PUT /es_db/_doc/3 { \u0026#34;name\u0026#34;: \u0026#34;王五\u0026#34;, \u0026#34;sex\u0026#34;: 0, \u0026#34;age\u0026#34;: 26, \u0026#34;address\u0026#34;: \u0026#34;广州白云山公园\u0026#34;, \u0026#34;remark\u0026#34;: \u0026#34;php developer\u0026#34; } PUT /es_db/_doc/4 { \u0026#34;name\u0026#34;: \u0026#34;赵六\u0026#34;, \u0026#34;sex\u0026#34;: 0, \u0026#34;age\u0026#34;: 22, \u0026#34;address\u0026#34;: \u0026#34;长沙橘子洲\u0026#34;, \u0026#34;remark\u0026#34;: \u0026#34;python assistant\u0026#34; } PUT /es_db/_doc/5 { \u0026#34;name\u0026#34;: \u0026#34;张龙\u0026#34;, \u0026#34;sex\u0026#34;: 0, \u0026#34;age\u0026#34;: 19, \u0026#34;address\u0026#34;: \u0026#34;长沙麓谷企业广场\u0026#34;, \u0026#34;remark\u0026#34;: \u0026#34;java architect assistant\u0026#34; }\tPUT /es_db/_doc/6 { \u0026#34;name\u0026#34;: \u0026#34;赵虎\u0026#34;, \u0026#34;sex\u0026#34;: 1, \u0026#34;age\u0026#34;: 32, \u0026#34;address\u0026#34;: \u0026#34;长沙麓谷兴工国际产业园\u0026#34;, \u0026#34;remark\u0026#34;: \u0026#34;java architect\u0026#34; }\t​\n添加（索引）文档 格式: [PUT | POST] /索引名称/[_doc | _create ]/id ​\n# 创建文档,指定id # 如果id不存在，创建新的文档，否则先删除现有文档，再创建新的文档，版本会增加 PUT /es_db/_doc/1 { \u0026#34;name\u0026#34;: \u0026#34;张三\u0026#34;, \u0026#34;sex\u0026#34;: 1, \u0026#34;age\u0026#34;: 25, \u0026#34;address\u0026#34;: \u0026#34;广州天河公园\u0026#34;, \u0026#34;remark\u0026#34;: \u0026#34;java developer\u0026#34; }\t#创建文档，ES生成id POST /es_db/_doc { \u0026#34;name\u0026#34;: \u0026#34;张三\u0026#34;, \u0026#34;sex\u0026#34;: 1, \u0026#34;age\u0026#34;: 25, \u0026#34;address\u0026#34;: \u0026#34;广州天河公园\u0026#34;, \u0026#34;remark\u0026#34;: \u0026#34;java developer\u0026#34; } ​\n​ 注意:POST和PUT都能起到创建/更新的作用，PUT需要对一个具体的资源进行操作也就是要确定id才能进行更新/创建，而POST是可以针对整个资源集合进行操作的，如果不写id就由ES生成一个唯一id进行创建新文档，如果填了id那就针对这个id的文档进行创建/更新\n​ Create -如果ID已经存在，会失败\n​ 修改文档 全量更新，整个json都会替换，格式: [PUT | POST] /索引名称/_doc/id 如果文档存在，现有文档会被删除，新的文档会被索引\n​\n# 全量更新，替换整个json PUT /es_db/_doc/1/ { \u0026#34;name\u0026#34;: \u0026#34;张三\u0026#34;, \u0026#34;sex\u0026#34;: 1, \u0026#34;age\u0026#34;: 25 } #查询文档 GET /es_db/_doc/1 ​\n​ 使用_update部分更新，格式: POST /索引名称/_update/id update不会删除原来的文档，而是实现真正的数据更新\n​\n# 部分更新：在原有文档上更新 # Update -文档必须已经存在，更新只会对相应字段做增量修改 POST /es_db/_update/1 { \u0026#34;doc\u0026#34;: { \u0026#34;age\u0026#34;: 28 } } #查询文档 GET /es_db/_doc/1 ​\n​ 使用 _update_by_query 更新文档 ​\nPOST /es_db/_update_by_query { \u0026#34;query\u0026#34;: { \u0026#34;match\u0026#34;: { \u0026#34;_id\u0026#34;: 1 } }, \u0026#34;script\u0026#34;: { \u0026#34;source\u0026#34;: \u0026#34;ctx._source.age = 30\u0026#34; } } ​\n​ 并发场景下修改文档 _seq_no和_primary_term是对_version的优化，7.X版本的ES默认使用这种方式控制版本，所以当在高并发环境下使用乐观锁机制修改文档时，要带上当前文档的_seq_no和_primary_term进行更新：\n​\nPOST /es_db/_doc/2?if_seq_no=21\u0026amp;if_primary_term=6 { \u0026#34;name\u0026#34;: \u0026#34;李四xxx\u0026#34; } 如果版本号不对，会抛出版本冲突异常，如下图：\n​ 查询文档 根据id查询文档，格式: GET /索引名称/_doc/id GET /es_db/_doc/1 条件查询 _search，格式： /索引名称/_doc/_search # 查询前10条文档 GET /es_db/_doc/_search ​\nES Search API提供了两种条件查询搜索方式：\nREST风格的请求URI，直接将参数带过去 封装到request body中，这种方式可以定义更加易读的JSON格式 ​\n#通过URI搜索，使用“q”指定查询字符串，“query string syntax” KV键值对 #条件查询, 如要查询age等于28岁的 _search?q=*:*** GET /es_db/_doc/_search?q=age:28 #范围查询, 如要查询age在25至26岁之间的 _search?q=***[** TO **] 注意: TO 必须为大写 GET /es_db/_doc/_search?q=age[25 TO 26] #查询年龄小于等于28岁的 :\u0026lt;= GET /es_db/_doc/_search?q=age:\u0026lt;=28 #查询年龄大于28前的 :\u0026gt; GET /es_db/_doc/_search?q=age:\u0026gt;28 #分页查询 from=*\u0026amp;size=* GET /es_db/_doc/_search?q=age[25 TO 26]\u0026amp;from=0\u0026amp;size=1 #对查询结果只输出某些字段 _source=字段,字段 GET /es_db/_doc/_search?_source=name,age #对查询结果排序 sort=字段:desc/asc GET /es_db/_doc/_search?sort=age:desc 通过请求体的搜索方式会在后面课程详细讲解（DSL）\n​\nGET /es_db/_search { \u0026#34;query\u0026#34;: { \u0026#34;match\u0026#34;: { \u0026#34;address\u0026#34;: \u0026#34;广州白云\u0026#34; } } } 删除文档 格式: DELETE /索引名称/_doc/id\nDELETE /es_db/_doc/1 ElasticSearch文档批量操作 批量操作可以减少网络连接所产生的开销，提升性能\n支持在一次API调用中，对不同的索引进行操作 可以在URI中指定Index，也可以在请求的Payload中进行 操作中单条操作失败，并不会影响其他操作 返回结果包括了每一条操作执行的结果 批量写入 批量对文档进行写操作是通过_bulk的API来实现的\n请求方式：POST\n请求地址：_bulk\n请求参数：通过_bulk操作文档，一般至少有两行参数(或偶数行参数)\n第一行参数为指定操作的类型及操作的对象(index,type和id) 第二行参数才是操作的数据 参数类似于：\n{\u0026#34;actionName\u0026#34;:{\u0026#34;_index\u0026#34;:\u0026#34;indexName\u0026#34;, \u0026#34;_type\u0026#34;:\u0026#34;typeName\u0026#34;,\u0026#34;_id\u0026#34;:\u0026#34;id\u0026#34;}} {\u0026#34;field1\u0026#34;:\u0026#34;value1\u0026#34;, \u0026#34;field2\u0026#34;:\u0026#34;value2\u0026#34;} actionName：表示操作类型，主要有create,index,delete和update 批量创建文档create\nPOST _bulk {\u0026#34;create\u0026#34;:{\u0026#34;_index\u0026#34;:\u0026#34;article\u0026#34;, \u0026#34;_type\u0026#34;:\u0026#34;_doc\u0026#34;, \u0026#34;_id\u0026#34;:3}} {\u0026#34;id\u0026#34;:3,\u0026#34;title\u0026#34;:\u0026#34;fox老师\u0026#34;,\u0026#34;content\u0026#34;:\u0026#34;fox老师666\u0026#34;,\u0026#34;tags\u0026#34;:[\u0026#34;java\u0026#34;, \u0026#34;面向对象\u0026#34;],\u0026#34;create_time\u0026#34;:1554015482530} {\u0026#34;create\u0026#34;:{\u0026#34;_index\u0026#34;:\u0026#34;article\u0026#34;, \u0026#34;_type\u0026#34;:\u0026#34;_doc\u0026#34;, \u0026#34;_id\u0026#34;:4}} {\u0026#34;id\u0026#34;:4,\u0026#34;title\u0026#34;:\u0026#34;mark老师\u0026#34;,\u0026#34;content\u0026#34;:\u0026#34;mark老师NB\u0026#34;,\u0026#34;tags\u0026#34;:[\u0026#34;java\u0026#34;, \u0026#34;面向对象\u0026#34;],\u0026#34;create_time\u0026#34;:1554015482530} 普通创建或全量替换index\nPOST _bulk {\u0026#34;index\u0026#34;:{\u0026#34;_index\u0026#34;:\u0026#34;article\u0026#34;, \u0026#34;_type\u0026#34;:\u0026#34;_doc\u0026#34;, \u0026#34;_id\u0026#34;:3}} {\u0026#34;id\u0026#34;:3,\u0026#34;title\u0026#34;:\u0026#34;图灵徐庶老师\u0026#34;,\u0026#34;content\u0026#34;:\u0026#34;图灵学院徐庶老师666\u0026#34;,\u0026#34;tags\u0026#34;:[\u0026#34;java\u0026#34;, \u0026#34;面向对象\u0026#34;],\u0026#34;create_time\u0026#34;:1554015482530} {\u0026#34;index\u0026#34;:{\u0026#34;_index\u0026#34;:\u0026#34;article\u0026#34;, \u0026#34;_type\u0026#34;:\u0026#34;_doc\u0026#34;, \u0026#34;_id\u0026#34;:4}} {\u0026#34;id\u0026#34;:4,\u0026#34;title\u0026#34;:\u0026#34;图灵诸葛老师\u0026#34;,\u0026#34;content\u0026#34;:\u0026#34;图灵学院诸葛老师NB\u0026#34;,\u0026#34;tags\u0026#34;:[\u0026#34;java\u0026#34;, \u0026#34;面向对象\u0026#34;],\u0026#34;create_time\u0026#34;:1554015482530} 如果原文档不存在，则是创建 如果原文档存在，则是替换(全量修改原文档) 批量删除delete\n​\nPOST _bulk {\u0026#34;delete\u0026#34;:{\u0026#34;_index\u0026#34;:\u0026#34;article\u0026#34;, \u0026#34;_type\u0026#34;:\u0026#34;_doc\u0026#34;, \u0026#34;_id\u0026#34;:3}} {\u0026#34;delete\u0026#34;:{\u0026#34;_index\u0026#34;:\u0026#34;article\u0026#34;, \u0026#34;_type\u0026#34;:\u0026#34;_doc\u0026#34;, \u0026#34;_id\u0026#34;:4}} 批量修改update\n​\nPOST _bulk {\u0026#34;update\u0026#34;:{\u0026#34;_index\u0026#34;:\u0026#34;article\u0026#34;, \u0026#34;_type\u0026#34;:\u0026#34;_doc\u0026#34;, \u0026#34;_id\u0026#34;:3}} {\u0026#34;doc\u0026#34;:{\u0026#34;title\u0026#34;:\u0026#34;ES大法必修内功\u0026#34;}} {\u0026#34;update\u0026#34;:{\u0026#34;_index\u0026#34;:\u0026#34;article\u0026#34;, \u0026#34;_type\u0026#34;:\u0026#34;_doc\u0026#34;, \u0026#34;_id\u0026#34;:4}} {\u0026#34;doc\u0026#34;:{\u0026#34;create_time\u0026#34;:1554018421008}} 组合应用\n​\nPOST _bulk {\u0026#34;create\u0026#34;:{\u0026#34;_index\u0026#34;:\u0026#34;article\u0026#34;, \u0026#34;_type\u0026#34;:\u0026#34;_doc\u0026#34;, \u0026#34;_id\u0026#34;:3}} {\u0026#34;id\u0026#34;:3,\u0026#34;title\u0026#34;:\u0026#34;fox老师\u0026#34;,\u0026#34;content\u0026#34;:\u0026#34;fox老师666\u0026#34;,\u0026#34;tags\u0026#34;:[\u0026#34;java\u0026#34;, \u0026#34;面向对象\u0026#34;],\u0026#34;create_time\u0026#34;:1554015482530} {\u0026#34;delete\u0026#34;:{\u0026#34;_index\u0026#34;:\u0026#34;article\u0026#34;, \u0026#34;_type\u0026#34;:\u0026#34;_doc\u0026#34;, \u0026#34;_id\u0026#34;:3}} {\u0026#34;update\u0026#34;:{\u0026#34;_index\u0026#34;:\u0026#34;article\u0026#34;, \u0026#34;_type\u0026#34;:\u0026#34;_doc\u0026#34;, \u0026#34;_id\u0026#34;:4}} {\u0026#34;doc\u0026#34;:{\u0026#34;create_time\u0026#34;:1554018421008}} 批量读取 es的批量查询可以使用mget和msearch两种。其中mget是需要我们知道它的id，可以指定不同的index，也可以指定返回值source。msearch可以通过字段查询来进行一个批量的查找。\n_mget\n​\n#可以通过ID批量获取不同index和type的数据 GET _mget { \u0026#34;docs\u0026#34;: [ { \u0026#34;_index\u0026#34;: \u0026#34;es_db\u0026#34;, \u0026#34;_id\u0026#34;: 1 }, { \u0026#34;_index\u0026#34;: \u0026#34;article\u0026#34;, \u0026#34;_id\u0026#34;: 4 } ] } #可以通过ID批量获取es_db的数据 GET /es_db/_mget { \u0026#34;docs\u0026#34;: [ { \u0026#34;_id\u0026#34;: 1 }, { \u0026#34;_id\u0026#34;: 4 } ] } #简化后 GET /es_db/_mget { \u0026#34;ids\u0026#34;:[\u0026#34;1\u0026#34;,\u0026#34;2\u0026#34;] } ​\n​ _msearch\n在_msearch中，请求格式和bulk类似。查询一条数据需要两个对象，第一个设置index和type，第二个设置查询语句。查询语句和search相同。如果只是查询一个index，我们可以在url中带上index，这样，如果查该index可以直接用空对象表示。\n​\nGET /es_db/_msearch {} {\u0026#34;query\u0026#34; : {\u0026#34;match_all\u0026#34; : {}}, \u0026#34;from\u0026#34; : 0, \u0026#34;size\u0026#34; : 2} {\u0026#34;index\u0026#34; : \u0026#34;article\u0026#34;} {\u0026#34;query\u0026#34; : {\u0026#34;match_all\u0026#34; : {}}} ​ Logstash与FileBeat详解以及ELK整合 链接：http://note.youdao.com/noteshare?id=cd88d72a1c76d18efcf7fe767e8c2d20\u0026amp;sub=D7819084A43243FFA52E8A8741795414\n背景 日志管理的挑战：\n关注点很多，任何一个点都有可能引起问题 日志分散在很多机器，出了问题时，才发现日志被删了 很多运维人员是消防员，哪里有问题去哪里 ​ 集中化日志管理思路：\n日志收集 ——》格式化分析 ——》检索和可视化 ——》 风险告警\nELK架构 ELK架构分为两种，一种是经典的ELK，另外一种是加上消息队列（Redis或Kafka或RabbitMQ）和Nginx结构。\n经典的ELK 经典的ELK主要是由Filebeat + Logstash + Elasticsearch + Kibana组成，如下图：（早期的ELK只有Logstash + Elasticsearch + Kibana）\n​ 此架构主要适用于数据量小的开发环境，存在数据丢失的危险。\n整合消息队列+Nginx架构 这种架构，主要加上了Redis或Kafka或RabbitMQ做消息队列，保证了消息的不丢失。\n​ 此种架构，主要用在生产环境，可以处理大数据量，并且不会丢失数据。\n什么是Logstash Logstash 是免费且开放的服务器端数据处理管道，能够从多个来源采集数据，转换数据，然后将数据发送到您最喜欢的存储库中。\nhttps://www.elastic.co/cn/logstash/\n应用：ETL工具 / 数据采集处理引擎\n​ Logstash核心概念 Pipeline\n包含了input—filter-output三个阶段的处理流程 插件生命周期管理 队列管理 Logstash Event\n数据在内部流转时的具体表现形式。数据在input 阶段被转换为Event，在 output被转化成目标格式数据 Event 其实是一个Java Object，在配置文件中，对Event 的属性进行增删改查 Codec (Code / Decode)\n将原始数据decode成Event;将Event encode成目标数据\n​ Logstash数据传输原理 数据采集与输入：Logstash支持各种输入选择，能够以连续的流式传输方式，轻松地从日志、指标、Web应用以及数据存储中采集数据。 实时解析和数据转换：通过Logstash过滤器解析各个事件，识别已命名的字段来构建结构，并将它们转换成通用格式，最终将数据从源端传输到存储库中。 存储与数据导出：Logstash提供多种输出选择，可以将数据发送到指定的地方。 Logstash通过管道完成数据的采集与处理，管道配置中包含input、output和filter（可选）插件，input和output用来配置输入和输出数据源、filter用来对数据进行过滤或预处理。\n​ Logstash配置文件结构 参考：https://www.elastic.co/guide/en/logstash/7.17/configuration.html\nLogstash的管道配置文件对每种类型的插件都提供了一个单独的配置部分，用于处理管道事件。\ninput { stdin { } } filter { grok { match =\u0026gt; { \u0026#34;message\u0026#34; =\u0026gt; \u0026#34;%{COMBINEDAPACHELOG}\u0026#34; } } date { match =\u0026gt; [ \u0026#34;timestamp\u0026#34; , \u0026#34;dd/MMM/yyyy:HH:mm:ss Z\u0026#34; ] } } output { elasticsearch { hosts =\u0026gt; [\u0026#34;localhost:9200\u0026#34;]} stdout { codec =\u0026gt; rubydebug } } 每个配置部分可以包含一个或多个插件。例如，指定多个filter插件，Logstash会按照它们在配置文件中出现的顺序进行处理。\n#运行 bin/logstash -f logstash-demo.conf Input Plugins\nhttps://www.elastic.co/guide/en/logstash/7.17/input-plugins.html\n一个 Pipeline可以有多个input插件\nStdin / File\nBeats / Log4J /Elasticsearch / JDBC / Kafka /Rabbitmq /Redis\nJMX/ HTTP / Websocket / UDP / TCP\nGoogle Cloud Storage / S3\nGithub / Twitter\nOutput Plugins\nhttps://www.elastic.co/guide/en/logstash/7.17/output-plugins.html\n将Event发送到特定的目的地，是 Pipeline 的最后一个阶段。\n常见 Output Plugins：\nElasticsearch Email / Pageduty Influxdb / Kafka / Mongodb / Opentsdb / Zabbix Http / TCP / Websocket Filter Plugins\nhttps://www.elastic.co/guide/en/logstash/7.17/filter-plugins.html\n处理Event\n内置的Filter Plugins:\nMutate 一操作Event的字段 Metrics — Aggregate metrics Ruby 一执行Ruby 代码 Codec Plugins\nhttps://www.elastic.co/guide/en/logstash/7.17/codec-plugins.html\n将原始数据decode成Event;将Event encode成目标数据\n内置的Codec Plugins:\nLine / Multiline JSON / Avro / Cef (ArcSight Common Event Format) Dots / Rubydebug Logstash Queue In Memory Queue 进程Crash，机器宕机，都会引起数据的丢失\nPersistent Queue 机器宕机，数据也不会丢失; 数据保证会被消费; 可以替代 Kafka等消息队列缓冲区的作用\nqueue.type: persisted (默认是memory) queue.max_bytes: 4gb ​ Logstash安装 logstash官方文档: https://www.elastic.co/guide/en/logstash/7.17/installing-logstash.html\n1）下载并解压logstash 下载地址： https://www.elastic.co/cn/downloads/past-releases#logstash\n选择版本：7.17.3\n​ 2）测试：运行最基本的logstash管道 ​\ncd logstash-7.17.3 #linux #-e选项表示，直接把配置放在命令中，这样可以有效快速进行测试 bin/logstash -e \u0026#39;input { stdin { } } output { stdout {} }\u0026#39; #windows .\\bin\\logstash.bat -e \u0026#34;input { stdin { } } output { stdout {} }\u0026#34; ​\n测试结果：\n​ window版本的logstash-7.17.3的bug:\nwindows出现错误提示could not find java; set JAVA_HOME or ensure java is in PATH\n​ 修改setup.bat\n​ ​ Codec Plugin测试\n# single line bin/logstash -e \u0026#34;input{stdin{codec=\u0026gt;line}}output{stdout{codec=\u0026gt; rubydebug}}\u0026#34; bin/logstash -e \u0026#34;input{stdin{codec=\u0026gt;json}}output{stdout{codec=\u0026gt; rubydebug}}\u0026#34; ​\nCodec Plugin —— Multiline\n设置参数:\npattern: 设置行匹配的正则表达式\nwhat : 如果匹配成功，那么匹配行属于上一个事件还是下一个事件\nprevious / next negate : 是否对pattern结果取反\ntrue / false ​\n# 多行数据，异常 Exception in thread \u0026#34;main\u0026#34; java.lang.NullPointerException at com.example.myproject.Book.getTitle(Book.java:16) at com.example.myproject.Author.getBookTitles(Author.java:25) at com.example.myproject.Bootstrap.main(Bootstrap.java:14) # multiline-exception.conf input { stdin { codec =\u0026gt; multiline { pattern =\u0026gt; \u0026#34;^\\s\u0026#34; what =\u0026gt; \u0026#34;previous\u0026#34; } } } filter {} output { stdout { codec =\u0026gt; rubydebug } } #执行管道 bin/logstash -f multiline-exception.conf Input Plugin —— File\n支持从文件中读取数据，如日志文件 文件读取需要解决的问题：只被读取一次。重启后需要从上次读取的位置继续(通过sincedb 实现) 读取到文件新内容，发现新文件 文件发生归档操作(文档位置发生变化，日志rotation)，不能影响当前的内容读取 Filter Plugin\nFilter Plugin可以对Logstash Event进行各种处理，例如解析，删除字段，类型转换\nDate: 日期解析 Dissect: 分割符解析 Grok: 正则匹配解析 Mutate: 处理字段。重命名，删除，替换 Ruby: 利用Ruby 代码来动态修改Event Filter Plugin - Mutate\n对字段做各种操作:\nConvert : 类型转换 Gsub : 字符串替换 Split / Join /Merge: 字符串切割，数组合并字符串，数组合并数组 Rename: 字段重命名 Update / Replace: 字段内容更新替换 Remove_field: 字段删除 Logstash导入数据到ES 1）测试数据集下载：https://grouplens.org/datasets/movielens/\n​ 2）准备logstash-movie.conf配置文件\ninput { file { path =\u0026gt; \u0026#34;/home/es/logstash-7.17.3/dataset/movies.csv\u0026#34; start_position =\u0026gt; \u0026#34;beginning\u0026#34; sincedb_path =\u0026gt; \u0026#34;/dev/null\u0026#34; } } filter { csv { separator =\u0026gt; \u0026#34;,\u0026#34; columns =\u0026gt; [\u0026#34;id\u0026#34;,\u0026#34;content\u0026#34;,\u0026#34;genre\u0026#34;] } mutate { split =\u0026gt; { \u0026#34;genre\u0026#34; =\u0026gt; \u0026#34;|\u0026#34; } remove_field =\u0026gt; [\u0026#34;path\u0026#34;, \u0026#34;host\u0026#34;,\u0026#34;@timestamp\u0026#34;,\u0026#34;message\u0026#34;] } mutate { split =\u0026gt; [\u0026#34;content\u0026#34;, \u0026#34;(\u0026#34;] add_field =\u0026gt; { \u0026#34;title\u0026#34; =\u0026gt; \u0026#34;%{[content][0]}\u0026#34;} add_field =\u0026gt; { \u0026#34;year\u0026#34; =\u0026gt; \u0026#34;%{[content][1]}\u0026#34;} } mutate { convert =\u0026gt; { \u0026#34;year\u0026#34; =\u0026gt; \u0026#34;integer\u0026#34; } strip =\u0026gt; [\u0026#34;title\u0026#34;] remove_field =\u0026gt; [\u0026#34;path\u0026#34;, \u0026#34;host\u0026#34;,\u0026#34;@timestamp\u0026#34;,\u0026#34;message\u0026#34;,\u0026#34;content\u0026#34;] } } output { elasticsearch { hosts =\u0026gt; \u0026#34;http://localhost:9200\u0026#34; index =\u0026gt; \u0026#34;movies\u0026#34; document_id =\u0026gt; \u0026#34;%{id}\u0026#34; user =\u0026gt; \u0026#34;elastic\u0026#34; password =\u0026gt; \u0026#34;123456\u0026#34; } stdout {} } ​\n3）运行logstash\n​\n# linux bin/logstash -f logstash-movie.conf ​\n同步数据库数据到Elasticsearch 需求: 将数据库中的数据同步到ES，借助ES的全文搜索,提高搜索速度\n需要把新增用户信息同步到Elasticsearch中 用户信息Update 后，需要能被更新到Elasticsearch 支持增量更新 用户注销后，不能被ES所搜索到 实现思路\n基于canal同步数据（项目实战中讲解）\n借助JDBC Input Plugin将数据从数据库读到Logstash\n需要自己提供所需的 JDBC Driver； JDBC Input Plugin 支持定时任务 Scheduling，其语法来自 Rufus-scheduler，其扩展了 Cron，使用 Cron 的语法可以完成任务的触发； JDBC Input Plugin 支持通过 Tracking_column / sql_last_value 的方式记录 State，最终实现增量的更新； https://www.elastic.co/cn/blog/logstash-jdbc-input-plugin JDBC Input Plugin实现步骤\n1）拷贝jdbc依赖到logstash-7.17.3/drivers目录下\n2）准备mysql-demo.conf配置文件\ninput { jdbc { jdbc_driver_library =\u0026gt; \u0026#34;/home/es/logstash-7.17.3/drivers/mysql-connector-java-5.1.49.jar\u0026#34; jdbc_driver_class =\u0026gt; \u0026#34;com.mysql.jdbc.Driver\u0026#34; jdbc_connection_string =\u0026gt; \u0026#34;jdbc:mysql://localhost:3306/test?useSSL=false\u0026#34; jdbc_user =\u0026gt; \u0026#34;root\u0026#34; jdbc_password =\u0026gt; \u0026#34;123456\u0026#34; #启用追踪，如果为true，则需要指定tracking_column use_column_value =\u0026gt; true #指定追踪的字段， tracking_column =\u0026gt; \u0026#34;last_updated\u0026#34; #追踪字段的类型，目前只有数字(numeric)和时间类型(timestamp)，默认是数字类型 tracking_column_type =\u0026gt; \u0026#34;numeric\u0026#34; #记录最后一次运行的结果 record_last_run =\u0026gt; true #上面运行结果的保存位置 last_run_metadata_path =\u0026gt; \u0026#34;jdbc-position.txt\u0026#34; statement =\u0026gt; \u0026#34;SELECT * FROM user where last_updated \u0026gt;:sql_last_value;\u0026#34; schedule =\u0026gt; \u0026#34; * * * * * *\u0026#34; } } output { elasticsearch { document_id =\u0026gt; \u0026#34;%{id}\u0026#34; document_type =\u0026gt; \u0026#34;_doc\u0026#34; index =\u0026gt; \u0026#34;users\u0026#34; hosts =\u0026gt; [\u0026#34;http://localhost:9200\u0026#34;] user =\u0026gt; \u0026#34;elastic\u0026#34; password =\u0026gt; \u0026#34;123456\u0026#34; } stdout{ codec =\u0026gt; rubydebug } } 3）运行logstash\nbin/logstash -f mysql-demo.conf 测试\n#user表 CREATE TABLE `user` ( `id` int NOT NULL AUTO_INCREMENT, `name` varchar(50) DEFAULT NULL, `address` varchar(50) CHARACTER DEFAULT NULL, `last_updated` bigint DEFAULT NULL, `is_deleted` int DEFAULT NULL, PRIMARY KEY (`id`) ) ENGINE=InnoDB AUTO_INCREMENT=2 DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_0900_ai_ci; #插入数据 INSERT INTO user(name,address,last_updated,is_deleted) VALUES(\u0026#34;张三\u0026#34;,\u0026#34;广州天河\u0026#34;,unix_timestamp(NOW()),0) ​ # 更新 update user set address=\u0026#34;广州白云山\u0026#34;,last_updated=unix_timestamp(NOW()) where name=\u0026#34;张三\u0026#34; ​\n​ #删除 update user set is_deleted=1,last_updated=unix_timestamp(NOW()) where name=\u0026#34;张三\u0026#34; ​ #ES中查询 # 创建 alias，只显示没有被标记 deleted的用户 POST /_aliases { \u0026#34;actions\u0026#34;: [ { \u0026#34;add\u0026#34;: { \u0026#34;index\u0026#34;: \u0026#34;users\u0026#34;, \u0026#34;alias\u0026#34;: \u0026#34;view_users\u0026#34;, \u0026#34;filter\u0026#34; : { \u0026#34;term\u0026#34; : { \u0026#34;is_deleted\u0026#34; : 0} } } } ] } # 通过 Alias查询，查不到被标记成 deleted的用户 POST view_users/_search POST view_users/_search { \u0026#34;query\u0026#34;: { \u0026#34;term\u0026#34;: { \u0026#34;name.keyword\u0026#34;: { \u0026#34;value\u0026#34;: \u0026#34;张三\u0026#34; } } } } ​\n什么是Beats 轻量型数据采集器，文档地址： https://www.elastic.co/guide/en/beats/libbeat/7.17/index.html\nBeats 是一个免费且开放的平台，集合了多种单一用途的数据采集器。它们从成百上千或成千上万台机器和系统向 Logstash 或 Elasticsearch 发送数据。\n​ FileBeat简介 FileBeat专门用于转发和收集日志数据的轻量级采集工具。它可以作为代理安装在服务器上，FileBeat监视指定路径的日志文件，收集日志数据，并将收集到的日志转发到Elasticsearch或者Logstash。\nFileBeat的工作原理 启动FileBeat时，会启动一个或者多个输入（Input），这些Input监控指定的日志数据位置。FileBeat会针对每一个文件启动一个Harvester（收割机）。Harvester读取每一个文件的日志，将新的日志发送到libbeat，libbeat将数据收集到一起，并将数据发送给输出（Output）。\n​ logstash vs FileBeat Logstash是在jvm上运行的，资源消耗比较大。而FileBeat是基于golang编写的，功能较少但资源消耗也比较小，更轻量级。 Logstash 和Filebeat都具有日志收集功能，Filebeat更轻量，占用资源更少 Logstash 具有Filter功能，能过滤分析日志 一般结构都是Filebeat采集日志，然后发送到消息队列、Redis、MQ中，然后Logstash去获取，利用Filter功能过滤分析，然后存储到Elasticsearch中 FileBeat和Logstash配合，实现背压机制。当将数据发送到Logstash或 Elasticsearch时，Filebeat使用背压敏感协议，以应对更多的数据量。如果Logstash正在忙于处理数据，则会告诉Filebeat 减慢读取速度。一旦拥堵得到解决，Filebeat就会恢复到原来的步伐并继续传输数据。 Filebeat安装 https://www.elastic.co/guide/en/beats/filebeat/7.17/filebeat-installation-configuration.html\n1）下载并解压Filebeat\n下载地址：https://www.elastic.co/cn/downloads/past-releases#filebeat\n选择版本：7.17.3\n​ 2）编辑配置\n修改 filebeat.yml 以设置连接信息：\n​\noutput.elasticsearch: hosts: [\u0026#34;192.168.65.174:9200\u0026#34;,\u0026#34;192.168.65.192:9200\u0026#34;,\u0026#34;192.168.65.204:9200\u0026#34;] username: \u0026#34;elastic\u0026#34; password: \u0026#34;123456\u0026#34; setup.kibana: host: \u0026#34;192.168.65.174:5601\u0026#34; ​\n3) 启用和配置数据收集模块\n从安装目录中，运行：\n# 查看可以模块列表 ./filebeat modules list #启用nginx模块 ./filebeat modules enable nginx #如果需要更改nginx日志路径,修改modules.d/nginx.yml - module: nginx access: var.paths: [\u0026#34;/var/log/nginx/access.log*\u0026#34;] #启用 Logstash 模块 ./filebeat modules enable logstash #在 modules.d/logstash.yml 文件中修改设置 - module: logstash log: enabled: true var.paths: [\u0026#34;/home/es/logstash-7.17.3/logs/*.log\u0026#34;] 4）启动 Filebeat\n# setup命令加载Kibana仪表板。 如果仪表板已经设置，则忽略此命令。 ./filebeat setup # 启动Filebeat ./filebeat -e ELK整合实战 案例：采集tomcat服务器日志 Tomcat服务器运行过程中产生很多日志信息，通过Logstash采集并存储日志信息至ElasticSearch中\n使用FileBeats将日志发送到Logstash 1）创建配置文件filebeat-logstash.yml，配置FileBeats将数据发送到Logstash\nvim filebeat-logstash.yml chmod 644 filebeat-logstash.yml #因为Tomcat的web log日志都是以IP地址开头的，所以我们需要修改下匹配字段。 # 不以ip地址开头的行追加到上一行 filebeat.inputs: - type: log enabled: true paths: - /home/es/apache-tomcat-8.5.33/logs/*access*.* multiline.pattern: \u0026#39;^\\\\d+\\\\.\\\\d+\\\\.\\\\d+\\\\.\\\\d+ \u0026#39; multiline.negate: true multiline.match: after output.logstash: enabled: true hosts: [\u0026#34;192.168.65.204:5044\u0026#34;] ​\npattern：正则表达式 negate：true 或 false；默认是false，匹配pattern的行合并到上一行；true，不匹配pattern的行合并到上一行 match：after 或 before，合并到上一行的末尾或开头 2）启动FileBeat，并指定使用指定的配置文件\n./filebeat -e -c filebeat-logstash.yml 可能出现的异常：\n异常1：Exiting: error loading config file: config file (\u0026ldquo;filebeat-logstash.yml\u0026rdquo;) can only be writable by the owner but the permissions are \u0026ldquo;-rw-rw-r\u0026ndash;\u0026rdquo; (to fix the permissions use: \u0026lsquo;chmod go-w /home/es/filebeat-7.17.3-linux-x86_64/filebeat-logstash.yml\u0026rsquo;)\n因为安全原因不要其他用户写的权限，去掉写的权限就可以了\n​ chmod 644 filebeat-logstash.yml\n异常2：Failed to connect to backoff(async(tcp://192.168.65.204:5044)): dial tcp 192.168.65.204:5044: connect: connection refused\nFileBeat将尝试建立与Logstash监听的IP和端口号进行连接。但此时，我们并没有开启并配置Logstash，所以FileBeat是无法连接到Logstash的。\n配置Logstash接收FileBeat收集的数据并打印 vim config/filebeat-console.conf # 配置从FileBeat接收数据 input { beats { port =\u0026gt; 5044 } } output { stdout { codec =\u0026gt; rubydebug } } 测试logstash配置是否正确\nbin/logstash -f config/filebeat-console.conf --config.test_and_exit 启动logstash\n# reload.automatic：修改配置文件时自动重新加载 bin/logstash -f config/filebeat-console.conf --config.reload.automatic ​\n测试访问tomcat，logstash是否接收到了Filebeat传过来的tomcat日志\nLogstash输出数据到Elasticsearch 如果我们需要将数据输出值ES而不是控制台的话，我们修改Logstash的output配置。\nvim config/filebeat-elasticSearch.conf input { beats { port =\u0026gt; 5044 } } output { elasticsearch { hosts =\u0026gt; [\u0026#34;http://localhost:9200\u0026#34;] user =\u0026gt; \u0026#34;elastic\u0026#34; password =\u0026gt; \u0026#34;123456\u0026#34; } stdout{ codec =\u0026gt; rubydebug } } 启动logstash\nbin/logstash -f config/filebeat-elasticSearch.conf --config.reload.automatic ​\nES中会生成一个以logstash开头的索引，测试日志是否保存到了ES。\n思考：日志信息都保证在message字段中，是否可以把日志进行解析一个个的字段？例如：IP字段、时间、请求方式、请求URL、响应结果。\n利用Logstash过滤器解析日志 从日志文件中收集到的数据包含了很多有效信息，比如IP、时间等，在Logstash中可以配置过滤器Filter对采集到的数据进行过滤处理，Logstash中有大量的插件可以供我们使用。\n#查看Logstash已经安装的插件 bin/logstash-plugin list Grok插件\nGrok是一种将非结构化日志解析为结构化的插件。这个工具非常适合用来解析系统日志、Web服务器日志、MySQL或者是任意其他的日志格式。\nhttps://www.elastic.co/guide/en/logstash/7.17/plugins-filters-grok.html\nGrok语法\nGrok是通过模式匹配的方式来识别日志中的数据,可以把Grok插件简单理解为升级版本的正则表达式。它拥有更多的模式，默认Logstash拥有120个模式。如果这些模式不满足我们解析日志的需求，我们可以直接使用正则表达式来进行匹配。\ngrok模式的语法是：\n%{SYNTAX:SEMANTIC} SYNTAX（语法）指的是Grok模式名称，SEMANTIC（语义）是给模式匹配到的文本字段名。例如：\n%{NUMBER:duration} %{IP:client} duration表示：匹配一个数字，client表示匹配一个IP地址。 默认在Grok中，所有匹配到的的数据类型都是字符串，如果要转换成int类型（目前只支持int和float），可以这样：%{NUMBER:duration:int} %{IP:client}\n常用的Grok模式\nhttps://help.aliyun.com/document_detail/129387.html?scm=20140722.184.2.173\n用法\nfilter { grok { match =\u0026gt; { \u0026#34;message\u0026#34; =\u0026gt; \u0026#34;%{IP:client} %{WORD:method} %{URIPATHPARAM:request} %{NUMBER:bytes} %{NUMBER:duration}\u0026#34; } } } 比如，tomacat日志\n192.168.65.103 - - [23/Jun/2022:22:37:23 +0800] \u0026#34;GET /docs/images/docs-stylesheet.css HTTP/1.1\u0026#34; 200 5780 解析后的字段\n字段名 说明 client IP 浏览器端IP timestamp 请求的时间戳 method 请求方式（GET/POST） uri 请求的链接地址 status 服务器端响应状态 length 响应的数据长度 grok模式\n​\n%{IP:ip} - - \\[%{HTTPDATE:date}\\] \\\u0026#34;%{WORD:method} %{PATH:uri} %{DATA:protocol}\\\u0026#34; %{INT:status} %{INT:length} ​\n为了方便测试，我们可以使用Kibana来进行Grok开发：\n​ 修改Logstash配置文件\nvim config/filebeat-console.conf input { beats { port =\u0026gt; 5044 } } filter { grok { match =\u0026gt; { \u0026#34;message\u0026#34; =\u0026gt; \u0026#34;%{IP:ip} - - \\[%{HTTPDATE:date}\\] \\\u0026#34;%{WORD:method} %{PATH:uri} %{DATA:protocol}\\\u0026#34; %{INT:status:int} %{INT:length:int}\u0026#34; } } } output { stdout { codec =\u0026gt; rubydebug } } 启动logstash测试\nbin/logstash -f config/filebeat-console.conf --config.reload.automatic 使用mutate插件过滤掉不需要的字段\nmutate { enable_metric =\u0026gt; \u0026#34;false\u0026#34; remove_field =\u0026gt; [\u0026#34;message\u0026#34;, \u0026#34;log\u0026#34;, \u0026#34;tags\u0026#34;, \u0026#34;input\u0026#34;, \u0026#34;agent\u0026#34;, \u0026#34;host\u0026#34;, \u0026#34;ecs\u0026#34;, \u0026#34;@version\u0026#34;] } 要将日期格式进行转换，我们可以使用Date插件来实现。该插件专门用来解析字段中的日期，官方说明文档：https://www.elastic.co/guide/en/logstash/7.17/plugins-filters-date.html\n用法如下：\n​ 将date字段转换为「年月日 时分秒」格式。默认字段经过date插件处理后，会输出到@timestamp字段，所以，我们可以通过修改target属性来重新定义输出字段。\ndate { match =\u0026gt; [\u0026#34;date\u0026#34;,\u0026#34;dd/MMM/yyyy:HH:mm:ss Z\u0026#34;,\u0026#34;yyyy-MM-dd HH:mm:ss\u0026#34;] target =\u0026gt; \u0026#34;date\u0026#34; } ​\n输出到Elasticsearch指定索引 index来指定索引名称，默认输出的index名称为：logstash-%{+yyyy.MM.dd}。但注意，要在index中使用时间格式化，filter的输出必须包含 @timestamp字段，否则将无法解析日期。\noutput { elasticsearch { index =\u0026gt; \u0026#34;tomcat_web_log_%{+YYYY-MM}\u0026#34; hosts =\u0026gt; [\u0026#34;http://localhost:9200\u0026#34;] user =\u0026gt; \u0026#34;elastic\u0026#34; password =\u0026gt; \u0026#34;123456\u0026#34; } stdout{ codec =\u0026gt; rubydebug } } 注意：index名称中，不能出现大写字符\n完整的Logstash配置文件\nvim config/filebeat-filter-es.conf input { beats { port =\u0026gt; 5044 } } filter { grok { match =\u0026gt; { \u0026#34;message\u0026#34; =\u0026gt; \u0026#34;%{IP:ip} - - \\[%{HTTPDATE:date}\\] \\\u0026#34;%{WORD:method} %{PATH:uri} %{DATA:protocol}\\\u0026#34; %{INT:status:int} %{INT:length:int}\u0026#34; } } mutate { enable_metric =\u0026gt; \u0026#34;false\u0026#34; remove_field =\u0026gt; [\u0026#34;message\u0026#34;, \u0026#34;log\u0026#34;, \u0026#34;tags\u0026#34;, \u0026#34;input\u0026#34;, \u0026#34;agent\u0026#34;, \u0026#34;host\u0026#34;, \u0026#34;ecs\u0026#34;, \u0026#34;@version\u0026#34;] } date { match =\u0026gt; [\u0026#34;date\u0026#34;,\u0026#34;dd/MMM/yyyy:HH:mm:ss Z\u0026#34;,\u0026#34;yyyy-MM-dd HH:mm:ss\u0026#34;] target =\u0026gt; \u0026#34;date\u0026#34; } } output { stdout { codec =\u0026gt; rubydebug } elasticsearch { index =\u0026gt; \u0026#34;tomcat_web_log_%{+YYYY-MM}\u0026#34; hosts =\u0026gt; [\u0026#34;http://localhost:9200\u0026#34;] user =\u0026gt; \u0026#34;elastic\u0026#34; password =\u0026gt; \u0026#34;123456\u0026#34; } } 启动logstash\nbin/logstash -f config/filebeat-filter-es.conf --config.reload.automatic input { redis { host=\u0026gt; \u0026#34;localhost\u0026#34; port =\u0026gt; \u0026#34;6379\u0026#34; password =\u0026gt; \u0026#34;9ed99d6b\u0026#34; key =\u0026gt; \u0026#34;filebeat\u0026#34; type =\u0026gt; \u0026#34;redis-input\u0026#34; data_type =\u0026gt; \u0026#34;list\u0026#34; threads =\u0026gt;4 batch_count =\u0026gt; 10 db =\u0026gt; 0 } } filter { } output { elasticsearch { hosts =\u0026gt; \u0026#34;http://cqzwy-mgmt-log-platform-grc055ce-0.cqzwy-mgmt-log-platform-grc055ce.013497775a1b4580924a00009a20c887.svc.cluster.local:9200\u0026#34; index =\u0026gt; \u0026#34;netlog\u0026#34; user =\u0026gt; \u0026#34;elastic\u0026#34; password =\u0026gt; \u0026#34;kuGmFNENeZyYuGkYZ4BU\u0026#34; } } logstash 问题处理\nhttps://blog.csdn.net/King_weng/article/details/106506996\nELFK整合实战2 filebeat =\u0026gt; redis =\u0026gt; logstash =\u0026gt; elasticsearch =\u0026gt; kinbana\nfilebeat的配置 filebeat.yml\nfilebeat.inputs: - type: filestream paths: - /var/log/data/10.42.76.202/*.log - /var/log/data/10.42.76.201/*.log - /var/log/data/10.42.76.204/*.log encoding: gbk # 对非utf-8的数据进行转码 ignore_older: 5m #只采集5分钟内更新的文件 - type: filestream paths: - /var/log/data/10.42.76.206/*.log - /var/log/data/10.42.76.207/*.log ignore_older: 5m output.redis: hosts: [\u0026#34;10.43.152.65:6379\u0026#34;] password: \u0026#34;9ed99d6b\u0026#34; key: \u0026#34;filebeat\u0026#34; db: 0 timeout: 5 filebeat 启动命令\nnohup ./filebeat -e -c filebeat.yml \u0026gt;/dev/null \u0026amp; logstash的配置 logstash_run.yml\ninput { redis { host=\u0026gt; \u0026#34;localhost\u0026#34; port =\u0026gt; \u0026#34;6379\u0026#34; password =\u0026gt; \u0026#34;9ed99d6b\u0026#34; key =\u0026gt; \u0026#34;filebeat\u0026#34; # 对应redis中的key名称 type =\u0026gt; \u0026#34;redis-input\u0026#34; data_type =\u0026gt; \u0026#34;list\u0026#34; # key的类型 threads =\u0026gt;4 batch_count =\u0026gt; 10 db =\u0026gt; 0 } } filter { } output { elasticsearch { hosts =\u0026gt; \u0026#34;http://cqzwy-mgmt-log-platform-grc055ce-0.cqzwy-mgmt-log-platform-grc055ce.013497775a1b4580924a00009a20c887.svc.cluster.local:9200\u0026#34; index =\u0026gt; \u0026#34;netlog\u0026#34; # 在es中的索引名称 user =\u0026gt; \u0026#34;elastic\u0026#34; password =\u0026gt; \u0026#34;kuGmFNENeZyYuGkYZ4BU\u0026#34; } } 通过jvm.options文件修改jvm参数\n制作logstash镜像(可选) start.sh启动脚本\n#!/bin/bash # -f 后指定的配置文件需是新的文件 bin/logstash -f config/logstash_run.yml --config.reload.automatic Dockerfile文件\nFROM centos:7 MAINTAINER wandong RUN yum install -y wget java-1.8.0-openjdk curl unzip iproute net-tools \u0026amp;\u0026amp; \\ yum clean all \u0026amp;\u0026amp; \\ rm -rf /var/cache/yum/* ADD logstash-7.15.2-linux-x86_64.tar.gz /opt/ WORKDIR /opt/logstash-7.15.2 COPY start.sh /opt/logstash-7.15.2 EXPOSE 5044 9600 CMD [\u0026#34;sh\u0026#34;,\u0026#34;start.sh\u0026#34;] log.file.path : 10.42.76.201 and message : 39.144.219.132\n","permalink":"https://www.sulvblog.cn/post/elasticsearch%E5%85%A5%E9%97%A8/","summary":"ES版本： v7.17.3\nES环境搭建视频：https://pan.baidu.com/s/1PsTNbpDy\u0026ndash;M-pvFWb3aehQ?pwd=nwxl\nElasticSearch快速入门实战 note 链接：http://note.youdao.com/noteshare?id=d5d5718ae542f274ba0fda4284a53231\u0026amp;sub=68E590656C7A48858C7F6997D4A1511A\n全文检索 数据分类：\n结构化数据： 固定格式，有限长度 比如mysql存的数据 非结构化数据：不定长，无固定格式 比如邮件，word文档，日志 半结构化数据： 前两者结合 比如xml，html 搜索分类：\n结构化数据搜索： 使用关系型数据库\n非结构化数据搜索\n顺序扫描 全文检索 设想一个关于搜索的场景，假设我们要搜索一首诗句内容中带“前”字的古诗\nname content author 静夜思 床前明月光,疑是地上霜。举头望明月，低头思故乡。 李白 望庐山瀑布 日照香炉生紫烟，遥看瀑布挂前川。飞流直下三千尺,疑是银河落九天。 李白 \u0026hellip; \u0026hellip; \u0026hellip; 思考：用传统关系型数据库和ES 实现会有什么差别？\n如果用像 MySQL 这样的 RDBMS 来存储古诗的话，我们应该会去使用这样的 SQL 去查询\n​ select name from poems where content like \u0026ldquo;%前%\u0026rdquo;\n这种我们称为顺序扫描法，需要遍历所有的记录进行匹配。不但效率低，而且不符合我们搜索时的期望，比如我们在搜索“ABCD\u0026quot;这样的关键词时，通常还希望看到\u0026quot;A\u0026quot;,\u0026ldquo;AB\u0026rdquo;,\u0026ldquo;CD\u0026rdquo;,“ABC”的搜索结果。\n什么是全文检索 全文检索是指：\n通过一个程序扫描文本中的每一个单词，针对单词建立索引，并保存该单词在文本中的位置、以及出现的次数 用户查询时，通过之前建立好的索引来查询，将索引中单词对应的文本位置、出现的次数返回给用户，因为有了具体文本的位置，所以就可以将具体内容读取出来了 ​ 搜索原理简单概括的话可以分为这么几步：\n内容爬取，停顿词过滤比如一些无用的像\u0026quot;的\u0026quot;，“了”之类的语气词/连接词 内容分词，提取关键词 根据关键词建立倒排索引 用户输入关键词进行搜索 倒排索引 索引就类似于目录，平时我们使用的都是索引，都是通过主键定位到某条数据，那么倒排索引呢，刚好相反，数据对应到主键。\n​ 这里以一个博客文章的内容为例:\n正排索引（正向索引）\n文章ID 文章标题 文章内容 1 浅析JAVA设计模式 JAVA设计模式是每一个JAVA程序员都应该掌握的进阶知识 2 JAVA多线程设计模式 JAVA多线程与设计模式结合 倒排索引（反向索引）","title":"离线安装docker"},{"content":"离线安装docker https://download.docker.com/linux/static/stable/x86_64/docker-20.10.14.tgz\n#解压 tar -xvzf docker-20.10.14.tgz -C /opt/ chown root:root -R /opt/docker/ cp /opt/docker/* /usr/bin cat \u0026lt;\u0026lt;EOF \u0026gt;/etc/systemd/system/docker.service [Unit] Description=Docker Application Container Engine Documentation=https://docs.docker.com After=network-online.target firewalld.service Wants=network-online.target [Service] Type=notify ExecStart=/usr/bin/dockerd ExecReload=/bin/kill -s HUP \\$MAINPID LimitNOFILE=infinity LimitNPROC=infinity TimeoutStartSec=0 Delegate=yes KillMode=process Restart=on-failure StartLimitBurst=3 StartLimitInterval=60s [Install] WantedBy=multi-user.target EOF chmod +x /etc/systemd/system/docker.service # 加载service配置 systemctl daemon-reload #设置开机启动 并立即启动 systemctl enable docker.service --now ","permalink":"https://www.sulvblog.cn/post/%E7%A6%BB%E7%BA%BF%E5%AE%89%E8%A3%85docker/","summary":"离线安装docker https://download.docker.com/linux/static/stable/x86_64/docker-20.10.14.tgz\n#解压 tar -xvzf docker-20.10.14.tgz -C /opt/ chown root:root -R /opt/docker/ cp /opt/docker/* /usr/bin cat \u0026lt;\u0026lt;EOF \u0026gt;/etc/systemd/system/docker.service [Unit] Description=Docker Application Container Engine Documentation=https://docs.docker.com After=network-online.target firewalld.service Wants=network-online.target [Service] Type=notify ExecStart=/usr/bin/dockerd ExecReload=/bin/kill -s HUP \\$MAINPID LimitNOFILE=infinity LimitNPROC=infinity TimeoutStartSec=0 Delegate=yes KillMode=process Restart=on-failure StartLimitBurst=3 StartLimitInterval=60s [Install] WantedBy=multi-user.target EOF chmod +x /etc/systemd/system/docker.service # 加载service配置 systemctl daemon-reload #设置开机启动 并立即启动 systemctl enable docker.service --now ","title":"离线安装docker"},{"content":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub.\nQuick Start Create a new post $ hexo new \u0026#34;My New Post\u0026#34; More info: Writing\nRun server $ hexo server More info: Server\nGenerate static files $ hexo generate More info: Generating\nDeploy to remote sites $ hexo deploy More info: Deployment\n","permalink":"https://www.sulvblog.cn/post/hello-world/","summary":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub.\nQuick Start Create a new post $ hexo new \u0026#34;My New Post\u0026#34; More info: Writing\nRun server $ hexo server More info: Server\nGenerate static files $ hexo generate More info: Generating\nDeploy to remote sites $ hexo deploy More info: Deployment","title":"Hello World"},{"content":"hexo博客框架的使用 安装node.js 官网： https://nodejs.org/en/\n安装国内淘宝npm npm install -g cnpm --registry=https://registry.npm.taobao.org 安装hexo cnpm install -g hexo-cli\rhexo -v hexo初始化 hexo init 目录 hexo server 新建文章 文章都在source\\_posts目录下\nhexo new \u0026#34;我的第一篇博客文章\u0026#34; 配置后刷新并重启服务 hexo clean hexo g hexo server 更换主题 进入项目目录\ngit clone https://github.com/litten/hexo-theme-yilia.git themes/yilia 修改项目目录下配置文件_config.yml\ntheme: yilia 修复更换主题后全部文章无法显示问题 # 进入项目目录后 cnpm i hexo-generator-json-content --save # 随后在项目目录下的_config.yml文件后添加内容 jsonContent: meta: false pages: false posts: title: true date: true path: true text: false raw: false content: false slug: false updated: false comments: false link: false permalink: false excerpt: false categories: false tags: true 刷新并重启项目\n配置yilia主题显示文章目录 进入 themes\\yilia目录下，修改_config.yml文件\ntoc: 2 处理文章图片不显示问题 查看hexo版本，现在我安装的 hexo 版本已经是 4.3.0 了 (2022年)，该方法适用\nhexo version 进入项目目录执行命令\n# 可用cnpm替换 npm install hexo-asset-image --save 插件bug问题，需要做如下修改 进入你博客的根目录，然后下面顺序找到index.js: node_modules \u0026ndash;\u0026gt; hexo-asset-image \u0026ndash;\u0026gt; index.js 用VS Code 或者 记事本打开 index.js 在第 58 行，可以找到这么一行代码： $(this).attr(\u0026#39;src\u0026#39;, config.root + link + src); 把这一行代码改成下面这样 $(this).attr(\u0026#39;src\u0026#39;, src); 随后保存文件\n插入图片的用法 创建文章时，现在插件会自动在文章的_posts目录下创建md文件名相同的目录以存放图片。当然也可以手动创建目录和md文件。\n在文章中写如下内容便可插入图片（注意圆括号内无需写路径，仅写图片的全名即可，前提是图片在对应的文章的目录下）：\n![image-20220809152616143](image-20220809152616143.png) ","permalink":"https://www.sulvblog.cn/post/hexo%E5%8D%9A%E5%AE%A2%E6%A1%86%E6%9E%B6%E7%9A%84%E4%BD%BF%E7%94%A8/","summary":"hexo博客框架的使用 安装node.js 官网： https://nodejs.org/en/\n安装国内淘宝npm npm install -g cnpm --registry=https://registry.npm.taobao.org 安装hexo cnpm install -g hexo-cli\rhexo -v hexo初始化 hexo init 目录 hexo server 新建文章 文章都在source\\_posts目录下\nhexo new \u0026#34;我的第一篇博客文章\u0026#34; 配置后刷新并重启服务 hexo clean hexo g hexo server 更换主题 进入项目目录\ngit clone https://github.com/litten/hexo-theme-yilia.git themes/yilia 修改项目目录下配置文件_config.yml\ntheme: yilia 修复更换主题后全部文章无法显示问题 # 进入项目目录后 cnpm i hexo-generator-json-content --save # 随后在项目目录下的_config.yml文件后添加内容 jsonContent: meta: false pages: false posts: title: true date: true path: true text: false raw: false content: false slug: false updated: false comments: false link: false permalink: false excerpt: false categories: false tags: true 刷新并重启项目","title":"hexo博客框架的使用"},{"content":"下载hugo二进制程序包 下载地址： https://github.com/gohugoio/hugo/releases\n下载后解压、将hugo路径添加到环境变量。先设置hugo变量，然后在path中添加\n验证安装 hugo version 新建站点 hugo new site myblog # 该命令会新建一个文件夹myblog ls ./myblog # archetypes/ config.toml content/ data/ # layouts/ static/ themes/ ##我目前了解如下 #config.toml 进行参数配置，与之后的theme相关 #content 之后博客(.md)的文件都储存在这里 #layout 可个性化修改博客的展示细节，需要懂网络架构知识 #static 储存一些静态文件，比如本地图片，插入到博客中 #themes 主题，接下来会介绍 下载主题（hugo没有默认主题） 有多种hugo主题可供下载：https://themes.gohugo.io/ 推荐主题： https://adityatelange.github.io/hugo-PaperMod/\ncd ./myblog git clone https://github.com/adityatelange/hugo-PaperMod themes/PaperMod ls ./themes # PaperMod/ ls ./themes/PaperMod/ # LICENSE README.md assets/ go.mod i18n/ images/ layouts/ theme.toml 修改配置 papermod\n通用配置参数查询：https://gohugo.io/getting-started/configuration/\nPaperMod自定义参数查询：https://adityatelange.github.io/hugo-PaperMod/posts/papermod/papermod-features/\n示例配置：https://www.sulvblog.cn/posts/blog/build_hugo/#4%e9%85%8d%e7%bd%ae%e6%96%87%e4%bb%b6\n将 config.toml 重命名为 config.yml 然后进行修改\nbaseURL: https://www.sulvblog.cn # baseURL: https://www.sulvblog.cn # 绑定的域名 languageCode: zh-cn # en-us title: 万东的云计算运维博客 theme: hugo-PaperMod # 主题名字，和themes文件夹下的一致 enableRobotsTXT: true buildDrafts: false buildFuture: false buildExpired: false googleAnalytics: UA-123-45 minify: disableXML: true minifyOutput: true params: env: production # to enable google analytics, opengraph, twitter-cards and schema. title: ExampleSite description: \u0026#34;ExampleSite description\u0026#34; keywords: [Blog, Portfolio, PaperMod] author: Me # author: [\u0026#34;Me\u0026#34;, \u0026#34;You\u0026#34;] # multiple authors images: [\u0026#34;\u0026lt;link or path of image for opengraph, twitter-cards\u0026gt;\u0026#34;] DateFormat: \u0026#34;January 2, 2006\u0026#34; defaultTheme: dark # dark, light disableThemeToggle: false ShowReadingTime: true ShowShareButtons: true ShowPostNavLinks: true ShowBreadCrumbs: true ShowCodeCopyButtons: true ShowWordCount: true ShowRssButtonInSectionTermList: true UseHugoToc: true disableSpecial1stPost: false disableScrollToTop: false comments: false hidemeta: false hideSummary: false showtoc: true tocopen: true searchHidden: true assets: # disableHLJS: true # to disable highlight.js # disableFingerprinting: true favicon: \u0026#34;\u0026lt;link / abs url\u0026gt;\u0026#34; favicon16x16: \u0026#34;\u0026lt;link / abs url\u0026gt;\u0026#34; favicon32x32: \u0026#34;\u0026lt;link / abs url\u0026gt;\u0026#34; apple_touch_icon: \u0026#34;\u0026lt;link / abs url\u0026gt;\u0026#34; safari_pinned_tab: \u0026#34;\u0026lt;link / abs url\u0026gt;\u0026#34; label: text: \u0026#34;万东的云计算运维博客\u0026#34; icon: /apple-touch-icon.png iconHeight: 35 # profile-mode profileMode: enabled: false # needs to be explicitly set title: ExampleSite subtitle: \u0026#34;This is subtitle\u0026#34; imageUrl: \u0026#34;\u0026lt;img location\u0026gt;\u0026#34; imageWidth: 120 imageHeight: 120 imageTitle: my image buttons: - name: 文章 url: posts - name: 标签 url: tags # home-info mode homeInfoParams: Title: \u0026#34;技术学习笔记 \\U0001F44B\u0026#34; Content: 学无止境 socialIcons: - name: github url: \u0026#34;https://github.com/wandong1\u0026#34; analytics: google: SiteVerificationTag: \u0026#34;XYZabc\u0026#34; bing: SiteVerificationTag: \u0026#34;XYZabc\u0026#34; yandex: SiteVerificationTag: \u0026#34;XYZabc\u0026#34; cover: hidden: true # hide everywhere but not in structured data hiddenInList: true # hide on list pages and home hiddenInSingle: true # hide on single page editPost: URL: \u0026#34;https://github.com/\u0026lt;path_to_repo\u0026gt;/content\u0026#34; Text: \u0026#34;Suggest Changes\u0026#34; # edit text appendFilePath: true # to append file path to Edit link # for search # https://fusejs.io/api/options.html fuseOpts: isCaseSensitive: false shouldSort: true location: 0 distance: 1000 threshold: 0.4 minMatchCharLength: 0 keys: [\u0026#34;title\u0026#34;, \u0026#34;permalink\u0026#34;, \u0026#34;summary\u0026#34;, \u0026#34;content\u0026#34;] menu: main: - identifier: 搜索 name: 搜索 url: search weight: 80 - identifier: 分类 name: 分类 url: /categories/ weight: 10 - identifier: 标签 name: 标签 url: /tags/ weight: 20 - identifier: 归档 name: 归档 url: /archives/ weight: 41 # Read: https://github.com/adityatelange/hugo-PaperMod/wiki/FAQs#using-hugos-syntax-highlighter-chroma pygmentsUseClasses: true markup: highlight: noClasses: false # anchorLineNos: true # codeFences: true # guessSyntax: true # lineNos: true # style: monokai outputs: home: - HTML - RSS - JSON # is necessary 搜索 和 归档功能需要在content目录下创建对应的md文件\n$ cat archive.md\n--- title: \u0026#34;文章归档\u0026#34; layout: \u0026#34;archives\u0026#34; url: \u0026#34;/archives/\u0026#34; summary: \u0026#34;archives\u0026#34; --- $ cat search.md\n--- title: \u0026#34;Search\u0026#34; layout: \u0026#34;search\u0026#34; --- 个性化修改 转移目录至侧边栏 Pull Request #675 · adityatelange/hugo-PaperMod 提出将文章目录转移至侧边栏，可以轻松实现上下文跳转。截至发文这一特性还未并入主分支，我们可以让主题子模块追踪该远程 PR 分支：\ncd themes/PaperMod git fetch origin pull/675/head:toc-on-the-side --depth=1 git checkout toc-on-the-side cd ../.. ","permalink":"https://www.sulvblog.cn/post/hugo-%E5%8D%9A%E5%AE%A2%E7%A8%8B%E5%BA%8F%E6%90%AD%E5%BB%BA%E6%95%99%E7%A8%8B/","summary":"下载hugo二进制程序包 下载地址： https://github.com/gohugoio/hugo/releases\n下载后解压、将hugo路径添加到环境变量。先设置hugo变量，然后在path中添加\n验证安装 hugo version 新建站点 hugo new site myblog # 该命令会新建一个文件夹myblog ls ./myblog # archetypes/ config.toml content/ data/ # layouts/ static/ themes/ ##我目前了解如下 #config.toml 进行参数配置，与之后的theme相关 #content 之后博客(.md)的文件都储存在这里 #layout 可个性化修改博客的展示细节，需要懂网络架构知识 #static 储存一些静态文件，比如本地图片，插入到博客中 #themes 主题，接下来会介绍 下载主题（hugo没有默认主题） 有多种hugo主题可供下载：https://themes.gohugo.io/ 推荐主题： https://adityatelange.github.io/hugo-PaperMod/\ncd ./myblog git clone https://github.com/adityatelange/hugo-PaperMod themes/PaperMod ls ./themes # PaperMod/ ls ./themes/PaperMod/ # LICENSE README.md assets/ go.mod i18n/ images/ layouts/ theme.toml 修改配置 papermod\n通用配置参数查询：https://gohugo.io/getting-started/configuration/\nPaperMod自定义参数查询：https://adityatelange.github.io/hugo-PaperMod/posts/papermod/papermod-features/\n示例配置：https://www.sulvblog.cn/posts/blog/build_hugo/#4%e9%85%8d%e7%bd%ae%e6%96%87%e4%bb%b6\n将 config.toml 重命名为 config.yml 然后进行修改","title":"Hugo 博客程序搭建教程"},{"content":"Rancher Rancher 是一套容器管理平台，它可以帮助组织在生产环境中轻松快捷的部署和管理容器。 Rancher 可以轻松地管理各种环境的 Kubernetes，满足 IT 需求并为 DevOps 团队提供支持。\nRancher 四个组成部分 Rancher 由以下四个部分组成：\n1、基础设施编排\nRancher 可以使用任何公有云或者私有云的 Linux 主机资源。Linux 主机可以是虚拟机，也可以是 物理机。\n2、容器编排与调度\n很多用户都会选择使用容器编排调度框架来运行容器化应用。Rancher 包含了当前全部主流的编排 调度引擎，例如 Docker Swarm， Kubernetes， 和 Mesos。同一个用户可以创建 Swarm 或者 Kubernetes 集群。并且可以使用原生的 Swarm 或者 Kubernetes 工具管理应用。 除了 Swarm，Kubernetes 和 Mesos 之外，Rancher 还支持自己的 Cattle 容器编排调度引擎。 Cattle 被广泛用于编排 Rancher 自己的基础设施服务以及用于 Swarm 集群，Kubernetes 集群和 Mesos 集群的配置，管理与升级。\n3、应用商店\nRancher 的用户可以在应用商店里一键部署由多个容器组成的应用。用户可以管理这个部署的应 用，并且可以在这个应用有新的可用版本时进行自动化的升级。Rancher 提供了一个由 Rancher 社区维 护的应用商店，其中包括了一系列的流行应用。Rancher 的用户也可以创建自己的私有应用商店。\n4、企业级权限管理\nRancher 支持灵活的插件式的用户认证。支持 Active Directory，LDAP， Github 等 认证方 式。\n使用 Rancher 搭建 k8s 集群 初始化安装机环境 关闭selinux和防火墙\nsystemctl stop firewalld.service \u0026amp;\u0026amp; systemctl disable firewalld.service \u0026amp;\u0026amp; iptables -F \u0026amp;\u0026amp;setenforce 0 hostnamectl set-hostname master01\rhostnamectl set-hostname node01\rhostnamectl set-hostname node02 安装 docker 环境依赖\n在线\nyum install -y yum-utils yum-config-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo yum install docker-ce docker-ce-cli containerd.io -y systemctl start docker \u0026amp;\u0026amp; systemctl enable docker.service \u0026amp;\u0026amp; systemctl status docker 离线安装docker\n#!/bin/bash\r#解压\rdockers images \u0026gt;\u0026gt;/dev/null\rif [ $? -eq 0 ];then\recho \u0026#34;docker is installed!!\u0026#34;\relse\rtar -xvzf docker-20.10.14.tgz -C /opt/\rchown root:root -R /opt/docker/\rcp /opt/docker/* /usr/bin\rcat \u0026lt;\u0026lt;EOF \u0026gt;/etc/systemd/system/docker.service\r[Unit]\rDescription=Docker Application Container Engine\rDocumentation=https://docs.docker.com\rAfter=network-online.target firewalld.service\rWants=network-online.target\r[Service]\rType=notify\rExecStart=/usr/bin/dockerd\rExecReload=/bin/kill -s HUP \\$MAINPID\rLimitNOFILE=infinity\rLimitNPROC=infinity\rTimeoutStartSec=0\rDelegate=yes\rKillMode=process\rRestart=on-failure\rStartLimitBurst=3\rStartLimitInterval=60s\r[Install]\rWantedBy=multi-user.target\rEOF\rchmod +x /etc/systemd/system/docker.service\r# 加载service配置\rsystemctl daemon-reload \u0026amp;\u0026amp; echo \u0026#34;加载service配置 success!\u0026#34;\r# dockerDamon\rtee /etc/docker/daemon.json \u0026lt;\u0026lt; \u0026#39;EOF\u0026#39;\r{\r\u0026#34;registry-mirrors\u0026#34;:[\u0026#34;https://dockerhub.azk8s.cn\u0026#34;,\u0026#34;http://hubmirror.c.163.com\u0026#34;,\u0026#34;http://qtid6917.mirror.aliyuncs.com\u0026#34;]\r}\rEOF\recho \u0026#34;docker daemon.json edit success!\u0026#34;\r#设置开机启动 并立即启动\rsystemctl enable docker.service --now \u0026amp;\u0026amp; echo \u0026#34;docker start success!\u0026#34;\rfi 镜像加速，每台机器执行\ntee /etc/docker/daemon.json \u0026lt;\u0026lt; \u0026#39;EOF\u0026#39; { \u0026#34;registry-mirrors\u0026#34;:[\u0026#34;https://dockerhub.azk8s.cn\u0026#34;,\u0026#34;http://hubmirror.c.163.com\u0026#34;,\u0026#34;http://qtid6917.mirror.aliyuncs.com\u0026#34;] } EOF 安装 rancher 平台\n离线导入rancher镜像\ndocker run -d --restart=unless-stopped -p 80:80 -p 443:443 -- privileged rancher/rancher 注：\u0026ndash;restart=unless-stopped ，在容器退出时总是重启容器，但是不考虑在 Docker 守护进程 启动时就已经停止了的容器\n安装过程如果失败需要清理后再重新安装K8S节点\n#!/bin/bash #df -h|grep kubelet |awk -F % \u0026#39;{print $2}\u0026#39;|xargs umount sudo rm /var/lib/kubelet/* -rf sudo rm /etc/kubernetes/* -rf sudo rm /etc/cni/* -rf sudo rm /var/lib/rancher/* -rf sudo rm /var/lib/etcd/* -rf sudo rm /var/lib/cni/* -rf sudo rm /opt/cni/* -rf sudo ip link del flannel.1 ip link del cni0 iptables -F \u0026amp;\u0026amp; iptables -t nat -F docker rm -f `docker ps -a -q` docker volume ls|awk \u0026#39;{print $2}\u0026#39;|xargs docker volume rm systemctl restart docker ","permalink":"https://www.sulvblog.cn/post/rancher/","summary":"Rancher Rancher 是一套容器管理平台，它可以帮助组织在生产环境中轻松快捷的部署和管理容器。 Rancher 可以轻松地管理各种环境的 Kubernetes，满足 IT 需求并为 DevOps 团队提供支持。\nRancher 四个组成部分 Rancher 由以下四个部分组成：\n1、基础设施编排\nRancher 可以使用任何公有云或者私有云的 Linux 主机资源。Linux 主机可以是虚拟机，也可以是 物理机。\n2、容器编排与调度\n很多用户都会选择使用容器编排调度框架来运行容器化应用。Rancher 包含了当前全部主流的编排 调度引擎，例如 Docker Swarm， Kubernetes， 和 Mesos。同一个用户可以创建 Swarm 或者 Kubernetes 集群。并且可以使用原生的 Swarm 或者 Kubernetes 工具管理应用。 除了 Swarm，Kubernetes 和 Mesos 之外，Rancher 还支持自己的 Cattle 容器编排调度引擎。 Cattle 被广泛用于编排 Rancher 自己的基础设施服务以及用于 Swarm 集群，Kubernetes 集群和 Mesos 集群的配置，管理与升级。\n3、应用商店\nRancher 的用户可以在应用商店里一键部署由多个容器组成的应用。用户可以管理这个部署的应 用，并且可以在这个应用有新的可用版本时进行自动化的升级。Rancher 提供了一个由 Rancher 社区维 护的应用商店，其中包括了一系列的流行应用。Rancher 的用户也可以创建自己的私有应用商店。\n4、企业级权限管理\nRancher 支持灵活的插件式的用户认证。支持 Active Directory，LDAP， Github 等 认证方 式。","title":"rancher的安装和使用"},{"content":"zookeeper 官网 https://zookeeper.apache.org/ 找download\n一、下载软件包 https://dlcdn.apache.org/zookeeper/zookeeper-3.8.0/apache-zookeeper-3.8.0-bin.tar.gz\n二、集群部署 1、安装JDK centos\nyum install java-1.8.0-openjdk* -y 2、zk配置文件 # The number of milliseconds of each tick\rtickTime=2000\r# The number of ticks that the initial # synchronization phase can take\rinitLimit=10\r# The number of ticks that can pass between # sending a request and getting an acknowledgement\rsyncLimit=5\r# the directory where the snapshot is stored.\r# do not use /tmp for storage, /tmp here is just # example sakes.\rdataDir=/opt/zookeeper/data\r# the port at which the clients will connect\rclientPort=2181\r# the maximum number of client connections.\r# increase this if you need to handle more clients\r#maxClientCnxns=60\r#\r# Be sure to read the maintenance section of the # administrator guide before turning on autopurge.\r#\r# https://zookeeper.apache.org/doc/current/zookeeperAdmin.html#sc_maintenance\r#\r# The number of snapshots to retain in dataDir\r#autopurge.snapRetainCount=3\r# Purge task interval in hours\r# Set to \u0026#34;0\u0026#34; to disable auto purge feature\r#autopurge.purgeInterval=1\r## Metrics Providers\r#\r# https://prometheus.io Metrics Exporter\r#metricsProvider.className=org.apache.zookeeper.metrics.prometheus.PrometheusMetricsProvider\r#metricsProvider.httpHost=0.0.0.0\r#metricsProvider.httpPort=7000\r#metricsProvider.exportJvmInfo=true\rserver.1=10.43.152.67:2888:3888\rserver.2=10.43.152.68:2888:3888\rserver.3=10.43.152.69:2888:3888 注：每个zk节点，的dataDir目录下必须有myid文件，myid文件中的内容必须为对应的 server.【编号】=10.43.152.67:2888:3888 中的编号\n3、解压zk并启动 zookeeper前台启动命令\nbin/zkServer.sh start-foreground conf/zoo.cfg ","permalink":"https://www.sulvblog.cn/post/zookeeper/","summary":"zookeeper 官网 https://zookeeper.apache.org/ 找download\n一、下载软件包 https://dlcdn.apache.org/zookeeper/zookeeper-3.8.0/apache-zookeeper-3.8.0-bin.tar.gz\n二、集群部署 1、安装JDK centos\nyum install java-1.8.0-openjdk* -y 2、zk配置文件 # The number of milliseconds of each tick\rtickTime=2000\r# The number of ticks that the initial # synchronization phase can take\rinitLimit=10\r# The number of ticks that can pass between # sending a request and getting an acknowledgement\rsyncLimit=5\r# the directory where the snapshot is stored.\r# do not use /tmp for storage, /tmp here is just # example sakes.","title":"zookeeper的安装和使用"},{"content":"随笔 技术的变革，一定是思想先行，云原生是一种构建和运行应用程序的方法，是一套技术体系和方法论。云原生（CloudNative）是一个组合词，Cloud+Native。Cloud表示应用程序位于云中，而不是传统的数据中心；Native表示应用程序从设计之初即考虑到云的环境，原生为云而设计，在云上以最佳姿势运行，充分利用和发挥云平台的弹性+分布式优势。\n符合云原生架构的应用程序应该是：采用开源堆栈（K8S+Docker）进行容器化，基于微服务架构提高灵活性和可维护性，借助敏捷方法、DevOps支持持续迭代和运维自动化，利用云平台设施实现弹性伸缩、动态调度、优化资源利用率。\n云原生的四要素 微服务：几乎每个云原生的定义都包含微服务，跟微服务相对的是单体应用，微服务有理论基础，那就是康威定律，指导服务怎么切分，很玄乎，凡是能称为理论定律的都简单明白不了，不然就忒没b格，大概意思是组织架构决定产品形态，不知道跟马克思的生产关系影响生产力有无关系。\n微服务架构的好处就是按function切了之后，服务解耦，内聚更强，变更更易；另一个划分服务的技巧据说是依据DDD来搞。\n容器化：Docker是应用最为广泛的容器引擎，在思科谷歌等公司的基础设施中大量使用，是基于LXC技术搞的，容器化为微服务提供实施保障，起到应用隔离作用，K8S是容器编排系统，用于容器管理，容器间的负载均衡，谷歌搞的，Docker和K8S都采用Go编写，都是好东西。\nDevOps：这是个组合词，Dev+Ops，就是开发和运维合体，不像开发和产品，经常刀刃相见，实际上DevOps应该还包括测试，DevOps是一个敏捷思维，是一个沟通文化，也是组织形式，为云原生提供持续交付能力。\n持续交付：持续交付是不误时开发，不停机更新，小步快跑，反传统瀑布式开发模型，这要求开发版本和稳定版本并存，其实需要很多流程和工具支撑。\n如何云原生？ 首先，云原生借了云计算的东风，没有云计算，自然没有云原生，云计算是云原生的基础。\n随着虚拟化技术的成熟和分布式框架的普及，在容器技术、可持续交付、编排系统等开源社区的推动下，以及微服务等开发理念的带动下，应用上云已经是不可逆转的趋势。\n云计算的3层划分，即基础设施即服务(IaaS)、平台即服务(PaaS)、软件即服务(SaaS)为云原生提供了技术基础和方向指引，真正的云化不仅仅是基础设施和平台的变化，应用也需要做出改变，摈弃传统的土方法，在架构设计、开发方式、部署维护等各个阶段和方面都基于云的特点，重新设计，从而建设全新的云化的应用，即云原生应用。\n1.本地部署的传统应用往往采用c/c++、企业级java编写，而云原生应用则需要用以网络为中心的go、node.js等新兴语言编写。\n2.本地部署的传统应用可能需要停机更新，而云原生应用应该始终是最新的，需要支持频繁变更，持续交付，蓝绿部署。\n3.本地部署的传统应用无法动态扩展，往往需要冗余资源以抵抗流量高峰，而云原生应用利用云的弹性自动伸缩，通过共享降本增效。\n4.本地部署的传统应用对网络资源，比如ip、端口等有依赖，甚至是硬编码，而云原生应用对网络和存储都没有这种限制。\n5.本地部署的传统应用通常人肉部署手工运维，而云原生应用这一切都是自动化的。\n6.本地部署的传统应用通常依赖系统环境，而云原生应用不会硬连接到任何系统环境，而是依赖抽象的基础架构，从而获得良好移植性。\n7.本地部署的传统应用有些是单体(巨石)应用，或者强依赖，而基于微服务架构的云原生应用，纵向划分服务，模块化更合理。\n可见，要转向云原生应用需要以新的云原生方法开展工作，云原生包括很多方面：基础架构服务、虚拟化、容器化、容器编排、微服务。幸运的是，开源社区在云原生应用方面做出了大量卓有成效的工作，很多开源的框架和设施可以通过拿来主义直接用，2013年Docker推出并很快成为容器事实标准，随后围绕容器编排的混战中，2017年诞生的k8s很快脱颖而出，而这些技术极大的降低了开发云原生应用的技术门槛。\n","permalink":"https://www.sulvblog.cn/post/%E9%9A%8F%E7%AC%94/","summary":"随笔 技术的变革，一定是思想先行，云原生是一种构建和运行应用程序的方法，是一套技术体系和方法论。云原生（CloudNative）是一个组合词，Cloud+Native。Cloud表示应用程序位于云中，而不是传统的数据中心；Native表示应用程序从设计之初即考虑到云的环境，原生为云而设计，在云上以最佳姿势运行，充分利用和发挥云平台的弹性+分布式优势。\n符合云原生架构的应用程序应该是：采用开源堆栈（K8S+Docker）进行容器化，基于微服务架构提高灵活性和可维护性，借助敏捷方法、DevOps支持持续迭代和运维自动化，利用云平台设施实现弹性伸缩、动态调度、优化资源利用率。\n云原生的四要素 微服务：几乎每个云原生的定义都包含微服务，跟微服务相对的是单体应用，微服务有理论基础，那就是康威定律，指导服务怎么切分，很玄乎，凡是能称为理论定律的都简单明白不了，不然就忒没b格，大概意思是组织架构决定产品形态，不知道跟马克思的生产关系影响生产力有无关系。\n微服务架构的好处就是按function切了之后，服务解耦，内聚更强，变更更易；另一个划分服务的技巧据说是依据DDD来搞。\n容器化：Docker是应用最为广泛的容器引擎，在思科谷歌等公司的基础设施中大量使用，是基于LXC技术搞的，容器化为微服务提供实施保障，起到应用隔离作用，K8S是容器编排系统，用于容器管理，容器间的负载均衡，谷歌搞的，Docker和K8S都采用Go编写，都是好东西。\nDevOps：这是个组合词，Dev+Ops，就是开发和运维合体，不像开发和产品，经常刀刃相见，实际上DevOps应该还包括测试，DevOps是一个敏捷思维，是一个沟通文化，也是组织形式，为云原生提供持续交付能力。\n持续交付：持续交付是不误时开发，不停机更新，小步快跑，反传统瀑布式开发模型，这要求开发版本和稳定版本并存，其实需要很多流程和工具支撑。\n如何云原生？ 首先，云原生借了云计算的东风，没有云计算，自然没有云原生，云计算是云原生的基础。\n随着虚拟化技术的成熟和分布式框架的普及，在容器技术、可持续交付、编排系统等开源社区的推动下，以及微服务等开发理念的带动下，应用上云已经是不可逆转的趋势。\n云计算的3层划分，即基础设施即服务(IaaS)、平台即服务(PaaS)、软件即服务(SaaS)为云原生提供了技术基础和方向指引，真正的云化不仅仅是基础设施和平台的变化，应用也需要做出改变，摈弃传统的土方法，在架构设计、开发方式、部署维护等各个阶段和方面都基于云的特点，重新设计，从而建设全新的云化的应用，即云原生应用。\n1.本地部署的传统应用往往采用c/c++、企业级java编写，而云原生应用则需要用以网络为中心的go、node.js等新兴语言编写。\n2.本地部署的传统应用可能需要停机更新，而云原生应用应该始终是最新的，需要支持频繁变更，持续交付，蓝绿部署。\n3.本地部署的传统应用无法动态扩展，往往需要冗余资源以抵抗流量高峰，而云原生应用利用云的弹性自动伸缩，通过共享降本增效。\n4.本地部署的传统应用对网络资源，比如ip、端口等有依赖，甚至是硬编码，而云原生应用对网络和存储都没有这种限制。\n5.本地部署的传统应用通常人肉部署手工运维，而云原生应用这一切都是自动化的。\n6.本地部署的传统应用通常依赖系统环境，而云原生应用不会硬连接到任何系统环境，而是依赖抽象的基础架构，从而获得良好移植性。\n7.本地部署的传统应用有些是单体(巨石)应用，或者强依赖，而基于微服务架构的云原生应用，纵向划分服务，模块化更合理。\n可见，要转向云原生应用需要以新的云原生方法开展工作，云原生包括很多方面：基础架构服务、虚拟化、容器化、容器编排、微服务。幸运的是，开源社区在云原生应用方面做出了大量卓有成效的工作，很多开源的框架和设施可以通过拿来主义直接用，2013年Docker推出并很快成为容器事实标准，随后围绕容器编排的混战中，2017年诞生的k8s很快脱颖而出，而这些技术极大的降低了开发云原生应用的技术门槛。","title":"随笔"}]